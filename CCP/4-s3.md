## S3

<br>

- s3는 `무한 확장 스토리` -> EBS처럼 따로 용량을 설정 안해도됨
- 예) EBS스냅샷을 뜨면, 실제 메카니즘은 s3에 저장 된다!

-----------------
## s3 사용 케이스

- 백업 또는 일반 저장 스토리지
- 재해복구 스토리지
- 아카이브
- 하이브리드 클라우드 스토리지
- 애플리케이션 호스팅
- 미디어 호스팅 -> s3에서 영상도 볼 수 있음
- 데이터 레이크, 빅데이터 분석용
- 소프트웨어 배포
- 동적 웹사이트!!!!!!

### `핵심은 객체를 저장하는 것임!!!!`

<br>
<br>

----------------

## s3 버킷 특징

- S3는 오브젝트(파일)이 버킷(디렉토리)에 저장 된다는 것이다
버킷 이름은 전역적으로 고유해야 된다. -> 웹사이트 도메인 같은 것임
- 버킷은 리전수준에서 정의해야된다
- s3 버킷은 특정지역(리전)에 생성되는 것이다!!!!!
- 객체를 저장하기 위해서는 키가 필요하고, 키는 객체의 전체 경로를 나타낸다.
- 실제 s3에는 디렉터리라는 개념은 없고, 슬러쉬를 포함한 아주 긴 이름일 뿐이다 (UI에서 보기에는)
- 객체의 최대 크기는 5TB이다.
- 또한 5기가가 넘는 파일은 여러부분으로 나누어서 업로드 해야 된다.
- S3 ACL 버킷에 넣은 객체의 소유권을 설정 할 수 있다
- www에서 엑세스 가능하고, 정적 웹호스팅 하기 좋다.

<br>
<br>

------

## S3 버킷 정책

<br>

- 왜 객체 URL로 이미지가 안열리나?
  - >퍼블릭 엑세스가 차단되서 열리지 않음,
그냥 열었을때는 서명된 url을 이용해서 열엇음(aws 자격증명이 포함된 url임)

<br>
<br>

-----------


## s3 버킷 보안
- 사용자 기반의 보안 (iam 사용)
- 리소스 기반 -> 버킷 자체에 보안 정책을 적용 할 수 있음
  - 오브젝트 기반의 ACL 엑시스 컨트롤 리스트
  - 버킷 기반의 ACL 엑시스 컨트롤 리스트
  - s3버킷에는 사용자 기반의 보안이든 리소스 기반의 보안이든, Deny(거부는) 실행 할 수 없음
- S3에 저장할때, 암호화 가능
- 다른 계정의 IAM으로도, 내 S3 버킷 정책으로 접근 가능함 

<br>
<br>


---------
## s3 객체의 버전관리
- 버켓 수준에서 버젼관리가 가능 -> 객체를 업데이트 할때마다
- 기존것들을 덮어 씌우기 하지 않음 
- 의도치 않은 삭제를 방지, 복구 할 수 있음


<br>
<br>



-------------
## s3 엑세스 로깅

- s3에 접근한 로그들을 다른 버킷에 저장해 분석 할 수 있음

<br>
<br>


-------------------------
## s3 리플리케이션 (복제)

- 리전간 복제인 CRR - 크로스 리전 리플리케이션
- 같은 리전 복제인 SRR - 세임 리전 리플리케이션


<br>
<br>


S3 복제 프로세싱은 기본적으로 비동기 방식으로 진행됨,
버켓 복제를 위해서는 소스 버킷과, 대상 버킷에 S3 `버저닝`이 무조건 활성화 되어 있어야함!!!!!!!!!!


<br>
<br>


`CRR 케이스` <br>
한국 리전 -> 미국 리전 = 한국에 개쩌는 서비스가 있고 미국에 진출하려면 `짧은 엑세스 시간을 위해` 미국에도 똑같은 데이터 s3가 있엇으면 한다

<br>
<br>



`SRR 케이스` <br>
-> 프로덕션 과 테스트 계정간의 s3를 복제해서 데이터의 이중화 또는 다른 워크로드로 데이터를 확인하려고 하는것임!!!!


<br>
<br>


-------------------------------------------------

## s3 내구성과 가용성 개념

`내구성` <br>
s3로 인해 객체가 손실 될 수 있는 확률, 아마존에는 내구성 99.9999999999999999%라고 주장함
<br>
천만개 객체가 있을때, 만년후 하나의 객체를 읽어버릴 확률이라고 주장함
또한 모든 스토리지 클래스의 내구성은 동일함

<br><br>

`유효성, 가용성` <br>
얼마나 쉽게 또는 장애없이 서비스를 이용할 수 있냐... <br>
이건 스토리지 클래스 마다 다름. <br>
s3 스탠다드는 99.99%로 , 약 1년에 53분동안 서비스를 이용 할 수 없다<br>
이는 서비스를 처리 할 때, 오류가 생길수도 있다는 의미


<br><br>

----------------------------

## s3 스토리지 클래스들

<br><br>

`s3 스탠다드` <br>
- 자주 액세스 하는 데이터 용
- 지연시간이 짧고, 처리량이 많음
- 빅데이터 분석과, 모바일 게임 애플리케이션 등 쓰이기 쉬움, 콘텐츠 배포
- 유효성,가용성은 99.99%

<br><br><br>

`s3 infrequent access` (ia) - 드문 엑세스
- 자주 엑세스 하지는 않지만, 필요할 때 빠르게 액세스 해야되는 데이터에 적합
- 요금은 스탠다드 보다 저렴하지만, 검색 요금이 추가로 발생
- 그리고 유효성,가용성은  스탠다드보다 약간 낮음 99.9% 
- 재해 복구와 백업에 이상적임

<br><br><br>

`s3 one zone-infrequent access`
- 위 Ia랑 똑같고, 하나의 az에만 있는 저장소
- 내구성은 99.999999%로 높지만 가용영역이 파괴되면 데이터 손실됨
- 가용성은 99.5%로 일반 ia보다 더 낮네;;;
- 온프레미스 데이터나 다시 생성 가능한 데이터의 보조 백업 복사본 저장에 적합함

<br><br><br>

`s3 글래셔` <br>
아카이브와 백업에 적합한 저비용 스토리지,스토리지 비용에 검색 비용이 포함됨!!!!
  <br><br>

  - `s3 glacier instant retrieval` - 글래셔 즉시 검색
    - 밀리초 단위의 검색이 가능
    - 분기에 한번 엑세스 할때 적합
    - 최소 스토리지 유지기간은 90일

  - `s3 glacier flexible retrieval`
    - 유연한 3가지 검색 기능을 제공 
    - 1분에서 5분의 빠른검색 - expedited
    - 3~5시간의 검색 - standard
    - 5~12시간 검색 - bulk 무료
    - 최소 스토리지 유지기간은 90일

  - `s3 glacier deep archive`
    - 장기보관 스토리지
    - 12시간 검색 - standard
    - 48시간 검색 - bulk
    - 최소 유지기간은 180일

<br><br>

`s3 intelligent tiering`
- 사용자 패턴을 기반으로 엑세스 계층간에 객체를 이동시킴
- `매월 모니터링과 자동화 요금이 발생`
- `검색 요금은 발생 X`
- frequent access 계층에 자동으로 저장되고, 30일동안 엑세스 하지 않은 객체는 infrequent access 계층으로 이동됨
- 90일동안 액세스 하지 않으면, 아카이브 인스탄스 계층으로 이동함
- 90일에서 700+일 이면 아카이브 엑세스 티어로 이동
- 180일에서 700+일이면 딥아카이스 엑세스 티어로 이동

<br><br>



---------------------
## s3 오브젝트 잠금과 글래셔 볼트 락

`s3 object lock`이란? <br>
worm (write once read many) 한번 쓰고, 자주 읽을때
말그대로 즉 , 한번 업로드 하면, 누구도 건들거나 수정 할 수 없게 하는것

<br><br>

`글래셔 볼트락` (글래셔 볼트 = S3 버킷)

해당 파일을 나중에 편집 할 수 없도록 하는것
-> 이건 `글래셔 저장소에 대한 전체적인 정책임`..... `객체 개인별로 들어가는 규칙이 아님.....
볼트락 정책을 잠금하면 더이상 정책을 바꿀수 없음`

<br>
<br>
<br>

-----------------------------------

## s3 암호화

<br>
<br>

- `s3에서 자체적으로 암호화를 하지 않는다!!!!`
- 서버(s3 버킷)에 업로드될때 지가 알아서 암호화, 클라이언트 암호화 3가지 있다.
-  왜 서버측 암호화 하나? 권한이 없는 파일이 사용되는 일을 막기 위해????

<br>
<br>

보충 필요


----------------
## s3 공동 책임 모델
`AWS 책임` <br>
- s3에 대한 인프라 (내구성 가용성 등)
- 취약성 분석 규정 준수, 검증 등

`고객 책임`
- s3 버저닝 등, 버킷 정책, s3 로깅이나 모니터링 (내선택이니까), s3 클래스 선정 , 데이터 암호화 여부 등

-------------------
## AWS SNOW family

<br>
<br>

높은 수준의 보안장비이며 에지 데이터나, 기업의 데이터 마이그래이션할때 쓰는 포타블 장비

<br>
<br>


`에지 데이터` :  인터넷이 안되는 장비에서 수집한 데이터
바다위의 배, 존나 깊은 채굴장을 엣지 로케이션이라고 하고, 거기서 생성된 데이터를 `에지 데이터`라고 한다

<br>
<br>

`기업 데이터 마이그래이션`
- 스노우콘, 스노우볼 에지, 스노우 모빌(트럭)

<br>

`에지 컴퓨팅 데이터`
- 스노우콘, 스노우볼 에지

<br>
<br>

스노우 패밀리 왜씀? <br>

- 기업의 대용량 데이터를 클라우드로 이전하거나 할때 네트워크로는 엄청 오래 걸림.....
- 네트워크의 연결 안정성, 대역폭, 기업의 높은 네트워크 비용등이 걸림
- 대규모 데이터를 클라우드로 이전하고 마이그래이션해서, 재해 복구나 백업 용도로 쓰기 위함

<br>
<br>
<br>
<br>


`스노우 콘 (작은 베어본 PC 정도 2.1키로그람임)`
- 총 8테라 저장 가능
- 공간이 협소한 환경에서 사용
- 데이터를 옮기면, 장비를 aws에 택배를 붙이거나 AWS datasync를 통해 네트워크에 데이터를 재전송 가능
- 그러니까 걍 꼽기만하면 자동으로 데이터가 aws로 전송됨!!!
- 마이그레이션 최대 크기는 24테라 바이트
- 데이터 에이전트는 미리 설치 되어 있슴 -> 이를 통해 위에 처럼 aws로 자동 전송

<br>
<br>
<br>

`스노우볼 에지 (커다란 서류 가방처럼 생김)`
2가지 종류가 잇음
<br>

- `스토리지 최적화 장비` :  80테라바이트이며 s3 오브젝트 스토리지를 연동할 수 있다, 또한 스노우 콘처럼 스토리지 클러스터링도 가능함
- `컴퓨팅 최적화 장비` : 똑같고, 42테라 바이트임 
- 마이그레이션 최대 크기는 1페타 바이트
- 스토리지 클러스터링이 있어, 총 15개 디바이스를 결합해서 사용할 수 도 있음
- 에지 디바이스들을 연결해, 스노우볼에지로 데이터 쏘면 -> aws 자동 업로드... 그래서 배같은 곳에서는 장기간 대여도 가능 (1~3년동안 저렴한 비용으로 )


<br>
<br>
<br>



`스노우 모빌 (트럭)`
- 엑사바이트.... 100만 테라바이트 저장 가능
- gps 연동,쿨링등 존나 쩜


<br>
<br>
<br>

`스노우볼 패밀리 신청`
- aws콘솔에서 장비 배송 신청
- 스노우볼 장비에 aws 스노우볼 클라이언트 / aws opshub 를 내 서버에 설치
- 스노우볼 장비와 내 서버를 연결해서 데이터 옮김
- 다되면 장비를 다시 aws에 배송
- 그럼 s3 버킷에 데이터가 로드 됨
- 스노우볼 장비에 데이터는 무조건 깨긋하게 완전 삭제됨


<br>
<br>


`저장 데이터` 
- 스노우콘 = 최대 24테라 바이트
- 스노우 에지 = 최대 페타바이트
- 스노우 모빌 = 최대 엑사바이트

<br>
<br>
<br>

-----------------

## AWS storage gateway - 스토리지 게이트 웨이

<br>

어떤 데이터는 온프라 미스에, 어떤데이터는 클라우드에 저장하고 싶을때 사용

<br>

`무슨 역활?`<br>

AWS 데이터와 클라우드 데이터를 연결해 준다
- s3는 자체적인 객체,키, EFS나 EBS는 스토리지 블록 등 각 저장 데이터 형태가 다름 = `저장 방식이 다름`
- 이걸 연결 해 준다라는 의미인듯

<br>

-> `온프라미스에서 발생하는 작업들이 바로 AWS 클라우드로 연결된다라고 생각 하면 됨`

<br>
<br>

`종류 3가지`
- 파일 게이트 웨이
- 볼륨 게이트 웨이
- 테입 게이트 웨이



