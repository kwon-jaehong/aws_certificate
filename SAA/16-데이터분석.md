## AWS athena - 아테나


- S3 버킷에 저장된 데이터 분석에 사용, `서버리스`로서 S3에 바로 사용가능
- `SQL 언어/엔진` 사용
- 아테나에 `스캔된 데이터`에 따라 비용 지불 (테라바이트당 5딸라)
- `ELB 로그, VPC flow 로그, 클라우드트레일 추적, BI, 등`
- 아파치 parquet이나 ORC 데이터 형식 사용하면 더 좋음
  - 아파치 `Parquet과` `ORC(Optimized Row Columnar)`는 둘 다 대규모 데이터 처리를 위한 열 지향 데이터 포맷입니다. 이러한 포맷은 대용량의 데이터를 효율적으로 저장하고 처리하기 위해 설계되었습니다.
  - AWS glue는 CSV -> `열기반 데이터`로 만들어줌
- 또한 `압축데이터(gzip,lz4,zlip 등)를 사용하면` 더 좋음
  - 최대한 128MB보다 큰 파일을 써서, 스캔을 유리하게 하는게 좋음
  - 작은파일로 나누어지면, 아테나 효율이 떨어질 수 있음
![Alt text](../etc/image2/%ED%96%89%EA%B8%B0%EB%B0%98%EC%A0%80%EC%9E%A5.png)



아테나 federated query
- 데이터 커넥터`(람다)`를 사용해서, `다른 AWS 서비스`(RDS,클라우드 와치 로그,다이나모 DB)를 `쿼리` 할 수 있음

![Alt text](../etc/image2/%EC%95%84%ED%85%8C%EB%82%98%ED%8E%98%EB%9F%AC%EB%8D%B0%EC%9D%B4%ED%8B%B0%EB%93%9C%EC%BF%BC%EB%A6%AC.png)


-------------------------------------------------
## AWS Redshift

- 레드쉬프트는, `데이터베이스이자, 분석 엔진임`
- postgreSQL을 사용하지만, OLTP에 적합 하진 않다. -> 1시간마다 DB가 업데이트 됨
- `열기반 쿼리엔진이라, 병렬 쿼리`가 가능
- 아테나랑 비교해보면, 훨씬 더빠른 쿼리 -> `아테나에 없는 index가 있기 떄문임`
- `S3에 대한 임시 쿼리라면 아테나`, 복잡하고 대용량 쿼리는 Redshift가 훨씬 좋음  
  

redshift cluster
- 클러스터를 구성하려면, 노드 크기를 미리 프로비저닝 해야됨
  - `예약 인스턴스` 사용하면 비용 절감
- 클러스터를 구성하면, 두가지 노드가 있음
  - 컴퓨팅 노드
    - 실제 쿼리를 실행하고, 결과를 리더 노드에 전달
  - 리더 노드
    - 쿼리를 계획, 결과를 집계
![Alt text](../etc/image2/%EB%A0%88%EB%93%9C%EC%8B%9C%ED%94%84%ED%8A%B8%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0.png)


redshift snapshots & DR(data recovery) 스냅샷 및 복구
- redshift는 `multi-AZ 모드가 없음`
- 따라서 재해 복구 전략에, `스냅샷을 사용 해야됨`
  - 스냅샷은 S3에 저장 되고, `증분 백업임`
  - 스냅샷은 자동,수동 두 가지 모드로 저장할 수 있음
  - 스냅샷을 이용하면 `다른 리전`에서도 똑같은 클러스터 구성 가능

redshift load data - 레드쉬프트 데이터 주입 방법
- 키네시스 data firehose
- S3
- EC2 `JDBC 드라이버`를 사용해서

JDBC(Java Database Connectivity) 드라이버
- Java 프로그램에서 데이터베이스와의 연결을 관리하고 데이터베이스에 대한 쿼리 및 업데이트 작업을 수행하는 데 사용되는 소프트웨어 컴포넌트입니다.



redshift spectrum - 레드쉬프트 스펙트럼
- `S3`에 있는데이터를 redshift를 사용해 분석하지만, `redshift에 데이터를 로드하지 않음`
- 스펙트럼 기능을 사용하려면, 반드시 쿼리를 시작할수 있는 `redshift 클러스터가 있어야함`

![Alt text](../etc/image2/%EB%A0%88%EB%93%9C%EC%89%AC%ED%94%84%ED%8A%B8%EC%8A%A4%ED%8E%99%ED%8A%B8%EB%9F%BC.png)


Redshift에서 클러스터와 데이터 저장소 사이의 모든 COPY와 UNLOAD `트래픽이 VPC를 통하도록 강제`하는 기능은 무엇입니까?
- Enhanced VPC Routing (향상된 VPC 라우팅)


------------------------------------
## AWS Opensearch (elastic search)
- 프라이머리 키또는 인덱스로 검색하는 Nosql과 달리, `모든 필드를 검색 할 수 있음`
- 인스턴스의 클러스터를 생성해서 운영 (`서버리스 아님`)
- 자체 엘라스틱 언어가 있고, `SQL 아님`
- 키네시스 data firehose, AWs Iot, 클라우드 와치 로그 데이터 주입 가능


-----------------------------------
## AWS EMR(elastic mapreduce)
- EMR은 `실제 디비가 아니라` AWS에서 빅데이터를 작업하고자 할때, 사용하는 `하둡 클러스터`를 이용해 방대한 양의 데이터를 마운트해서 분석함

- 즉 EMR은 하둡클러스터를 구성하고(ec2로) 빅테이터 관점에서 데이터를 분석할 수 있도록 지원하는 하둡 클러스터? 정도라고 생각

- ec2라 오토스케일링이 가능하고, 스팟 인스턴스도 쓸수잇음

- 사용 케이스는 빅데이터 처리, 머신러닝, 웹 인덱싱에 사용 할 수 있음

`하둡 클러스터` : 많은양의 데이터를 분산 저장하는 클러스터
스파크나 Hbase,flink,presto,Spark 등 다양한 도구들이 하둡 클러스터를 이용해서 작업 하는거임


EMR 노드 타입
- 마스터 노드
  - 클러스터 관리,  노드들의 상태 관리 (장기 유지)
- core 노드
  - Task를 실행하고, `데이터를 저장` (장기 유지)
- Task 노드 (옵션)
  - Task 실행만 함
  - 대게, 스팟인스턴스를 사용

--------------------------------------------
## AWS QuickSight

- `서버리스` 머신러닝 방식의 비즈니스 인텔리전스 서비스로 대화형 대시보드를 생성
- SPICE 엔진을 사용 (인메모리 연산 엔진)
- CLS (cloumn-level security)를 사용해, `엑세스 권한이 없는 사용자에게, 일부 데이터 표시 안되게` 할 수 있음
- `그라파나와` 비슷함
- 엔터프라이즈 버젼을 써야, 유저의 `Groups관리` 가능
- IAM과 별개로, 보안 관리 가능
- 특정 사용자 또는 그룹과 `분석 결과 공유 가능함`

<br>
<br>



-----------------------------------------------------

## AWS glue - 글루

- 관리형 추출, 변환 및 로드 서비스 (ETL) 서비스
- `서버리스`
- 데이터 변형, 추가, 필터링 다됨
- 기본은 ETL은 `배치작업 기반임`

- glue data 크롤러를 사용해 -> DB를 크롤링, 기존 AWS서비스 데이터 정제도 가능
- 글루 크롤링 사용하면, glue data catalog가 백그라운드에서 있음

![Alt text](../etc/image2/%EA%B8%80%EB%A3%A8%EC%B9%B4%ED%83%88%EB%A1%9C%EA%B7%B8.png)


- `glue job bookmark`
  - 새 ETL 작업을 실행할때, 재처리 방지( 처음부터 계속 다시 돌릴거 아님 )
- `glue elastic views`
  - SQl을 사용해 여러 DB를 복사하거나, 결합함 (`DB의 View 테이블 역활`)
  - 커스텀 코드 지원 X
- `glue databrew`
  - 사전 빌드된 변환을 사용
- `glue studio`
  - 글루 작업을 GUI에서 제공
- `glue streaming ETL`
  - 글루를 배치작업으로 하는것이 아니라,`실시간 스트리밍으로 작업 가능`
  - 키네시스 data streaming,kafka


-----------------------------------------------------
## AWS Lake Formation

- 데이터 레이크 생성을 도움을 주는 `완전 관리형 서비스`
- 데이터 레이크에서 -> 검색,정제,변환,삽입,중복제거 등
- 위 작업들을 자동화 할 수 있음
- 각 AWS RDS나 S3 블루 브린터를 제공해, 마이그레이션 작업을 도와줌
- 정형, 비정형 다 통합해서 만들수있음
- `glue 위에서 작동함`


![Alt text](../etc/image2/%EB%A0%88%EC%9D%B4%ED%81%AC%ED%8F%AC%EB%A9%94%EC%9D%B4%EC%85%98.png)


이거 왜사용함?
- `중앙화된 권한`으로 데이터 웨어하우스를 관리 가능



------------------------------------------
## AWS Kinesis data Analytics

- 2가지 종류가 있음
  - SQL 애플리케이션 용


![Alt text](../etc/image2/%ED%82%A4%EB%84%A4%EC%8B%9C%EC%8A%A4%EB%B6%84%EC%84%9D%EB%8F%84%EA%B5%ACSQL.png)


  - Apache flink 용
    - 자바,스칼라, SQL로 작성 가능하고, 이 언어로 스트리밍 데이터 처리 및 분석 가능함
    - `AWS MSK(카프카), 키네시스 Data Streams 데이터만` 읽을 수 있음
    - 키네시스 파이어 호스 데이터 `못읽음`




Apache flink
![Alt text](../etc/image2/%ED%94%8C%EB%A7%81%ED%81%AC.png)


-----------------------------------------------
## AWS MSK (managed streaming kafka)

- 키네시스와 같이, `데이터 스트리밍` 서비스임
  - 카프카는 키네시스의 대안(대체품)이 될 수 있다
- AWS에서 카프카를 관리해주는 서비스
- 고가용성을 위해, 최대 3개의 AZ에 `MKS 클러스터` 배포
- `서버리스 모드 지원함` -> 이 모드는 프로비저닝 필요 X


키네시스와 차이점
- 카프카 메세지는 1Mb보다 크게 해도 상관 X
- 카프카는 파티션(토픽)을 `확장`만 할 수 있다 (파티션 제거는 불가능)
- 원한다면, 1년이상 데이터를 보관(EBS에)할 수있음

------------------------------------

## AWS 빅테이터 수집 파이프라인





































