exam_category,exam_type,quiz_id,en_quiz_title,most_vote,correct,en_A,en_B,en_C,en_D,en_E,en_F,en_G,ko_quiz_title,ko_A,ko_B,ko_C,ko_D,ko_E,ko_G,subject,choice_count,ko_F
udemy,CLF-01,1,"The engineering team at a data analytics company has observed that its flagship application functions at its peak performance when the underlying EC2 instances have a CPU utilization of about 50%. The application is built on a fleet of EC2 instances managed under an Auto Scaling group. The workflow requests are handled by an internal Application Load Balancer that routes the requests to the instances.As a solutions architect, what would you recommend so that the application runs near its peak performance state?",C,C,Configure the Auto Scaling group to use simple scaling policy and set the CPU utilization as the target metric with a target value of 50%,Configure the Auto Scaling group to use step scaling policy and set the CPU utilization as the target metric with a target value of 50%,Configure the Auto Scaling group to use target tracking policy and set the CPU utilization as the target metric with a target value of 50%,Configure the Auto Scaling group to use a Cloudwatch alarm triggered on a CPU utilization threshold of 50%,,,,데이터 분석 회사의 엔지니어링 팀은 기본 EC2 인스턴스의 CPU 사용률이 약 50%일 때 주력 애플리케이션이 최고 성능으로 작동하는 것을 관찰했습니다. 이 애플리케이션은 Auto Scaling 그룹에서 관리되는 EC2 인스턴스 플릿을 기반으로 구축됩니다. 워크플로 요청은 요청을 인스턴스로 라우팅하는 내부 Application Load Balancer에서 처리합니다.솔루션 아키텍트로서 애플리케이션이 최고 성능 상태에 가깝게 실행되도록 권장하는 것은 무엇입니까?,단순 조정 정책을 사용하도록 Auto Scaling 그룹을 구성하고 목표 값이 50%인 대상 메트릭으로 CPU 사용률을 설정합니다.,단계 조정 정책을 사용하도록 Auto Scaling 그룹을 구성하고 목표 값이 50%인 목표 지표로 CPU 사용률을 설정합니다.,대상 추적 정책을 사용하도록 Auto Scaling 그룹을 구성하고 목표 값이 50%인 대상 메트릭으로 CPU 사용률을 설정합니다.,CPU 사용률 임계값 50%에서 트리거되는 Cloudwatch 경보를 사용하도록 Auto Scaling 그룹 구성,,,0,,
udemy,CLF-01,2,An Electronic Design Automation (EDA) application produces massive volumes of data that can be divided into two categories. The 'hot data' needs to be both processed and stored quickly in a parallel and distributed fashion. The 'cold data' needs to be kept for reference with quick access for reads and updates at a low cost.Which of the following AWS services is BEST suited to accelerate the aforementioned chip design process?,A,A,Amazon FSx for Lustre,Amazon EMR,Amazon FSx for Windows File Server,AWS Glue,,,,전자 설계 자동화(EDA) 애플리케이션은 두 가지 범주로 나눌 수 있는 방대한 양의 데이터를 생성합니다. '핫 데이터'는 병렬 및 분산 방식으로 빠르게 처리되고 저장되어야 합니다. '콜드 데이터'는 저렴한 비용으로 읽기 및 업데이트를 위한 빠른 액세스와 함께 참조용으로 보관해야 합니다.다음 중 앞서 언급한 칩 설계 프로세스를 가속화하는 데 가장 적합한 AWS 서비스는 무엇입니까?,Lustre용 Amazon FSx,아마존 EMR,Windows 파일 서버용 Amazon FSx,AWS 글루,,,0,,
udemy,CLF-01,3,A news network uses Amazon S3 to aggregate the raw video footage from its reporting teams across the US. The news network has recently expanded into new geographies in Europe and Asia. The technical teams at the overseas branch offices have reported huge delays in uploading large video files to the destination S3 bucket.Which of the following are the MOST cost-effective options to improve the file upload speed into S3? (Select two),CD,CD,Use AWS Global Accelerator for faster file uploads into the destination S3 bucket,Create multiple AWS direct connect connections between the AWS Cloud and branch offices in Europe and Asia. Use the direct connect connections for faster file uploads into S3,Use multipart uploads for faster file uploads into the destination S3 bucket,Use Amazon S3 Transfer Acceleration to enable faster file uploads into the destination S3 bucket,Create multiple site-to-site VPN connections between the AWS Cloud and branch offices in Europe and Asia. Use these VPN connections for faster file uploads into S3,,,뉴스 네트워크는 Amazon S3를 사용하여 미국 전역의 보도 팀에서 원시 비디오 영상을 집계합니다. 뉴스 네트워크는 최근 유럽과 아시아의 새로운 지역으로 확장되었습니다. 해외 지사의 기술 팀은 대용량 비디오 파일을 대상 S3 버킷에 업로드하는 데 엄청난 지연이 발생했다고 보고했습니다.다음 중 S3로의 파일 업로드 속도를 개선하기 위한 가장 비용 효율적인 옵션은 무엇입니까? (2개 선택),대상 S3 버킷에 더 빠르게 파일을 업로드하려면 AWS Global Accelerator를 사용하십시오.,AWS 클라우드와 유럽 및 아시아 지사 간에 여러 AWS Direct Connect 연결을 만듭니다. S3에 더 빠른 파일 업로드를 위해 직접 연결 연결 사용,대상 S3 버킷에 더 빠르게 파일을 업로드하려면 멀티파트 업로드를 사용하십시오.,Amazon S3 Transfer Acceleration을 사용하여 대상 S3 버킷에 더 빠르게 파일을 업로드할 수 있습니다.,AWS 클라우드와 유럽 및 아시아 지사 간에 여러 사이트 간 VPN 연결을 생성합니다. S3에 더 빠르게 파일을 업로드하려면 이 VPN 연결을 사용하십시오.,,0,,
udemy,CLF-01,4,"A gaming company is developing a mobile game that streams score updates to a backend processor and then publishes results on a leaderboard. The company has hired you as an AWS Certified Solutions Architect Associate to design a solution that can handle major traffic spikes, process the mobile game updates in the order of receipt, and store the processed updates in a highly available database. The company wants to minimize the management overhead required to maintain the solution.Which of the following will you recommend to meet these requirements?",A,A,Push score updates to Kinesis Data Streams which uses a Lambda function to process these updates and then store these processed updates in DynamoDB,Push score updates to Kinesis Data Streams which uses a fleet of EC2 instances (with Auto Scaling) to process the updates in Kinesis Data Streams and then store these processed updates in DynamoDB,"Push score updates to an SNS topic, subscribe a Lambda function to this SNS topic to process the updates and then store these processed updates in a SQL database running on Amazon EC2",Push score updates to an SQS queue which uses a fleet of EC2 instances (with Auto Scaling) to process these updates in the SQS queue and then store these processed updates in an RDS MySQL database,,,,"게임 회사는 점수 업데이트를 백엔드 프로세서로 스트리밍한 다음 순위표에 결과를 게시하는 모바일 게임을 개발하고 있습니다. 이 회사는 주요 트래픽 급증을 처리하고, 수신 순서대로 모바일 게임 업데이트를 처리하고, 처리된 업데이트를 고가용성 데이터베이스에 저장할 수 있는 솔루션을 설계하기 위해 귀하를 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용했습니다. 회사는 솔루션을 유지 관리하는 데 필요한 관리 오버헤드를 최소화하려고 합니다.이러한 요구 사항을 충족하기 위해 다음 중 무엇을 권장하시겠습니까?",Lambda 함수를 사용하여 이러한 업데이트를 처리한 다음 처리된 업데이트를 DynamoDB에 저장하는 Kinesis Data Streams로 점수 업데이트를 푸시합니다.,Kinesis Data Streams에서 업데이트를 처리하기 위해 EC2 인스턴스(Auto Scaling 포함) 플릿을 사용하는 Kinesis Data Streams로 점수 업데이트를 푸시한 다음 이러한 처리된 업데이트를 DynamoDB에 저장합니다.,점수 업데이트를 SNS 주제로 푸시하고 이 SNS 주제에 Lambda 함수를 구독하여 업데이트를 처리한 다음 이러한 처리된 업데이트를 Amazon EC2에서 실행되는 SQL 데이터베이스에 저장합니다.,EC2 인스턴스(Auto Scaling 포함) 플릿을 사용하여 SQS 대기열에서 이러한 업데이트를 처리한 다음 처리된 업데이트를 RDS MySQL 데이터베이스에 저장하는 SQS 대기열에 점수 업데이트를 푸시합니다.,,,0,,
udemy,CLF-01,5,"A media company runs a photo-sharing web application that is accessed across three different countries. The application is deployed on several Amazon EC2 instances running behind an Application Load Balancer. With new government regulations, the company has been asked to block access from two countries and allow access only from the home country of the company.Which configuration should be used to meet this changed requirement?",D,D,Configure the security group on the Application Load Balancer,Configure the security group for the EC2 instances,Use Geo Restriction feature of Amazon CloudFront in a VPC,Configure AWS WAF on the Application Load Balancer in a VPC,,,,한 미디어 회사는 서로 다른 3개국에서 액세스할 수 있는 사진 공유 웹 애플리케이션을 운영합니다. 애플리케이션은 Application Load Balancer 뒤에서 실행되는 여러 Amazon EC2 인스턴스에 배포됩니다. 새로운 정부 규정에 따라 회사는 두 국가의 액세스를 차단하고 회사 본국에서만 액세스를 허용하도록 요청받았습니다.이 변경된 요구 사항을 충족하려면 어떤 구성을 사용해야 합니까?,Application Load Balancer에서 보안 그룹 구성,EC2 인스턴스에 대한 보안 그룹 구성,VPC에서 Amazon CloudFront의 지리적 제한 기능 사용,VPC의 Application Load Balancer에서 AWS WAF 구성,,,0,,
udemy,CLF-01,6,"A technology blogger wants to write a review on the comparative pricing for various storage types available on AWS Cloud. The blogger has created a test file of size 1GB with some random data. Next he copies this test file into AWS S3 Standard storage class, provisions an EBS volume (General Purpose SSD (gp2)) with 100GB of provisioned storage and copies the test file into the EBS volume, and lastly copies the test file into an EFS Standard Storage filesystem. At the end of the month, he analyses the bill for costs incurred on the respective storage types for the test file.What is the correct order of the storage charges incurred for the test file on these three storage types?",D,D,Cost of test file storage on S3 Standard < Cost of test file storage on EBS < Cost of test file storage on EFS,Cost of test file storage on EBS < Cost of test file storage on S3 Standard < Cost of test file storage on EFS,Cost of test file storage on EFS < Cost of test file storage on S3 Standard < Cost of test file storage on EBS,Cost of test file storage on S3 Standard < Cost of test file storage on EFS < Cost of test file storage on EBS,,,,한 기술 블로거가 AWS 클라우드에서 사용할 수 있는 다양한 스토리지 유형의 가격 비교에 대한 리뷰를 작성하려고 합니다. 블로거는 임의의 데이터로 1GB 크기의 테스트 파일을 만들었습니다. 다음으로 그는 이 테스트 파일을 AWS S3 Standard 스토리지 클래스에 복사하고 100GB의 프로비저닝된 스토리지로 EBS 볼륨(범용 SSD(gp2))을 프로비저닝하고 테스트 파일을 EBS 볼륨에 복사하고 마지막으로 테스트 파일을 EFS Standard에 복사합니다. 스토리지 파일 시스템. 월말에 그는 테스트 파일의 각 스토리지 유형에서 발생한 비용에 대한 청구서를 분석합니다.이 세 가지 스토리지 유형에서 테스트 파일에 대해 발생하는 스토리지 요금의 올바른 순서는 무엇입니까?,S3 Standard의 테스트 파일 스토리지 비용 < EBS의 테스트 파일 스토리지 비용 < EFS의 테스트 파일 스토리지 비용,EBS의 테스트 파일 스토리지 비용 < S3 Standard의 테스트 파일 스토리지 비용 < EFS의 테스트 파일 스토리지 비용,EFS의 테스트 파일 스토리지 비용 < S3 Standard의 테스트 파일 스토리지 비용 < EBS의 테스트 파일 스토리지 비용,S3 Standard의 테스트 파일 스토리지 비용 < EFS의 테스트 파일 스토리지 비용 < EBS의 테스트 파일 스토리지 비용,,,0,,
udemy,CLF-01,7,"A financial services company recently launched an initiative to improve the security of its AWS resources and it had enabled AWS Shield Advanced across multiple AWS accounts owned by the company. Upon analysis, the company has found that the costs incurred are much higher than expected.Which of the following would you attribute as the underlying reason for the unexpectedly high costs for AWS Shield Advanced service?",D,D,"AWS Shield Advanced is being used for custom servers, that are not part of AWS Cloud, thereby resulting in increased costs","AWS Shield Advanced also covers AWS Shield Standard plan, thereby resulting in increased costs",Savings Plans has not been enabled for the AWS Shield Advanced service across all the AWS accounts,Consolidated billing has not been enabled. All the AWS accounts should fall under a single consolidated billing for the monthly fee to be charged only once,,,,금융 서비스 회사는 최근 AWS 리소스의 보안을 개선하기 위한 이니셔티브를 시작했으며 회사가 소유한 여러 AWS 계정에서 AWS Shield Advanced를 활성화했습니다. 회사는 분석 결과 발생 비용이 예상보다 훨씬 높다는 사실을 발견했습니다.다음 중 AWS Shield Advanced 서비스에 대해 예기치 않게 높은 비용이 발생한 근본적인 이유는 무엇이라고 생각하십니까?,AWS Shield Advanced는 AWS 클라우드의 일부가 아닌 사용자 지정 서버에 사용되므로 비용이 증가합니다.,AWS Shield Advanced는 AWS Shield Standard 플랜도 포함하므로 비용이 증가합니다.,모든 AWS 계정에서 AWS Shield Advanced 서비스에 대해 Savings Plans가 활성화되지 않았습니다.,통합 결제가 활성화되지 않았습니다. 모든 AWS 계정은 월 요금이 한 번만 청구되도록 단일 통합 결제에 속해야 합니다.,,,0,,
udemy,CLF-01,8,"The engineering team at an e-commerce company wants to establish a dedicated, encrypted, low latency, and high throughput connection between its data center and AWS Cloud. The engineering team has set aside sufficient time to account for the operational overhead of establishing this connection.As a solutions architect, which of the following solutions would you recommend to the company?",B,B,Use VPC transit gateway to establish a connection between the data center and AWS Cloud,Use AWS Direct Connect plus VPN to establish a connection between the data center and AWS Cloud,Use site-to-site VPN to establish a connection between the data center and AWS Cloud,Use AWS Direct Connect to establish a connection between the data center and AWS Cloud,,,,전자 상거래 회사의 엔지니어링 팀은 데이터 센터와 AWS 클라우드 간에 지연 시간이 짧고 처리량이 높은 암호화된 전용 연결을 설정하려고 합니다. 엔지니어링 팀은 이 연결 설정의 운영 오버헤드를 설명하기 위해 충분한 시간을 할당했습니다.솔루션 아키텍트로서 다음 중 회사에 추천할 솔루션은 무엇입니까?,VPC 전송 게이트웨이를 사용하여 데이터 센터와 AWS 클라우드 간의 연결 설정,AWS Direct Connect와 VPN을 사용하여 데이터 센터와 AWS 클라우드 간의 연결 설정,사이트 간 VPN을 사용하여 데이터 센터와 AWS 클라우드 간의 연결 설정,AWS Direct Connect를 사용하여 데이터 센터와 AWS 클라우드 간의 연결 설정,,,0,,
udemy,CLF-01,9,"A retail company's dynamic website is hosted using on-premises servers in its data center in the United States. The company is launching its website in Asia, and it wants to optimize the website loading times for new users in Asia. The website's backend must remain in the United States. The website is being launched in a few days, and an immediate solution is needed.What would you recommend?",C,C,Migrate the website to Amazon S3. Use cross-Region replication between AWS Regions in the US and Asia,Leverage a Route 53 geo-proximity routing policy pointing to on-premises servers,Use Amazon CloudFront with a custom origin pointing to the on-premises servers,Use Amazon CloudFront with a custom origin pointing to the DNS record of the website on Route 53,,,,소매 회사의 동적 웹 사이트는 미국 데이터 센터의 온프레미스 서버를 사용하여 호스팅됩니다. 이 회사는 아시아에서 웹 사이트를 시작하고 있으며 아시아의 신규 사용자를 위해 웹 사이트 로드 시간을 최적화하려고 합니다. 웹사이트의 백엔드는 미국에 남아 있어야 합니다. 웹 사이트는 며칠 내에 시작되며 즉각적인 솔루션이 필요합니다.무엇을 추천하나요?,웹 사이트를 Amazon S3로 마이그레이션합니다. 미국과 아시아의 AWS 리전 간 교차 리전 복제 사용,온프레미스 서버를 가리키는 Route 53 지리적 근접성 라우팅 정책 활용,온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 사용,Route 53에 있는 웹 사이트의 DNS 레코드를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 사용,,,0,,
udemy,CLF-01,10,"The IT department at a consulting firm is conducting a training workshop for new developers. As part of an evaluation exercise on Amazon S3, the new developers were asked to identify the invalid storage class lifecycle transitions for objects stored on S3.Can you spot the INVALID lifecycle transitions from the options below? (Select two)",CE,CE,S3 Standard => S3 Intelligent-Tiering,S3 Standard-IA => S3 Intelligent-Tiering,S3 One Zone-IA => S3 Standard-IA,S3 Standard-IA => S3 One Zone-IA,S3 Intelligent-Tiering => S3 Standard,,,컨설팅 회사의 IT 부서에서 신입 개발자를 위한 교육 워크숍을 진행하고 있습니다. Amazon S3에 대한 평가 연습의 일환으로 새로운 개발자는 S3에 저장된 객체에 대한 유효하지 않은 스토리지 클래스 수명 주기 전환을 식별하라는 요청을 받았습니다.아래 옵션에서 잘못된 수명 주기 전환을 찾을 수 있습니까? (2개 선택),S3 Standard => S3 Intelligent-Tiering,S3 Standard-IA => S3 Intelligent-Tiering,S3 One Zone-IA => S3 스탠다드-IA,S3 Standard-IA => S3 One Zone-IA,S3 Intelligent-Tiering => S3 Standard,,0,,
udemy,CLF-01,11,A leading video streaming service delivers billions of hours of content from Amazon S3 to customers around the world. Amazon S3 also serves as the data lake for its big data analytics solution. The data lake has a staging zone where intermediary query results are kept only for 24 hours. These results are also heavily referenced by other parts of the analytics pipeline.Which of the following is the MOST cost-effective strategy for storing this intermediary query data?,A,A,Store the intermediary query results in S3 Standard storage class,Store the intermediary query results in S3 Standard-Infrequent Access storage class,Store the intermediary query results in S3 One Zone-Infrequent Access storage class,Store the intermediary query results in S3 Glacier Instant Retrieval storage class,,,,선도적인 비디오 스트리밍 서비스는 Amazon S3에서 전 세계 고객에게 수십억 시간 분량의 콘텐츠를 제공합니다. Amazon S3는 빅 데이터 분석 솔루션의 데이터 레이크 역할도 합니다. 데이터 레이크에는 중간 쿼리 결과가 24시간 동안만 보관되는 스테이징 영역이 있습니다. 이러한 결과는 분석 파이프라인의 다른 부분에서도 많이 참조됩니다.다음 중 이 중간 쿼리 데이터를 저장하기 위한 가장 비용 효율적인 전략은 무엇입니까?,중간 쿼리 결과를 S3 Standard 스토리지 클래스에 저장,중간 쿼리 결과를 S3 Standard-Infrequent Access 스토리지 클래스에 저장,중간 쿼리 결과를 S3 One Zone-Infrequent Access 스토리지 클래스에 저장,중간 쿼리 결과를 S3 Glacier Instant Retrieval 스토리지 클래스에 저장,,,0,,
udemy,CLF-01,12,A gaming company is looking at improving the availability and performance of its global flagship application which utilizes UDP protocol and needs to support fast regional failover in case an AWS Region goes down. The company wants to continue using its own custom DNS service.Which of the following AWS services represents the best solution for this use-case?,D,D,Amazon Route 53,AWS Elastic Load Balancing (ELB),Amazon CloudFront,AWS Global Accelerator,,,,한 게임 회사는 UDP 프로토콜을 활용하고 AWS 리전이 다운될 경우 빠른 지역 장애 조치를 지원해야 하는 글로벌 플래그십 애플리케이션의 가용성과 성능을 개선하는 방법을 모색하고 있습니다. 회사는 자체 사용자 지정 DNS 서비스를 계속 사용하려고 합니다.다음 AWS 서비스 중 이 사용 사례에 가장 적합한 솔루션은 무엇입니까?,아마존 루트 53,AWS 엘라스틱 로드 밸런싱(ELB),아마존 클라우드프론트,AWS 글로벌 액셀러레이터,,,0,,
udemy,CLF-01,13,"A company uses DynamoDB as a data store for various kinds of customer data, such as user profiles, user events, clicks, and visited links. Some of these use-cases require a high request rate (millions of requests per second), low predictable latency, and reliability. The company now wants to add a caching layer to support high read volumes.As a solutions architect, which of the following AWS services would you recommend as a caching layer for this use-case? (Select two)",CD,CD,Elasticsearch,RDS,DynamoDB Accelerator (DAX),ElastiCache,Redshift,,,"회사는 DynamoDB를 사용자 프로필, 사용자 이벤트, 클릭 및 방문한 링크와 같은 다양한 종류의 고객 데이터에 대한 데이터 저장소로 사용합니다. 이러한 사용 사례 중 일부는 높은 요청 속도(초당 수백만 건의 요청), 예측 가능한 낮은 대기 시간 및 안정성이 필요합니다. 회사는 이제 높은 읽기 볼륨을 지원하기 위해 캐싱 계층을 추가하려고 합니다.솔루션 아키텍트로서 다음 중 이 사용 사례의 캐싱 계층으로 추천할 AWS 서비스는 무엇입니까? (2개 선택)",엘라스틱서치,RDS,DynamoDB 액셀러레이터(DAX),ElastiCache,적색편이,,0,,
udemy,CLF-01,14,"The flagship application for a gaming company connects to an Amazon Aurora database and the entire technology stack is currently deployed in the United States. Now, the company has plans to expand to Europe and Asia for its operations. It needs the games table to be accessible globally but needs the users and games_played tables to be regional only.How would you implement this with minimal application refactoring?",C,C,Use an Amazon Aurora Global Database for the games table and use DynamoDB tables for the users and games_played tables,Use a DynamoDB global table for the games table and use Amazon Aurora for the users and games_played tables,Use an Amazon Aurora Global Database for the games table and use Amazon Aurora for the users and games_played tables,Use a DynamoDB global table for the games table and use DynamoDB tables for the users and games_played tables,,,,게임 회사의 주력 애플리케이션은 Amazon Aurora 데이터베이스에 연결되며 전체 기술 스택은 현재 미국에 배포되어 있습니다. 이제 회사는 유럽과 아시아로 사업을 확장할 계획입니다. games전역적으로 액세스할 수 있는 테이블이 필요 하지만 지역 전용 테이블이 users필요 합니다.games_played최소한의 애플리케이션 리팩토링으로 어떻게 구현하시겠습니까?,테이블에는 Amazon Aurora 글로벌 데이터베이스를 사용하고 games및 테이블에는 DynamoDB 테이블을 사용 users하십시오 games_played.,테이블에는 DynamoDB 전역 테이블을 사용하고 및 테이블 games에는 Amazon Aurora를 사용하십시오 .usersgames_played,테이블에는 Amazon Aurora 글로벌 데이터베이스를 사용하고 및 테이블 games에는 Amazon Aurora를 사용하십시오.usersgames_played,테이블에 DynamoDB 전역 테이블을 사용하고 및 테이블 games에 DynamoDB 테이블을 사용합니다.usersgames_played,,,0,,
udemy,CLF-01,15,A major bank is using SQS to migrate several core banking applications to the cloud to ensure high availability and cost efficiency while simplifying administrative complexity and overhead. The development team at the bank expects a peak rate of about 1000 messages per second to be processed via SQS. It is important that the messages are processed in order.Which of the following options can be used to implement this system?,A,A,Use Amazon SQS FIFO queue in batch mode of 4 messages per operation to process the messages at the peak rate,Use Amazon SQS FIFO queue to process the messages,Use Amazon SQS FIFO queue in batch mode of 2 messages per operation to process the messages at the peak rate,Use Amazon SQS standard queue to process the messages,,,,주요 은행은 관리 복잡성과 오버헤드를 단순화하는 동시에 고가용성과 비용 효율성을 보장하기 위해 SQS를 사용하여 여러 핵심 뱅킹 애플리케이션을 클라우드로 마이그레이션하고 있습니다. 은행의 개발 팀은 SQS를 통해 초당 약 1000개의 메시지가 처리될 것으로 예상합니다. 메시지가 순서대로 처리되는 것이 중요합니다.다음 중 이 시스템을 구현하는 데 사용할 수 있는 옵션은 무엇입니까?,작업당 4개 메시지의 배치 모드에서 Amazon SQS FIFO 대기열을 사용하여 최고 속도로 메시지 처리,Amazon SQS FIFO 대기열을 사용하여 메시지 처리,작업당 2개 메시지의 배치 모드에서 Amazon SQS FIFO 대기열을 사용하여 최고 속도로 메시지 처리,Amazon SQS 표준 대기열을 사용하여 메시지 처리,,,0,,
udemy,CLF-01,16,An ivy-league university is assisting NASA to find potential landing sites for exploration vehicles of unmanned missions to our neighboring planets. The university uses High Performance Computing (HPC) driven application architecture to identify these landing sites.Which of the following EC2 instance topologies should this application be deployed on?,D,D,The EC2 instances should be deployed in a partition placement group so that distributed workloads can be handled effectively,The EC2 instances should be deployed in a spread placement group so that there are no correlated failures,The EC2 instances should be deployed in an Auto Scaling group so that application meets high availability requirements,The EC2 instances should be deployed in a cluster placement group so that the underlying workload can benefit from low network latency and high network throughput,,,,아이비 리그 대학은 NASA가 이웃 행성에 무인 임무를 수행할 탐사 차량을 위한 잠재적 착륙 지점을 찾도록 지원하고 있습니다. 이 대학은 HPC(고성능 컴퓨팅) 기반 애플리케이션 아키텍처를 사용하여 이러한 랜딩 사이트를 식별합니다.다음 중 이 애플리케이션을 배포해야 하는 EC2 인스턴스 토폴로지는 무엇입니까?,분산된 워크로드를 효과적으로 처리할 수 있도록 EC2 인스턴스를 파티션 배치 그룹에 배포해야 합니다.,상관 장애가 발생하지 않도록 EC2 인스턴스를 분산 배치 그룹에 배포해야 합니다.,애플리케이션이 고가용성 요구 사항을 충족하도록 EC2 인스턴스를 Auto Scaling 그룹에 배포해야 합니다.,EC2 인스턴스는 기본 워크로드가 낮은 네트워크 지연 시간과 높은 네트워크 처리량의 이점을 누릴 수 있도록 클러스터 배치 그룹에 배포되어야 합니다.,,,0,,
udemy,CLF-01,17,"A financial services company uses Amazon GuardDuty for analyzing its AWS account metadata to meet the compliance guidelines. However, the company has now decided to stop using GuardDuty service. All the existing findings have to be deleted and cannot persist anywhere on AWS Cloud.Which of the following techniques will help the company meet this requirement?",C,C,De-register the service under services tab,Raise a service request with Amazon to completely delete the data from all their backups,Disable the service in the general settings,Suspend the service in the general settings,,,,금융 서비스 회사는 규정 준수 지침을 충족하기 위해 Amazon GuardDuty를 사용하여 AWS 계정 메타데이터를 분석합니다. 그러나 회사는 이제 GuardDuty 서비스 사용을 중단하기로 결정했습니다. 모든 기존 결과를 삭제해야 하며 AWS 클라우드의 어디에도 유지할 수 없습니다.다음 중 회사가 이 요구 사항을 충족하는 데 도움이 되는 기술은 무엇입니까?,서비스 탭에서 서비스 등록 취소,모든 백업에서 데이터를 완전히 삭제하려면 Amazon에 서비스 요청을 제출하십시오.,일반 설정에서 서비스 비활성화,일반 설정에서 서비스 일시 중단,,,0,,
udemy,CLF-01,18,A logistics company is building a multi-tier application to track the location of its trucks during peak operating hours. The company wants these data points to be accessible in real-time in its analytics platform via a REST API. The company has hired you as an AWS Certified Solutions Architect Associate to build a multi-tier solution to store and retrieve this location data for analysis.Which of the following options addresses the given use case?,D,D,Leverage Amazon Athena with S3,Leverage Amazon API Gateway with AWS Lambda,Leverage QuickSight with Redshift,Leverage Amazon API Gateway with Kinesis Data Analytics,,,,물류 회사는 피크 운영 시간 동안 트럭의 위치를 ​​추적하기 위해 다중 계층 애플리케이션을 구축하고 있습니다. 이 회사는 REST API를 통해 분석 플랫폼에서 이러한 데이터 포인트에 실시간으로 액세스할 수 있기를 원합니다. 이 회사는 분석을 위해 이 위치 데이터를 저장하고 검색하는 다중 계층 솔루션을 구축하기 위해 귀하를 AWS 공인 솔루션 설계자 어소시에이트로 고용했습니다.다음 중 주어진 사용 사례를 다루는 옵션은 무엇입니까?,S3로 Amazon Athena 활용,AWS Lambda와 함께 Amazon API Gateway 활용,Redshift와 함께 QuickSight 활용,Kinesis Data Analytics와 함께 Amazon API Gateway 활용,,,0,,
udemy,CLF-01,19,"The sourcing team at the US headquarters of a global e-commerce company is preparing a spreadsheet of the new product catalog. The spreadsheet is saved on an EFS file system created in us-east-1 region. The sourcing team counterparts from other AWS regions such as Asia Pacific and Europe also want to collaborate on this spreadsheet.As a solutions architect, what is your recommendation to enable this collaboration with the LEAST amount of operational overhead?",D,D,The spreadsheet data will have to be moved into an RDS MySQL database which can then be accessed from any AWS region,The spreadsheet will have to be copied into EFS file systems of other AWS regions as EFS is a regional service and it does not allow access from other AWS regions,The spreadsheet will have to be copied in Amazon S3 which can then be accessed from any AWS region,The spreadsheet on the EFS file system can be accessed in other AWS regions by using an inter-region VPC peering connection,,,,글로벌 전자상거래 기업의 미국 본사 소싱팀이 신제품 카탈로그 스프레드시트를 준비하고 있다. 스프레드시트는 us-east-1 지역에서 생성된 EFS 파일 시스템에 저장됩니다. 아시아 태평양 및 유럽과 같은 다른 AWS 지역의 소싱 팀 담당자도 이 스프레드시트에서 협업하기를 원합니다.솔루션 아키텍트로서 최소한의 운영 오버헤드로 이러한 협업을 가능하게 하기 위한 권장 사항은 무엇입니까?,스프레드시트 데이터는 모든 AWS 리전에서 액세스할 수 있는 RDS MySQL 데이터베이스로 이동해야 합니다.,EFS는 지역 서비스이며 다른 AWS 지역에서 액세스를 허용하지 않으므로 스프레드시트를 다른 AWS 지역의 EFS 파일 시스템으로 복사해야 합니다.,스프레드시트는 모든 AWS 리전에서 액세스할 수 있는 Amazon S3에 복사해야 합니다.,EFS 파일 시스템의 스프레드시트는 리전 간 VPC 피어링 연결을 사용하여 다른 AWS 리전에서 액세스할 수 있습니다.,,,0,,
udemy,CLF-01,20,"A telecom company operates thousands of hardware devices like switches, routers, cables, etc. The real-time status data for these devices must be fed into a communications application for notifications. Simultaneously, another analytics application needs to read the same real-time status data and analyze all the connecting lines that may go down because of any device failures.As a Solutions Architect, which of the following solutions would you suggest, so that both the applications can consume the real-time status data concurrently?",D,D,Amazon Simple Notification Service (SNS),Amazon Simple Queue Service (SQS) with Amazon Simple Email Service (Amazon SES),Amazon Simple Queue Service (SQS) with Amazon Simple Notification Service (SNS),Amazon Kinesis Data Streams,,,,"통신 회사는 스위치, 라우터, 케이블 등과 같은 수천 개의 하드웨어 장치를 운영합니다. 이러한 장치의 실시간 상태 데이터는 알림을 위해 통신 응용 프로그램에 입력되어야 합니다. 동시에 다른 분석 애플리케이션은 동일한 실시간 상태 데이터를 읽고 장치 오류로 인해 중단될 수 있는 모든 연결 라인을 분석해야 합니다.솔루션 아키텍트로서 두 애플리케이션이 실시간 상태 데이터를 동시에 사용할 수 있도록 다음 중 어떤 솔루션을 제안하시겠습니까?",Amazon 단순 알림 서비스(SNS),Amazon Simple Email Service(Amazon SES)를 사용한 Amazon Simple Queue Service(SQS),Amazon Simple Notification Service(SNS)를 사용하는 Amazon Simple Queue Service(SQS),Amazon Kinesis 데이터 스트림,,,0,,
udemy,CLF-01,21,"The engineering team at an in-home fitness company is evaluating multiple in-memory data stores with the ability to power its on-demand, live leaderboard. The company's leaderboard requires high availability, low latency, and real-time processing to deliver customizable user data for the community of users working out together virtually from the comfort of their home.As a solutions architect, which of the following solutions would you recommend? (Select two)",AB,AB,"Power the on-demand, live leaderboard using ElastiCache Redis as it meets the in-memory, high availability, low latency requirements","Power the on-demand, live leaderboard using DynamoDB with DynamoDB Accelerator (DAX) as it meets the in-memory, high availability, low latency requirements","Power the on-demand, live leaderboard using AWS Neptune as it meets the in-memory, high availability, low latency requirements","Power the on-demand, live leaderboard using RDS Aurora as it meets the in-memory, high availability, low latency requirements","Power the on-demand, live leaderboard using DynamoDB as it meets the in-memory, high availability, low latency requirements",,,"가정 내 피트니스 회사의 엔지니어링 팀은 온디맨드 라이브 순위표에 전원을 공급할 수 있는 기능으로 여러 인메모리 데이터 저장소를 평가하고 있습니다. 집에서 편안하게 가상으로 함께 작업하는 사용자 커뮤니티를 위해 사용자 지정 가능한 사용자 데이터를 제공하기 위해 회사의 순위표에는 고가용성, 낮은 대기 시간 및 실시간 처리가 필요합니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 추천하시겠습니까? (2개 선택)","인메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 ElastiCache Redis를 사용하여 온디맨드 라이브 리더보드를 구동합니다.","인메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 DynamoDB Accelerator(DAX)와 함께 DynamoDB를 사용하여 온디맨드 라이브 순위표를 강화하십시오.","인메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 AWS Neptune을 사용하여 온디맨드 라이브 순위표를 강화하십시오.","인메모리, 고가용성, 낮은 대기 시간 요구 사항을 충족하는 RDS Aurora를 사용하여 온디맨드 라이브 리더보드를 강화하십시오.","인메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 DynamoDB를 사용하여 온디맨드 라이브 순위표를 강화하십시오.",,0,,
udemy,CLF-01,22,"A company manages a multi-tier social media application that runs on EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. As a solutions architect, you have been tasked to make the application more resilient to periodic spikes in request rates.Which of the following solutions would you recommend for the given use-case? (Select two)",BE,BE,Use AWS Direct Connect,Use CloudFront distribution in front of the Application Load Balancer,Use AWS Shield,Use AWS Global Accelerator,Use Aurora Replica,,,회사는 Application Load Balancer 뒤의 EC2 인스턴스에서 실행되는 다중 계층 소셜 미디어 애플리케이션을 관리합니다. 인스턴스는 여러 가용 영역의 EC2 Auto Scaling 그룹에서 실행되며 Amazon Aurora 데이터베이스를 사용합니다. 솔루션 아키텍트로서 귀하는 주기적으로 급증하는 요청 비율에 대해 애플리케이션의 복원력을 높이는 임무를 받았습니다.다음 중 주어진 사용 사례에 대해 권장하는 솔루션은 무엇입니까? (2개 선택),AWS Direct Connect 사용,Application Load Balancer 앞에서 CloudFront 배포 사용,AWS 실드 사용,AWS 글로벌 액셀러레이터 사용,Aurora 복제본 사용,,0,,
udemy,CLF-01,23,"A retail company uses Amazon EC2 instances, API Gateway, Amazon RDS, Elastic Load Balancer and CloudFront services. To improve the security of these services, the Risk Advisory group has suggested a feasibility check for using the Amazon GuardDuty service.Which of the following would you identify as data sources supported by GuardDuty?",B,B,"VPC Flow Logs, API Gateway logs, S3 access logs","VPC Flow Logs, DNS logs, CloudTrail events","CloudFront logs, API Gateway logs, CloudTrail events","ELB logs, DNS logs, CloudTrail events",,,,"소매 회사는 Amazon EC2 인스턴스, API 게이트웨이, Amazon RDS, Elastic Load Balancer 및 CloudFront 서비스를 사용합니다. 이러한 서비스의 보안을 개선하기 위해 Risk Advisory 그룹은 Amazon GuardDuty 서비스 사용에 대한 타당성 검사를 제안했습니다.다음 중 GuardDuty에서 지원하는 데이터 원본은 무엇입니까?","VPC 흐름 로그, API 게이트웨이 로그, S3 액세스 로그","VPC 흐름 로그, DNS 로그, CloudTrail 이벤트","CloudFront 로그, API 게이트웨이 로그, CloudTrail 이벤트","ELB 로그, DNS 로그, CloudTrail 이벤트",,,0,,
udemy,CLF-01,24,"A social photo-sharing company uses Amazon S3 to store the images uploaded by the users. These images are kept encrypted in S3 by using AWS-KMS and the company manages its own Customer Master Key (CMK) for encryption. A member of the DevOps team accidentally deleted the CMK a day ago, thereby rendering the user's photo data unrecoverable. You have been contacted by the company to consult them on possible solutions to this crisis.As a solutions architect, which of the following steps would you recommend to solve this issue?",B,B,The CMK can be recovered by the AWS root account user,"As the CMK was deleted a day ago, it must be in the 'pending deletion' status and hence you can just cancel the CMK deletion and recover the key",Contact AWS support to retrieve the CMK from their backup,The company should issue a notification on its web application informing the users about the loss of their data,,,,소셜 사진 공유 회사는 Amazon S3를 사용하여 사용자가 업로드한 이미지를 저장합니다. 이러한 이미지는 AWS-KMS를 사용하여 S3에서 암호화된 상태로 유지되며 회사는 암호화를 위해 자체 고객 마스터 키(CMK)를 관리합니다. DevOps 팀원이 하루 전에 실수로 CMK를 삭제하여 사용자의 사진 데이터를 복구할 수 없게 만들었습니다. 귀하는 이 위기에 대한 가능한 해결책에 대해 상담하기 위해 회사로부터 연락을 받았습니다.솔루션 설계자로서 이 문제를 해결하기 위해 다음 중 어떤 단계를 권장하시겠습니까?,CMK는 AWS 루트 계정 사용자가 복구할 수 있습니다.,CMK는 하루 전에 삭제되었으므로 '삭제 대기 중' 상태여야 하므로 CMK 삭제를 취소하고 키를 복구하면 됩니다.,백업에서 CMK를 검색하려면 AWS 지원에 문의하십시오.,회사는 사용자에게 데이터 손실에 대해 알리는 웹 애플리케이션에 대한 알림을 발행해야 합니다.,,,0,,
udemy,CLF-01,25,A company runs a data processing workflow that takes about 60 minutes to complete. The workflow can withstand disruptions and it can be started and stopped multiple times.Which is the most cost-effective solution to build a solution for the workflow?,B,B,Use AWS Lambda function to run the workflow processes,Use EC2 spot instances to run the workflow processes,Use EC2 reserved instances to run the workflow processes,Use EC2 on-demand instances to run the workflow processes,,,,회사에서 완료하는 데 약 60분이 소요되는 데이터 처리 워크플로를 실행합니다. 워크플로는 중단을 견딜 수 있으며 여러 번 시작하고 중지할 수 있습니다.워크플로를 위한 솔루션을 구축하는 데 가장 비용 효율적인 솔루션은 무엇입니까?,AWS Lambda 함수를 사용하여 워크플로 프로세스 실행,EC2 스팟 인스턴스를 사용하여 워크플로 프로세스 실행,EC2 예약 인스턴스를 사용하여 워크플로 프로세스 실행,EC2 온디맨드 인스턴스를 사용하여 워크플로 프로세스 실행,,,0,,
udemy,CLF-01,26,A healthcare company uses its on-premises infrastructure to run legacy applications that require specialized customizations to the underlying Oracle database as well as its host operating system (OS). The company also wants to improve the availability of the Oracle database layer. The company has hired you as an AWS Certified Solutions Architect Associate to build a solution on AWS that meets these requirements while minimizing the underlying infrastructure maintenance effort.Which of the following options represents the best solution for this use case?,C,C,Leverage cross AZ read-replica configuration of RDS for Oracle that allows the database administrators to access and customize the database environment and the underlying operating system,Deploy the Oracle database layer on multiple EC2 instances spread across two Availability Zones (AZ). This deployment configuration guarantees high availability and also allows the database administrators to access and customize the database environment and the underlying operating system,Leverage multi-AZ configuration of RDS Custom for Oracle that allows the database administrators to access and customize the database environment and the underlying operating system,Leverage multi-AZ configuration of RDS for Oracle that allows the database administrators to access and customize the database environment and the underlying operating system,,,,의료 회사는 온프레미스 인프라를 사용하여 기본 Oracle 데이터베이스 및 호스트 OS(운영 체제)에 대한 특수 사용자 지정이 필요한 레거시 애플리케이션을 실행합니다. 이 회사는 또한 Oracle 데이터베이스 계층의 가용성을 개선하기를 원합니다. 회사는 기본 인프라 유지 관리 노력을 최소화하면서 이러한 요구 사항을 충족하는 솔루션을 AWS에서 구축하기 위해 귀사를 AWS 공인 솔루션 아키텍트 어소시에이트로 고용했습니다.다음 옵션 중 이 사용 사례에 가장 적합한 솔루션은 무엇입니까?,데이터베이스 관리자가 데이터베이스 환경 및 기본 운영 체제에 액세스하고 사용자 지정할 수 있도록 하는 RDS for Oracle의 교차 AZ 읽기 복제본 구성을 활용합니다.,두 AZ(가용 영역)에 분산된 여러 EC2 인스턴스에 Oracle 데이터베이스 계층을 배포합니다. 이 배포 구성은 고가용성을 보장하고 데이터베이스 관리자가 데이터베이스 환경 및 기본 운영 체제에 액세스하고 사용자 지정할 수 있도록 합니다.,데이터베이스 관리자가 데이터베이스 환경 및 기본 운영 체제에 액세스하고 사용자 지정할 수 있는 RDS Custom for Oracle의 다중 AZ 구성을 활용합니다.,데이터베이스 관리자가 데이터베이스 환경 및 기본 운영 체제에 액세스하고 사용자 지정할 수 있도록 Oracle용 RDS의 다중 AZ 구성을 활용합니다.,,,0,,
udemy,CLF-01,27,"One of the biggest football leagues in Europe has granted the distribution rights for live streaming its matches in the US to a silicon valley based streaming services company. As per the terms of distribution, the company must make sure that only users from the US are able to live stream the matches on their platform. Users from other countries in the world must be denied access to these live-streamed matches.Which of the following options would allow the company to enforce these streaming restrictions? (Select two)",BE,BE,Use Route 53 based failover routing policy to restrict distribution of content to only the locations in which you have distribution rights,Use Route 53 based geolocation routing policy to restrict distribution of content to only the locations in which you have distribution rights,Use Route 53 based latency routing policy to restrict distribution of content to only the locations in which you have distribution rights,Use Route 53 based weighted routing policy to restrict distribution of content to only the locations in which you have distribution rights,Use georestriction to prevent users in specific geographic locations from accessing content that you're distributing through a CloudFront web distribution,,,유럽에서 가장 큰 축구 리그 중 하나가 실리콘 밸리에 기반을 둔 스트리밍 서비스 회사에 미국에서 경기를 라이브 스트리밍할 수 있는 배포 권한을 부여했습니다. 배포 조건에 따라 회사는 미국 사용자만 플랫폼에서 경기를 라이브 스트리밍할 수 있도록 해야 합니다. 전 세계 다른 국가의 사용자는 이러한 라이브 스트리밍 경기에 대한 액세스를 거부해야 합니다.다음 중 회사에서 이러한 스트리밍 제한을 시행할 수 있는 옵션은 무엇입니까? (2개 선택),Route 53 기반 장애 조치 라우팅 정책을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한합니다.,Route 53 기반 지리적 위치 라우팅 정책을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한합니다.,Route 53 기반 지연 시간 라우팅 정책을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한합니다.,Route 53 기반 가중치 라우팅 정책을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한합니다.,지역 제한을 사용하여 특정 지리적 위치에 있는 사용자가 CloudFront 웹 배포를 통해 배포하는 콘텐츠에 액세스하지 못하도록 방지,,0,,
udemy,CLF-01,28,A company is in the process of migrating its on-premises SMB file shares to AWS so the company can get out of the business of managing multiple file servers across dozens of offices. The company has 200TB of data in its file servers. The existing on-premises applications and native Windows workloads should continue to have low latency access to this data without any disruptions after the migration. The company also wants any new applications deployed on AWS to have access to this migrated data.Which of the following is the best solution to meet this requirement?,A,A,"Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon FSx for Windows File Server. The applications deployed on AWS can access this data directly from Amazon FSx in AWS","Use Amazon Storage Gateway’s File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon FSx for Windows File Server. The applications deployed on AWS can access this data directly from Amazon FSx in AWS","Use Amazon Storage Gateway’s File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon S3. The applications deployed on AWS can access this data directly from Amazon S3","Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon EFS. The applications deployed on AWS can access this data directly from Amazon EFS",,,,회사는 수십 개의 사무실에 걸쳐 여러 파일 서버를 관리하는 업무에서 벗어날 수 있도록 온프레미스 SMB 파일 공유를 AWS로 마이그레이션하는 과정에 있습니다. 이 회사는 파일 서버에 200TB의 데이터를 보유하고 있습니다. 기존 온프레미스 애플리케이션 및 기본 Windows 워크로드는 마이그레이션 후 중단 없이 이 데이터에 대한 짧은 대기 시간 액세스를 계속 유지해야 합니다. 또한 이 회사는 AWS에 배포된 모든 새 애플리케이션이 이 마이그레이션된 데이터에 액세스할 수 있기를 원합니다.다음 중 이 요구 사항을 충족하는 가장 좋은 솔루션은 무엇입니까?,Amazon FSx File Gateway를 사용하여 Amazon FSx for Windows File Server에서 완전히 관리되는 파일 공유에 대한 지연 시간이 짧은 온프레미스 액세스를 제공합니다. AWS에 배포된 애플리케이션은 AWS의 Amazon FSx에서 직접 이 데이터에 액세스할 수 있습니다.,Amazon Storage Gateway의 파일 게이트웨이를 사용하여 Amazon FSx for Windows File Server에서 완전히 관리되는 파일 공유에 대한 지연 시간이 짧은 온프레미스 액세스를 제공합니다. AWS에 배포된 애플리케이션은 AWS의 Amazon FSx에서 직접 이 데이터에 액세스할 수 있습니다.,Amazon Storage Gateway의 파일 게이트웨이를 사용하여 지연 시간이 짧은 온프레미스 액세스를 Amazon S3의 완전 관리형 파일 공유에 제공하십시오. AWS에 배포된 애플리케이션은 Amazon S3에서 직접 이 데이터에 액세스할 수 있습니다.,Amazon FSx File Gateway를 사용하여 지연 시간이 짧은 온프레미스 액세스를 Amazon EFS에서 완전히 관리되는 파일 공유에 제공하십시오. AWS에 배포된 애플리케이션은 Amazon EFS에서 직접 이 데이터에 액세스할 수 있습니다.,,,0,,
udemy,CLF-01,29,The product team at a startup has figured out a market need to support both stateful and stateless client-server communications via the APIs developed using its platform. You have been hired by the startup as a solutions architect to build a solution to fulfill this market need using AWS API Gateway.Which of the following would you identify as correct?,C,C,"API Gateway creates RESTful APIs that enable stateful client-server communication and API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full-duplex communication between client and server","API Gateway creates RESTful APIs that enable stateful client-server communication and API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server","API Gateway creates RESTful APIs that enable stateless client-server communication and API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server","API Gateway creates RESTful APIs that enable stateless client-server communication and API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full-duplex communication between client and server",,,,신생 기업의 제품 팀은 플랫폼을 사용하여 개발된 API를 통해 상태 저장 및 상태 비저장 클라이언트-서버 통신을 모두 지원해야 하는 시장 요구 사항을 파악했습니다. 귀하는 AWS API Gateway를 사용하여 이러한 시장 요구 사항을 충족하는 솔루션을 구축하기 위해 스타트업에서 솔루션 설계자로 고용되었습니다.다음 중 올바른 것으로 식별할 수 있는 것은 무엇입니까?,API Gateway는 상태 저장 클라이언트-서버 통신을 가능하게 하는 RESTful API를 생성하고 API Gateway는 클라이언트와 서버 간의 상태 비저장 전이중 통신을 가능하게 하는 WebSocket 프로토콜을 준수하는 WebSocket API도 생성합니다.,API Gateway는 상태 저장 클라이언트-서버 통신을 지원하는 RESTful API를 생성하고 API Gateway는 클라이언트와 서버 간의 상태 저장 전이중 통신을 지원하는 WebSocket 프로토콜을 준수하는 WebSocket API도 생성합니다.,API 게이트웨이는 상태 비저장 클라이언트-서버 통신을 가능하게 하는 RESTful API를 생성하고 API 게이트웨이는 클라이언트와 서버 간의 상태 저장 전이중 통신을 가능하게 하는 WebSocket 프로토콜을 준수하는 WebSocket API도 생성합니다.,API Gateway는 상태 비저장 클라이언트-서버 통신을 지원하는 RESTful API를 생성하고 API Gateway는 클라이언트와 서버 간의 상태 비저장 전이중 통신을 지원하는 WebSocket 프로토콜을 준수하는 WebSocket API도 생성합니다.,,,0,,
udemy,CLF-01,30,"A retail company has developed a REST API which is deployed in an Auto Scaling group behind an Application Load Balancer. The API stores the user data in DynamoDB and any static content, such as images, are served via S3. On analyzing the usage trends, it is found that 90% of the read requests are for commonly accessed data across all users.As a Solutions Architect, which of the following would you suggest as the MOST efficient solution to improve the application performance?",A,A,Enable DynamoDB Accelerator (DAX) for DynamoDB and CloudFront for S3,Enable ElastiCache Redis for DynamoDB and CloudFront for S3,Enable DAX for DynamoDB and ElastiCache Memcached for S3,Enable ElastiCache Redis for DynamoDB and ElastiCache Memcached for S3,,,,소매 회사는 Application Load Balancer 뒤의 Auto Scaling 그룹에 배포되는 REST API를 개발했습니다. API는 사용자 데이터를 DynamoDB에 저장하고 이미지와 같은 모든 정적 콘텐츠는 S3를 통해 제공됩니다. 사용 경향을 분석한 결과 읽기 요청의 90%가 모든 사용자가 공통적으로 액세스하는 데이터에 대한 것으로 나타났습니다.솔루션 아키텍트로서 애플리케이션 성능을 개선하기 위한 가장 효율적인 솔루션으로 다음 중 무엇을 제안하시겠습니까?,DynamoDB용 DynamoDB Accelerator(DAX) 및 S3용 CloudFront 활성화,DynamoDB용 ElastiCache Redis 및 S3용 CloudFront 활성화,DynamoDB용 DAX 및 S3용 ElastiCache Memcached 활성화,DynamoDB용 ElastiCache Redis 및 S3용 ElastiCache Memcached 활성화,,,0,,
udemy,CLF-01,31,"The engineering team at a Spanish professional football club has built a notification system for its website using Amazon SNS notifications which are then handled by a Lambda function for end-user delivery. During the off-season, the notification systems need to handle about 100 requests per second. During the peak football season, the rate touches about 5000 requests per second and it is noticed that a significant number of the notifications are not being delivered to the end-users on the website.As a solutions architect, which of the following would you suggest as the BEST possible solution to this issue?",B,B,The engineering team needs to provision more servers running the Lambda service,"Amazon SNS message deliveries to AWS Lambda have crossed the account concurrency quota for Lambda, so the team needs to contact AWS support to raise the account limit","Amazon SNS has hit a scalability limit, so the team needs to contact AWS support to raise the account limit",The engineering team needs to provision more servers running the SNS service,,,,스페인 프로 축구 클럽의 엔지니어링 팀은 Amazon SNS 알림을 사용하여 웹 사이트에 대한 알림 시스템을 구축한 다음 최종 사용자 전달을 위해 Lambda 기능으로 처리합니다. 오프 시즌 동안 알림 시스템은 초당 약 100개의 요청을 처리해야 합니다. 성수기 축구 시즌에는 초당 약 5000건의 요청이 발생하며 상당수의 알림이 웹사이트의 최종 사용자에게 전달되지 않는 것으로 나타났습니다.솔루션 아키텍트로서 다음 중 이 문제에 대한 최상의 솔루션으로 제안하는 것은 무엇입니까?,엔지니어링 팀은 Lambda 서비스를 실행하는 더 많은 서버를 프로비저닝해야 합니다.,AWS Lambda로의 Amazon SNS 메시지 전송이 Lambda에 대한 계정 동시성 할당량을 초과했으므로 팀은 계정 한도를 높이려면 AWS 지원팀에 문의해야 합니다.,Amazon SNS가 확장성 한도에 도달했으므로 팀은 계정 한도를 높이려면 AWS 지원팀에 문의해야 합니다.,엔지니어링 팀은 SNS 서비스를 실행하는 더 많은 서버를 프로비저닝해야 합니다.,,,0,,
udemy,CLF-01,32,A large financial institution operates an on-premises data center with hundreds of PB of data managed on Microsoft’s Distributed File System (DFS). The CTO wants the organization to transition into a hybrid cloud environment and run data-intensive analytics workloads that support DFS.Which of the following AWS services can facilitate the migration of these workloads?,A,A,Amazon FSx for Windows File Server,Amazon FSx for Lustre,Microsoft SQL Server on Amazon,AWS Managed Microsoft AD,,,,대규모 금융 기관은 Microsoft의 DFS(분산 파일 시스템)에서 관리되는 수백 PB의 데이터가 포함된 온프레미스 데이터 센터를 운영합니다. CTO는 조직이 하이브리드 클라우드 환경으로 전환하고 DFS를 지원하는 데이터 집약적 분석 워크로드를 실행하기를 원합니다.다음 중 이러한 워크로드의 마이그레이션을 용이하게 할 수 있는 AWS 서비스는 무엇입니까?,Windows 파일 서버용 Amazon FSx,Lustre용 Amazon FSx,아마존의 마이크로소프트 SQL 서버,AWS 관리형 Microsoft AD,,,0,,
udemy,CLF-01,33,"A research group needs a fleet of EC2 instances for a specialized task that must deliver high random I/O performance. Each instance in the fleet would have access to a dataset that is replicated across the instances. Because of the resilient application architecture, the specialized task would continue to be processed even if any instance goes down, as the underlying application architecture would ensure the replacement instance has access to the required dataset.Which of the following options is the MOST cost-optimal and resource-efficient solution to build this fleet of EC2 instances?",A,A,Use Instance Store based EC2 instances,Use EC2 instances with access to S3 based storage,Use EBS based EC2 instances,Use EC2 instances with EFS mount points,,,,연구 그룹은 높은 임의 I/O 성능을 제공해야 하는 특수 작업을 위해 EC2 인스턴스 플릿이 필요합니다. 플릿의 각 인스턴스는 인스턴스 간에 복제되는 데이터 세트에 액세스할 수 있습니다. 탄력적인 애플리케이션 아키텍처로 인해 기본 애플리케이션 아키텍처가 대체 인스턴스가 필요한 데이터 세트에 액세스할 수 있도록 보장하므로 인스턴스가 다운되더라도 특수 작업이 계속 처리됩니다.다음 옵션 중 이 EC2 인스턴스 플릿을 구축하기 위한 가장 비용 최적화되고 리소스 효율적인 솔루션은 무엇입니까?,인스턴스 스토어 기반 EC2 인스턴스 사용,S3 기반 스토리지에 대한 액세스 권한이 있는 EC2 인스턴스 사용,EBS 기반 EC2 인스턴스 사용,EFS 탑재 지점과 함께 EC2 인스턴스 사용,,,0,,
udemy,CLF-01,34,"An organization wants to delegate access to a set of users from the development environment so that they can access some resources in the production environment which is managed under another AWS account.As a solutions architect, which of the following steps would you recommend?",D,D,It is not possible to access cross-account resources,Both IAM roles and IAM users can be used interchangeably for cross-account access,Create new IAM user credentials for the production environment and share these credentials with the set of users from the development environment,Create a new IAM role with the required permissions to access the resources in the production environment. The users can then assume this IAM role while accessing the resources from the production environment,,,,조직은 다른 AWS 계정으로 관리되는 프로덕션 환경의 일부 리소스에 액세스할 수 있도록 개발 환경의 사용자 집합에 대한 액세스 권한을 위임하려고 합니다.솔루션 설계자로서 다음 중 어떤 단계를 권장하시겠습니까?,교차 계정 리소스에 액세스할 수 없습니다.,IAM 역할과 IAM 사용자는 교차 계정 액세스를 위해 상호 교환적으로 사용할 수 있습니다.,프로덕션 환경에 대한 새 IAM 사용자 자격 증명을 생성하고 이러한 자격 증명을 개발 환경의 사용자 집합과 공유,프로덕션 환경의 리소스에 액세스하는 데 필요한 권한이 있는 새 IAM 역할을 생성합니다. 그런 다음 사용자는 프로덕션 환경에서 리소스에 액세스하는 동안 이 IAM 역할을 맡을 수 있습니다.,,,0,,
udemy,CLF-01,35,"A media agency stores its re-creatable assets on Amazon S3 buckets. The assets are accessed by a large number of users for the first few days and the frequency of access falls down drastically after a week. Although the assets would be accessed occasionally after the first week, but they must continue to be immediately accessible when required. The cost of maintaining all the assets on S3 storage is turning out to be very expensive and the agency is looking at reducing costs as much as possible.As a Solutions Architect, can you suggest a way to lower the storage costs while fulfilling the business requirements?",C,C,Configure a lifecycle policy to transition the objects to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 7 days,Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 7 days,Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days,Configure a lifecycle policy to transition the objects to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days,,,,미디어 대행사는 재생성 가능한 자산을 Amazon S3 버킷에 저장합니다. 처음 며칠 동안은 많은 수의 사용자가 자산에 액세스하고 일주일 후에는 액세스 빈도가 급격히 떨어집니다. 자산은 첫 주 이후 가끔 액세스되지만 필요할 때 즉시 액세스할 수 있어야 합니다. S3 스토리지에 모든 자산을 유지하는 비용이 매우 비싼 것으로 판명되었으며 기관은 비용을 최대한 줄이는 방법을 모색하고 있습니다.솔루션 설계자로서 비즈니스 요구 사항을 충족하면서 스토리지 비용을 낮추는 방법을 제안할 수 있습니까?,7일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책 구성,7일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책 구성,30일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책 구성,30일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책 구성,,,0,,
udemy,CLF-01,36,A leading social media analytics company is contemplating moving its dockerized application stack into AWS Cloud. The company is not sure about the pricing for using Elastic Container Service (ECS) with the EC2 launch type compared to the Elastic Container Service (ECS) with the Fargate launch type.Which of the following is correct regarding the pricing for these two services?,A,A,ECS with EC2 launch type is charged based on EC2 instances and EBS volumes used. ECS with Fargate launch type is charged based on vCPU and memory resources that the containerized application requests,Both ECS with EC2 launch type and ECS with Fargate launch type are just charged based on Elastic Container Service used per hour,Both ECS with EC2 launch type and ECS with Fargate launch type are charged based on EC2 instances and EBS volumes used,Both ECS with EC2 launch type and ECS with Fargate launch type are charged based on vCPU and memory resources that the containerized application requests,,,,선도적인 소셜 미디어 분석 회사는 도커화된 애플리케이션 스택을 AWS 클라우드로 이전하는 것을 고려하고 있습니다. 회사는 Fargate 시작 유형이 포함된 Elastic Container Service(ECS)와 비교하여 EC2 시작 유형이 포함된 Elastic Container Service(ECS)를 사용하는 가격에 대해 확신하지 못합니다.이 두 서비스의 가격 책정에 관한 설명으로 옳은 것은?,EC2 시작 유형의 ECS는 사용된 EC2 인스턴스 및 EBS 볼륨에 따라 요금이 부과됩니다. Fargate 시작 유형이 포함된 ECS는 컨테이너화된 애플리케이션이 요청하는 vCPU 및 메모리 리소스에 따라 요금이 부과됩니다.,EC2 시작 유형이 포함된 ECS와 Fargate 시작 유형이 포함된 ECS는 모두 시간당 사용된 Elastic Container Service에 따라 요금이 부과됩니다.,EC2 시작 유형이 포함된 ECS와 Fargate 시작 유형이 포함된 ECS는 모두 사용된 EC2 인스턴스 및 EBS 볼륨에 따라 요금이 부과됩니다.,EC2 시작 유형이 포함된 ECS와 Fargate 시작 유형이 포함된 ECS는 모두 컨테이너화된 애플리케이션이 요청하는 vCPU 및 메모리 리소스에 따라 요금이 부과됩니다.,,,0,,
udemy,CLF-01,37,A video analytics organization has been acquired by a leading media company. The analytics organization has 10 independent applications with an on-premises data footprint of about 70TB for each application. The CTO of the media company has set a timeline of two weeks to carry out the data migration from on-premises data center to AWS Cloud and establish connectivity.Which of the following are the MOST cost-effective options for completing the data transfer and establishing connectivity? (Select two),AB,AB,Setup Site-to-Site VPN to establish on-going connectivity between the on-premises data center and AWS Cloud,Order 10 Snowball Edge Storage Optimized devices to complete the one-time data transfer,Order 70 Snowball Edge Storage Optimized devices to complete the one-time data transfer,Setup AWS direct connect to establish connectivity between the on-premises data center and AWS Cloud,Order 1 Snowmobile to complete the one-time data transfer,,,선도적인 미디어 회사에서 비디오 분석 조직을 인수했습니다. 분석 조직에는 각 애플리케이션에 대해 약 70TB의 온프레미스 데이터 풋프린트가 있는 10개의 독립적인 애플리케이션이 있습니다. 미디어 회사의 CTO는 온프레미스 데이터 센터에서 AWS 클라우드로의 데이터 마이그레이션을 수행하고 연결을 설정하는 데 2주의 일정을 설정했습니다.다음 중 데이터 전송을 완료하고 연결을 설정하기 위한 가장 비용 효율적인 옵션은 무엇입니까? (2개 선택),온프레미스 데이터 센터와 AWS 클라우드 간의 지속적인 연결을 설정하도록 Site-to-Site VPN 설정,10개의 Snowball Edge Storage Optimized 디바이스를 주문하여 일회성 데이터 전송 완료,70개의 Snowball Edge Storage Optimized 디바이스를 주문하여 일회성 데이터 전송 완료,온프레미스 데이터 센터와 AWS 클라우드 간의 연결을 설정하도록 AWS Direct Connect 설정,일회성 데이터 전송을 완료하려면 Snowmobile 1대를 주문하세요.,,0,,
udemy,CLF-01,38,"A development team requires permissions to list an S3 bucket and delete objects from that bucket. A systems administrator has created the following IAM policy to provide access to the bucket and applied that policy to the group. The group is not able to delete objects in the bucket. The company follows the principle of least privilege.    ""Version"": ""2021-10-17"",    ""Statement"": [        {            ""Action"": [                ""s3:ListBucket"",                ""s3:DeleteObject""            ],            ""Resource"": [                ""arn:aws:s3:::example-bucket""            ],            ""Effect"": ""Allow""        }    ]Which statement should a solutions architect add to the policy to address this issue?",B,B,"{
    ""Action"": [
        ""s3:*""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:DeleteObject""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:*Object""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:DeleteObject""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket*""
    ],
    ""Effect"": ""Allow""
}",,,,"개발 팀은 S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 수 있는 권한이 필요합니다. 시스템 관리자가 다음 IAM 정책을 생성하여 버킷에 대한 액세스를 제공하고 해당 정책을 그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. 회사는 최소 권한의 원칙을 따릅니다.    ""Version"": ""2021-10-17"",    ""Statement"": [        {            ""Action"": [                ""s3:ListBucket"",                ""s3:DeleteObject""            ],            ""Resource"": [                ""arn:aws:s3:::example-bucket""            ],            ""Effect"": ""Allow""        }    ]솔루션 아키텍트가 이 문제를 해결하기 위해 정책에 추가해야 하는 문장은 무엇입니까?","{
    ""Action"": [
        ""s3:*""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:DeleteObject""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:*Object""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket/*""
    ],
    ""Effect"": ""Allow""
}","{
    ""Action"": [
        ""s3:DeleteObject""
    ],
    ""Resource"": [
        ""arn:aws:s3:::example-bucket*""
    ],
    ""Effect"": ""Allow""
}",,,0,,
udemy,CLF-01,39,"A leading carmaker would like to build a new car-as-a-sensor service by leveraging fully serverless components that are provisioned and managed automatically by AWS. The development team at the carmaker does not want an option that requires the capacity to be manually provisioned, as it does not want to respond manually to changing volumes of sensor data.Given these constraints, which of the following solutions is the BEST fit to develop this car-as-a-sensor service?",D,D,"Ingest the sensor data in an Amazon SQS standard queue, which is polled by an application running on an EC2 instance and the data is written into an auto-scaled DynamoDB table for downstream processing","Ingest the sensor data in Kinesis Data Firehose, which directly writes the data into an auto-scaled DynamoDB table for downstream processing","Ingest the sensor data in Kinesis Data Streams, which is polled by an application running on an EC2 instance and the data is written into an auto-scaled DynamoDB table for downstream processing","Ingest the sensor data in an Amazon SQS standard queue, which is polled by a Lambda function in batches and the data is written into an auto-scaled DynamoDB table for downstream processing",,,,선도적인 자동차 제조업체는 AWS에서 자동으로 프로비저닝하고 관리하는 완전 서버리스 구성 요소를 활용하여 새로운 자동차 센서 서비스를 구축하려고 합니다. 자동차 제조업체의 개발 팀은 변화하는 센서 데이터 볼륨에 수동으로 대응하기를 원하지 않기 때문에 용량을 수동으로 프로비저닝해야 하는 옵션을 원하지 않습니다.이러한 제약 조건을 감안할 때 다음 중 이 자동차 센서 서비스를 개발하는 데 가장 적합한 솔루션은 무엇입니까?,Amazon SQS 표준 대기열에서 센서 데이터를 수집합니다. 이 대기열은 EC2 인스턴스에서 실행되는 애플리케이션에 의해 폴링되고 데이터는 다운스트림 처리를 위해 자동 확장된 DynamoDB 테이블에 기록됩니다.,다운스트림 처리를 위해 데이터를 자동 조정된 DynamoDB 테이블에 직접 쓰는 Kinesis Data Firehose에서 센서 데이터를 수집합니다.,Kinesis Data Streams에서 센서 데이터를 수집합니다. EC2 인스턴스에서 실행되는 애플리케이션이 폴링하고 데이터는 다운스트림 처리를 위해 자동 조정된 DynamoDB 테이블에 기록됩니다.,Amazon SQS 표준 대기열에서 센서 데이터를 수집합니다. 이 대기열은 Lambda 함수에 의해 배치로 폴링되고 데이터는 다운스트림 처리를 위해 자동 확장된 DynamoDB 테이블에 기록됩니다.,,,0,,
udemy,CLF-01,40,"A healthcare startup needs to enforce compliance and regulatory guidelines for objects stored in Amazon S3. One of the key requirements is to provide adequate protection against accidental deletion of objects.As a solutions architect, what are your recommendations to address these guidelines? (Select two)",BC,BC,Change the configuration on AWS S3 console so that the user needs to provide additional confirmation while deleting any S3 object,Enable MFA delete on the bucket,Enable versioning on the bucket,Create an event trigger on deleting any S3 object. The event invokes an SNS notification via email to the IT manager,Establish a process to get managerial approval for deleting S3 objects,,,의료 스타트업은 Amazon S3에 저장된 객체에 대한 규정 준수 및 규제 지침을 시행해야 합니다. 주요 요구 사항 중 하나는 실수로 객체를 삭제하지 않도록 적절한 보호를 제공하는 것입니다.솔루션 설계자로서 이러한 지침을 다루기 위한 권장 사항은 무엇입니까? (2개 선택),사용자가 S3 객체를 삭제하는 동안 추가 확인을 제공해야 하도록 AWS S3 콘솔에서 구성을 변경합니다.,버킷에서 MFA 삭제 활성화,버킷에서 버전 관리 활성화,S3 객체 삭제 시 이벤트 트리거를 생성합니다. 이벤트는 IT 관리자에게 이메일을 통해 SNS 알림을 호출합니다.,S3 객체 삭제에 대한 관리자 승인을 얻기 위한 프로세스 설정,,0,,
udemy,CLF-01,41,A software engineering intern at an e-commerce company is documenting the process flow to provision EC2 instances via the Amazon EC2 API. These instances are to be used for an internal application that processes HR payroll data. He wants to highlight those volume types that cannot be used as a boot volume.Can you help the intern by identifying those storage volume types that CANNOT be used as boot volumes while creating the instances? (Select two),BE,BE,Provisioned IOPS SSD (io1),Throughput Optimized HDD (st1),General Purpose SSD (gp2),Instance Store,Cold HDD (sc1),,,전자상거래 회사의 소프트웨어 엔지니어링 인턴이 Amazon EC2 API를 통해 EC2 인스턴스를 프로비저닝하는 프로세스 흐름을 문서화하고 있습니다. 이러한 인스턴스는 HR 급여 데이터를 처리하는 내부 애플리케이션에 사용됩니다. 그는 부팅 볼륨으로 사용할 수 없는 볼륨 유형을 강조 표시하려고 합니다.인스턴스를 생성하는 동안 부트 볼륨으로 사용할 수 없는 스토리지 볼륨 유형을 식별하여 인턴을 도울 수 있습니까? (2개 선택),프로비저닝된 IOPS SSD(io1),처리량 최적화 HDD(st1),범용 SSD(gp2),인스턴스 스토어,콜드 HDD(sc1),,0,,
udemy,CLF-01,42,"A US-based healthcare startup is building an interactive diagnostic tool for COVID-19 related assessments. The users would be required to capture their personal health records via this tool. As this is sensitive health information, the backup of the user data must be kept encrypted in S3. The startup does not want to provide its own encryption keys but still wants to maintain an audit trail of when an encryption key was used and by whom.Which of the following is the BEST solution for this use-case?",B,B,Use client-side encryption with client provided keys and then upload the encrypted user data to S3,Use SSE-KMS to encrypt the user data on S3,Use SSE-S3 to encrypt the user data on S3,Use SSE-C to encrypt the user data on S3,,,,미국에 기반을 둔 의료 스타트업은 COVID-19 관련 평가를 위한 대화형 진단 도구를 구축하고 있습니다. 사용자는 이 도구를 통해 개인 건강 기록을 캡처해야 합니다. 이것은 민감한 건강 정보이므로 사용자 데이터의 백업은 S3에서 암호화된 상태로 유지되어야 합니다. 스타트업은 자체 암호화 키를 제공하기를 원하지 않지만 여전히 암호화 키가 언제 누구에 의해 사용되었는지에 대한 감사 추적을 유지하기를 원합니다.다음 중 이 사용 사례에 가장 적합한 솔루션은 무엇입니까?,클라이언트 제공 키로 클라이언트 측 암호화를 사용한 다음 암호화된 사용자 데이터를 S3에 업로드,SSE-KMS를 사용하여 S3에서 사용자 데이터 암호화,SSE-S3를 사용하여 S3의 사용자 데이터 암호화,SSE-C를 사용하여 S3에서 사용자 데이터 암호화,,,0,,
udemy,CLF-01,43,"An e-commerce company is looking for a solution with high availability, as it plans to migrate its flagship application to a fleet of Amazon EC2 instances. The solution should allow for content-based routing as part of the architecture.As a Solutions Architect, which of the following will you suggest for the company?",C,C,Use an Auto Scaling group for distributing traffic to the EC2 instances spread across different Availability Zones. Configure a Public IP address to mask any failure of an instance,Use an Auto Scaling group for distributing traffic to the EC2 instances spread across different Availability Zones. Configure an Elastic IP address to mask any failure of an instance,Use an Application Load Balancer for distributing traffic to the EC2 instances spread across different Availability Zones. Configure Auto Scaling group to mask any failure of an instance,Use a Network Load Balancer for distributing traffic to the EC2 instances spread across different Availability Zones. Configure a Private IP address to mask any failure of an instance,,,,한 전자상거래 회사는 플래그십 애플리케이션을 Amazon EC2 인스턴스 플릿으로 마이그레이션할 계획이므로 가용성이 높은 솔루션을 찾고 있습니다. 솔루션은 아키텍처의 일부로 콘텐츠 기반 라우팅을 허용해야 합니다.솔루션 설계자로서 다음 중 회사에 제안할 사항은 무엇입니까?,서로 다른 가용 영역에 분산된 EC2 인스턴스에 트래픽을 분산하려면 Auto Scaling 그룹을 사용하십시오. 인스턴스의 장애를 마스킹하도록 퍼블릭 IP 주소 구성,서로 다른 가용 영역에 분산된 EC2 인스턴스에 트래픽을 분산하려면 Auto Scaling 그룹을 사용하십시오. 인스턴스의 장애를 마스킹하도록 탄력적 IP 주소 구성,Application Load Balancer를 사용하여 여러 가용 영역에 분산된 EC2 인스턴스에 트래픽을 분산합니다. 인스턴스의 장애를 마스킹하도록 Auto Scaling 그룹 구성,Network Load Balancer를 사용하여 여러 가용 영역에 분산된 EC2 인스턴스로 트래픽을 분산합니다. 인스턴스의 장애를 마스킹하도록 개인 IP 주소 구성,,,0,,
udemy,CLF-01,44,"A new DevOps engineer has joined a large financial services company recently. As part of his onboarding, the IT department is conducting a review of the checklist for tasks related to AWS Identity and Access Management.As a solutions architect, which best practices would you recommend (Select two)?",DE,DE,Create a minimum number of accounts and share these account credentials among employees,Grant maximum privileges to avoid assigning privileges again,Use user credentials to provide access specific permissions for Amazon EC2 instances,Configure AWS CloudTrail to log all IAM actions,Enable MFA for privileged users,,,새로운 DevOps 엔지니어가 최근 대규모 금융 서비스 회사에 합류했습니다. 온보딩의 일환으로 IT 부서는 AWS Identity and Access Management와 관련된 작업에 대한 체크리스트를 검토하고 있습니다.솔루션 설계자로서 어떤 모범 사례를 추천하시겠습니까(2개 선택)?,최소 수의 계정을 생성하고 직원 간에 이러한 계정 자격 증명을 공유합니다.,권한을 다시 할당하지 않으려면 최대 권한을 부여하세요.,사용자 자격 증명을 사용하여 Amazon EC2 인스턴스에 대한 특정 액세스 권한 제공,모든 IAM 작업을 기록하도록 AWS CloudTrail 구성,권한 있는 사용자에 대해 MFA 활성화,,0,,
udemy,CLF-01,45,"As part of a pilot program, a biotechnology company wants to integrate data files from its on-premises analytical application with AWS Cloud via an NFS interface.Which of the following AWS service is the MOST efficient solution for the given use-case?",D,D,AWS Site-to-Site VPN,AWS Storage Gateway - Tape Gateway,AWS Storage Gateway - Volume Gateway,AWS Storage Gateway - File Gateway,,,,파일럿 프로그램의 일환으로 생명 공학 회사는 온프레미스 분석 애플리케이션의 데이터 파일을 NFS 인터페이스를 통해 AWS 클라우드와 통합하려고 합니다.다음 AWS 서비스 중 주어진 사용 사례에 가장 효율적인 솔루션은 무엇입니까?,AWS 사이트 간 VPN,AWS Storage Gateway - 테이프 게이트웨이,AWS Storage Gateway - 볼륨 게이트웨이,AWS Storage Gateway - 파일 게이트웨이,,,0,,
udemy,CLF-01,46,"A junior scientist working with the Deep Space Research Laboratory at NASA is trying to upload a high-resolution image of a nebula into Amazon S3. The image size is approximately 3GB. The junior scientist is using S3 Transfer Acceleration (S3TA) for faster image upload. It turns out that S3TA did not result in an accelerated transfer.Given this scenario, which of the following is correct regarding the charges for this image transfer?",A,A,The junior scientist does not need to pay any transfer charges for the image upload,The junior scientist only needs to pay S3 transfer charges for the image upload,The junior scientist needs to pay both S3 transfer charges and S3TA transfer charges for the image upload,The junior scientist only needs to pay S3TA transfer charges for the image upload,,,,NASA의 Deep Space Research Laboratory에서 일하는 주니어 과학자가 성운의 고해상도 이미지를 Amazon S3에 업로드하려고 합니다. 이미지 크기는 약 3GB입니다. 주니어 과학자는 더 빠른 이미지 업로드를 위해 S3TA(S3 Transfer Acceleration)를 사용하고 있습니다. S3TA가 가속 전송을 초래하지 않은 것으로 나타났습니다.이 시나리오를 고려할 때 이 이미지 전송에 대한 요금과 관련하여 다음 중 올바른 것은 무엇입니까?,후배 과학자는 이미지 업로드에 대한 이체 수수료를 지불할 필요가 없습니다.,주니어 과학자는 이미지 업로드에 대한 S3 전송 요금만 지불하면 됩니다.,주니어 과학자는 이미지 업로드에 대한 S3 전송 요금과 S3TA 전송 요금을 모두 지불해야 합니다.,주니어 과학자는 이미지 업로드에 대한 S3TA 전송 요금만 지불하면 됩니다.,,,0,,
udemy,CLF-01,47,An IT company wants to review its security best-practices after an incident was reported where a new developer on the team was assigned full access to DynamoDB. The developer accidentally deleted a couple of tables from the production environment while building out a new feature.Which is the MOST effective way to address this issue so that such incidents do not recur?,B,B,The CTO should review the permissions for each new developer's IAM user so that such incidents don't recur,Use permissions boundary to control the maximum permissions employees can grant to the IAM principals,Only root user should have full database access in the organization,Remove full database access for all IAM users in the organization,,,,IT 회사는 팀의 새 개발자에게 DynamoDB에 대한 전체 액세스 권한이 할당된 사건이 ​​보고된 후 보안 모범 사례를 검토하려고 합니다. 개발자가 새 기능을 구축하는 동안 프로덕션 환경에서 실수로 몇 개의 테이블을 삭제했습니다.이러한 사고가 재발하지 않도록 이 문제를 해결하는 가장 효과적인 방법은 무엇입니까?,CTO는 이러한 사건이 재발하지 않도록 각 신규 개발자의 IAM 사용자에 대한 권한을 검토해야 합니다.,권한 경계를 사용하여 직원이 IAM 보안 주체에게 부여할 수 있는 최대 권한 제어,루트 사용자만 조직에서 전체 데이터베이스 액세스 권한을 가져야 합니다.,조직의 모든 IAM 사용자에 대한 전체 데이터베이스 액세스 권한 제거,,,0,,
udemy,CLF-01,48,"A gaming company uses Amazon Aurora as its primary database service. The company has now deployed 5 multi-AZ read replicas to increase the read throughput and for use as failover target. The replicas have been assigned the following failover priority tiers and corresponding instance sizes are given in parentheses: tier-1 (16TB), tier-1 (32TB), tier-10 (16TB), tier-15 (16TB), tier-15 (32TB).In the event of a failover, Amazon Aurora will promote which of the following read replicas?",C,C,Tier-1 (16TB),Tier-15 (32TB),Tier-1 (32TB),Tier-10 (16TB),,,,"게임 회사는 Amazon Aurora를 기본 데이터베이스 서비스로 사용합니다. 이 회사는 이제 읽기 처리량을 늘리고 장애 조치 대상으로 사용하기 위해 5개의 다중 AZ 읽기 복제본을 배포했습니다. 복제본에는 다음과 같은 장애 조치 우선순위 계층이 할당되었으며 해당 인스턴스 크기는 괄호 안에 표시됩니다. 계층-1(16TB), 계층-1(32TB), 계층-10(16TB), 계층-15(16TB), 계층-15 (32TB).장애 조치 시 Amazon Aurora는 다음 중 어떤 읽기 전용 복제본을 승격합니까?",계층 1(16TB),계층 15(32TB),계층 1(32TB),계층 10(16TB),,,0,,
udemy,CLF-01,49,Which of the following features of an Amazon S3 bucket can only be suspended once they have been enabled?,C,C,Requester Pays,Server Access Logging,Versioning,Static Website Hosting,,,,Amazon S3 버킷의 다음 기능 중 활성화된 후에만 일시 중지할 수 있는 기능은 무엇입니까?,요청자 지불,서버 액세스 로깅,버전 관리,정적 웹사이트 호스팅,,,0,,
udemy,CLF-01,50,An IT consultant is helping the owner of a medium-sized business set up an AWS account. What are the security recommendations he must follow while creating the AWS account root user? (Select two),AD,AD,Enable Multi Factor Authentication (MFA) for the AWS account root user account,Encrypt the access keys and save them on Amazon S3,Create AWS account root user access keys and share those keys only with the business owner,Create a strong password for the AWS account root user,Send an email to the business owner with details of the login username and password for the AWS root user. This will help the business owner to troubleshoot any login issues in future,,,IT 컨설턴트가 중소기업 소유주가 AWS 계정을 설정하도록 돕고 있습니다. AWS 계정 루트 사용자를 생성하는 동안 준수해야 하는 보안 권장 사항은 무엇입니까? (2개 선택),AWS 계정 루트 사용자 계정에 대해 Multi Factor Authentication(MFA) 활성화,액세스 키를 암호화하고 Amazon S3에 저장,AWS 계정 루트 사용자 액세스 키를 생성하고 해당 키를 비즈니스 소유자와만 공유,AWS 계정 루트 사용자에 대한 강력한 암호 생성,AWS 루트 사용자의 로그인 사용자 이름 및 암호 세부 정보와 함께 비즈니스 소유자에게 이메일을 보냅니다. 이렇게 하면 비즈니스 소유자가 향후 로그인 문제를 해결하는 데 도움이 됩니다.,,0,,
udemy,CLF-01,51,"The solo founder at a tech startup has just created a brand new AWS account. The founder has provisioned an EC2 instance 1A which is running in region A. Later, he takes a snapshot of the instance 1A and then creates a new AMI in region A from this snapshot. This AMI is then copied into another region B. The founder provisions an instance 1B in region B using this new AMI in region B.At this point in time, what entities exist in region B?",D,D,1 EC2 instance and 2 AMIs exist in region B,1 EC2 instance and 1 AMI exist in region B,1 EC2 instance and 1 snapshot exist in region B,"1 EC2 instance, 1 AMI and 1 snapshot exist in region B",,,,기술 스타트업의 단독 창업자가 방금 새로운 AWS 계정을 만들었습니다. 설립자는 리전 A에서 실행 중인 EC2 인스턴스 1A를 프로비저닝했습니다. 나중에 인스턴스 1A의 스냅샷을 만든 다음 이 스냅샷에서 리전 A에 새 AMI를 생성합니다. 그런 다음 이 AMI는 다른 리전 B로 복사됩니다. 설립자는 리전 B에서 이 새 AMI를 사용하여 리전 B에서 인스턴스 1B를 프로비저닝합니다.이 시점에서 영역 B에는 어떤 엔터티가 존재합니까?,1개의 EC2 인스턴스와 2개의 AMI가 리전 B에 존재합니다.,1개의 EC2 인스턴스와 1개의 AMI가 리전 B에 존재합니다.,1개의 EC2 인스턴스와 1개의 스냅샷이 리전 B에 존재합니다.,"1개의 EC2 인스턴스, 1개의 AMI 및 1개의 스냅샷이 리전 B에 존재합니다.",,,0,,
udemy,CLF-01,52,A new DevOps engineer has just joined a development team and wants to understand the replication capabilities for RDS Multi-AZ as well as RDS Read-replicas.Which of the following correctly summarizes these capabilities for the given database?,C,C,"Multi-AZ follows asynchronous replication and spans at least two Availability Zones within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region","Multi-AZ follows asynchronous replication and spans one Availability Zone within a single region. Read replicas follow synchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region","Multi-AZ follows synchronous replication and spans at least two Availability Zones within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region","Multi-AZ follows asynchronous replication and spans at least two Availability Zones within a single region. Read replicas follow synchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region",,,,새로운 DevOps 엔지니어가 방금 개발 팀에 합류했으며 RDS 다중 AZ 및 RDS 읽기 복제본의 복제 기능을 이해하고자 합니다.다음 중 주어진 데이터베이스에 대한 이러한 기능을 올바르게 요약한 것은 무엇입니까?,"다중 AZ는 비동기식 복제를 따르고 단일 지역 내에서 최소 두 개의 가용 영역에 걸쳐 있습니다. 읽기 전용 복제본은 비동기식 복제를 따르며 가용 영역, 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.","다중 AZ는 비동기식 복제를 따르고 단일 지역 내에서 하나의 가용 영역에 걸쳐 있습니다. 읽기 전용 복제본은 동기식 복제를 따르며 가용 영역, 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.","다중 AZ는 동기식 복제를 따르고 단일 지역 내에서 최소 두 개의 가용 영역에 걸쳐 있습니다. 읽기 전용 복제본은 비동기식 복제를 따르며 가용 영역, 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.","다중 AZ는 비동기식 복제를 따르고 단일 지역 내에서 최소 두 개의 가용 영역에 걸쳐 있습니다. 읽기 전용 복제본은 동기식 복제를 따르며 가용 영역, 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.",,,0,,
udemy,CLF-01,53,A Big Data analytics company wants to set up an AWS cloud architecture that throttles requests in case of sudden traffic spikes. The company is looking for AWS services that can be used for buffering or throttling to handle such traffic variations.Which of the following services can be used to support this requirement?,A,A,"Amazon API Gateway, Amazon SQS and Amazon Kinesis","Amazon Gateway Endpoints, Amazon SQS and Amazon Kinesis","Elastic Load Balancer, Amazon SQS, AWS Lambda","Amazon SQS, Amazon SNS and AWS Lambda",,,,빅 데이터 분석 회사는 갑작스러운 트래픽 급증 시 요청을 제한하는 AWS 클라우드 아키텍처를 설정하려고 합니다. 회사는 이러한 트래픽 변동을 처리하기 위해 버퍼링 또는 스로틀링에 사용할 수 있는 AWS 서비스를 찾고 있습니다.다음 중 이 요구 사항을 지원하는 데 사용할 수 있는 서비스는 무엇입니까?,"Amazon API 게이트웨이, Amazon SQS 및 Amazon Kinesis","Amazon Gateway 엔드포인트, Amazon SQS 및 Amazon Kinesis","Elastic Load Balancer, Amazon SQS, AWS Lambda","Amazon SQS, Amazon SNS 및 AWS Lambda",,,0,,
udemy,CLF-01,54,"The DevOps team at an e-commerce company wants to perform some maintenance work on a specific EC2 instance that is part of an Auto Scaling group using a step scaling policy. The team is facing a maintenance challenge - every time the team deploys a maintenance patch, the instance health check status shows as out of service for a few minutes. This causes the Auto Scaling group to provision another replacement instance immediately.As a solutions architect, which are the MOST time/resource efficient steps that you would recommend so that the maintenance work can be completed at the earliest? (Select two)",BD,BD,"Take a snapshot of the instance, create a new AMI and then launch a new instance using this AMI. Apply the maintenance patch to this new instance and then add it back to the Auto Scaling Group by using the manual scaling policy. Terminate the earlier instance that had the maintenance issue","Suspend the ReplaceUnhealthy process type for the Auto Scaling group and apply the maintenance patch to the instance. Once the instance is ready, you can manually set the instance's health status back to healthy and activate the ReplaceUnhealthy process type again","Suspend the ScheduledActions process type for the Auto Scaling group and apply the maintenance patch to the instance. Once the instance is ready, you can you can manually set the instance's health status back to healthy and activate the ScheduledActions process type again","Put the instance into the Standby state and then update the instance by applying the maintenance patch. Once the instance is ready, you can exit the Standby state and then return the instance to service",Delete the Auto Scaling group and apply the maintenance fix to the given instance. Create a new Auto Scaling group and add all the instances again using the manual scaling policy,,,전자 상거래 회사의 DevOps 팀은 단계 조정 정책을 사용하여 Auto Scaling 그룹의 일부인 특정 EC2 인스턴스에서 일부 유지 관리 작업을 수행하려고 합니다. 팀은 유지 관리 문제에 직면해 있습니다. 팀이 유지 관리 패치를 배포할 때마다 인스턴스 상태 확인 상태가 몇 분 동안 서비스 중단으로 표시됩니다. 이로 인해 Auto Scaling 그룹이 다른 대체 인스턴스를 즉시 프로비저닝합니다.솔루션 설계자로서 유지 관리 작업을 가장 빨리 완료할 수 있도록 권장하는 가장 시간/자원 효율적인 단계는 무엇입니까? (2개 선택),인스턴스의 스냅샷을 만들고 새 AMI를 만든 다음 이 AMI를 사용하여 새 인스턴스를 시작합니다. 이 새 인스턴스에 유지 관리 패치를 적용한 다음 수동 조정 정책을 사용하여 Auto Scaling 그룹에 다시 추가합니다. 유지 관리 문제가 있는 이전 인스턴스를 종료합니다.,Auto Scaling 그룹에 대한 ReplaceUnhealthy 프로세스 유형을 일시 중지하고 유지 관리 패치를 인스턴스에 적용합니다. 인스턴스가 준비되면 수동으로 인스턴스의 상태를 다시 정상으로 설정하고 ReplaceUnhealthy 프로세스 유형을 다시 활성화할 수 있습니다.,Auto Scaling 그룹에 대한 ScheduledActions 프로세스 유형을 일시 중단하고 유지 관리 패치를 인스턴스에 적용합니다. 인스턴스가 준비되면 수동으로 인스턴스의 상태를 다시 정상으로 설정하고 ScheduledActions 프로세스 유형을 다시 활성화할 수 있습니다.,인스턴스를 대기 상태로 전환한 다음 유지 관리 패치를 적용하여 인스턴스를 업데이트합니다. 인스턴스가 준비되면 대기 상태를 종료한 다음 인스턴스를 서비스 상태로 되돌릴 수 있습니다.,Auto Scaling 그룹을 삭제하고 지정된 인스턴스에 유지 관리 수정 사항을 적용합니다. 새 Auto Scaling 그룹을 생성하고 수동 조정 정책을 사용하여 모든 인스턴스를 다시 추가합니다.,,0,,
udemy,CLF-01,55,A file-hosting service uses Amazon S3 under the hood to power its storage offerings. Currently all the customer files are uploaded directly under a single S3 bucket. The engineering team has started seeing scalability issues where customer file uploads have started failing during the peak access hours with more than 5000 requests per second.Which of the following is the MOST resource efficient and cost-optimal way of addressing this issue?,B,B,Change the application architecture to use EFS instead of Amazon S3 for storing the customers' uploaded files,Change the application architecture to create customer-specific custom prefixes within the single bucket and then upload the daily files into those prefixed locations,Change the application architecture to create a new S3 bucket for each day's data and then upload the daily files directly under that day's bucket,Change the application architecture to create a new S3 bucket for each customer and then upload each customer's files directly under the respective buckets,,,,파일 호스팅 서비스는 내부적으로 Amazon S3를 사용하여 스토리지 오퍼링을 강화합니다. 현재 모든 고객 파일은 단일 S3 버킷 아래에 직접 업로드됩니다. 엔지니어링 팀은 초당 5000개 이상의 요청으로 액세스가 가장 많은 시간 동안 고객 파일 업로드가 실패하기 시작하는 확장성 문제를 확인하기 시작했습니다.다음 중 이 문제를 해결하는 가장 효율적이고 비용 효율적인 방법은 무엇입니까?,고객이 업로드한 파일을 저장하기 위해 Amazon S3 대신 EFS를 사용하도록 애플리케이션 아키텍처 변경,애플리케이션 아키텍처를 변경하여 단일 버킷 내에서 고객별 사용자 지정 접두사를 생성한 다음 해당 접두사 위치에 일일 파일을 업로드합니다.,애플리케이션 아키텍처를 변경하여 매일의 데이터에 대한 새 S3 버킷을 생성한 다음 해당 날짜의 버킷 바로 아래에 매일 파일을 업로드합니다.,애플리케이션 아키텍처를 변경하여 각 고객에 대한 새 S3 버킷을 생성한 다음 각 버킷 아래에 각 고객의 파일을 직접 업로드합니다.,,,0,,
udemy,CLF-01,56,A geological research agency maintains the seismological data for the last 100 years. The data has a velocity of 1GB per minute. You would like to store the data with only the most relevant attributes to build a predictive model for earthquakes.What AWS services would you use to build the most cost-effective solution with the LEAST amount of infrastructure maintenance?,D,D,Ingest the data in a Spark Streaming Cluster on EMR use Spark Streaming transformations before writing to S3,Ingest the data in Kinesis Data Streams and use an intermediary Lambda function to filter and transform the incoming stream before the output is dumped on S3,Ingest the data in Kinesis Data Analytics and use SQL queries to filter and transform the data before writing to S3,Ingest the data in Kinesis Data Firehose and use an intermediary Lambda function to filter and transform the incoming stream before the output is dumped on S3,,,,지질 조사 기관은 지난 100년 동안의 지진 데이터를 유지 관리합니다. 데이터 속도는 분당 1GB입니다. 지진에 대한 예측 모델을 구축하기 위해 가장 관련성이 높은 특성만 있는 데이터를 저장하려고 합니다.최소한의 인프라 유지 관리로 가장 비용 효율적인 솔루션을 구축하기 위해 어떤 AWS 서비스를 사용하시겠습니까?,S3에 쓰기 전에 Spark Streaming 변환을 사용하는 EMR의 Spark Streaming Cluster에서 데이터 수집,Kinesis Data Streams에서 데이터를 수집하고 중간 Lambda 함수를 사용하여 출력이 S3에 덤프되기 전에 들어오는 스트림을 필터링하고 변환합니다.,Kinesis Data Analytics에서 데이터를 수집하고 SQL 쿼리를 사용하여 S3에 쓰기 전에 데이터를 필터링하고 변환합니다.,Kinesis Data Firehose에서 데이터를 수집하고 중간 Lambda 함수를 사용하여 출력이 S3에 덤프되기 전에 들어오는 스트림을 필터링하고 변환합니다.,,,0,,
udemy,CLF-01,57,"A company uses Amazon S3 buckets for storing sensitive customer data. The company has defined different retention periods for different objects present in the Amazon S3 buckets, based on the compliance requirements. But, the retention rules do not seem to work as expected.Which of the following options represent a valid configuration for setting up retention periods for objects in Amazon S3 buckets? (Select two)",BC,BC,"When you use bucket default settings, you specify a Retain Until Date for the object version",Different versions of a single object can have different retention modes and periods,"When you apply a retention period to an object version explicitly, you specify a Retain Until Date for the object version",The bucket default settings will override any explicit retention mode or period you request on an object version,You cannot place a retention period on an object version through a bucket default setting,,,회사는 민감한 고객 데이터를 저장하기 위해 Amazon S3 버킷을 사용합니다. 회사는 규정 준수 요구 사항에 따라 Amazon S3 버킷에 있는 다양한 객체에 대해 서로 다른 보존 기간을 정의했습니다. 그러나 보관 규칙이 예상대로 작동하지 않는 것 같습니다.다음 중 Amazon S3 버킷의 객체에 대한 보존 기간을 설정하기 위한 유효한 구성을 나타내는 옵션은 무엇입니까? (2개 선택),Retain Until Date버킷 기본 설정을 사용하는 경우 객체 버전에 대해 지정합니다.,단일 객체의 다른 버전은 다른 보존 모드 및 기간을 가질 수 있습니다.,보관 기간을 객체 버전에 명시적으로 적용하는 경우 Retain Until Date객체 버전에 대해 를 지정합니다.,버킷 기본 설정은 객체 버전에서 요청한 모든 명시적 보관 모드 또는 기간을 재정의합니다.,버킷 기본 설정을 통해 객체 버전에 보관 기간을 지정할 수 없습니다.,,0,,
udemy,CLF-01,58,"An audit department generates and accesses the audit reports only twice in a financial year. The department uses AWS Step Functions to orchestrate the report creating process that has failover and retry scenarios built into the solution. The underlying data to create these audit reports is stored on S3, runs into hundreds of Terabytes and should be available with millisecond latency.As a solutions architect, which is the MOST cost-effective storage class that you would recommend to be used for this use-case?",A,A,Amazon S3 Standard-Infrequent Access (S3 Standard-IA),Amazon S3 Glacier Deep Archive,Amazon S3 Standard,Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering),,,,감사 부서는 회계 연도에 두 번만 감사 보고서를 생성하고 액세스합니다. 이 부서는 AWS Step Functions를 사용하여 솔루션에 내장된 장애 조치 및 재시도 시나리오가 있는 보고서 작성 프로세스를 오케스트레이션합니다. 이러한 감사 보고서를 생성하기 위한 기본 데이터는 S3에 저장되고 수백 테라바이트로 실행되며 밀리초 지연 시간으로 사용할 수 있어야 합니다.솔루션 설계자로서 이 사용 사례에 사용하도록 권장하는 가장 비용 효율적인 스토리지 클래스는 무엇입니까?,Amazon S3 Standard-Infrequent Access(S3 Standard-IA),Amazon S3 Glacier 딥 아카이브,아마존 S3 스탠다드,Amazon S3 지능형 계층화(S3 지능형 계층화),,,0,,
udemy,CLF-01,59,"An IT security consultancy is working on a solution to protect data stored in S3 from any malicious activity as well as check for any vulnerabilities on EC2 instances.As a solutions architect, which of the following solutions would you suggest to help address the given requirement?",D,D,Use Amazon GuardDuty to monitor any malicious activity on data stored in S3. Use security assessments provided by Amazon GuardDuty to check for vulnerabilities on EC2 instances,Use Amazon Inspector to monitor any malicious activity on data stored in S3. Use security assessments provided by Amazon Inspector to check for vulnerabilities on EC2 instances,Use Amazon Inspector to monitor any malicious activity on data stored in S3. Use security assessments provided by Amazon GuardDuty to check for vulnerabilities on EC2 instances,Use Amazon GuardDuty to monitor any malicious activity on data stored in S3. Use security assessments provided by Amazon Inspector to check for vulnerabilities on EC2 instances,,,,IT 보안 컨설팅 회사는 악의적인 활동으로부터 S3에 저장된 데이터를 보호하고 EC2 인스턴스의 취약성을 확인하는 솔루션을 개발하고 있습니다.솔루션 설계자로서 주어진 요구 사항을 해결하는 데 도움이 되도록 다음 중 어떤 솔루션을 제안하시겠습니까?,Amazon GuardDuty를 사용하여 S3에 저장된 데이터에 대한 모든 악의적인 활동을 모니터링합니다. Amazon GuardDuty에서 제공하는 보안 평가를 사용하여 EC2 인스턴스의 취약성 확인,Amazon Inspector를 사용하여 S3에 저장된 데이터에 대한 악의적인 활동을 모니터링합니다. Amazon Inspector에서 제공하는 보안 평가를 사용하여 EC2 인스턴스의 취약성 확인,Amazon Inspector를 사용하여 S3에 저장된 데이터에 대한 악의적인 활동을 모니터링합니다. Amazon GuardDuty에서 제공하는 보안 평가를 사용하여 EC2 인스턴스의 취약성 확인,Amazon GuardDuty를 사용하여 S3에 저장된 데이터에 대한 모든 악의적인 활동을 모니터링합니다. Amazon Inspector에서 제공하는 보안 평가를 사용하여 EC2 인스턴스의 취약성 확인,,,0,,
udemy,CLF-01,60,A company has a web application that runs 24*7 in the production environment. The development team at the company runs a clone of the same application in the dev environment for up to 8 hours every day. The company wants to build the MOST cost-optimal solution by deploying these applications using the best-fit pricing options for EC2 instances.What would you recommend?,D,D,Use reserved EC2 instances for the production application and spot instances for the dev application,Use reserved EC2 instances for the production application and spot block instances for the dev application,Use on-demand EC2 instances for the production application and spot instances for the dev application,Use reserved EC2 instances for the production application and on-demand instances for the dev application,,,,회사에는 프로덕션 환경에서 24*7 실행되는 웹 애플리케이션이 있습니다. 회사의 개발 팀은 매일 최대 8시간 동안 개발 환경에서 동일한 애플리케이션의 복제본을 실행합니다. 이 회사는 EC2 인스턴스에 가장 적합한 가격 옵션을 사용하여 이러한 애플리케이션을 배포함으로써 가장 비용 최적화된 솔루션을 구축하고자 합니다.무엇을 추천하나요?,프로덕션 애플리케이션에는 예약된 EC2 인스턴스를 사용하고 개발 애플리케이션에는 스팟 인스턴스를 사용하십시오.,프로덕션 애플리케이션에는 예약된 EC2 인스턴스를 사용하고 개발 애플리케이션에는 스팟 블록 인스턴스를 사용하십시오.,프로덕션 애플리케이션에는 온디맨드 EC2 인스턴스를 사용하고 개발 애플리케이션에는 스팟 인스턴스를 사용하십시오.,프로덕션 애플리케이션에는 예약된 EC2 인스턴스를 사용하고 개발 애플리케이션에는 온디맨드 인스턴스를 사용합니다.,,,0,,
udemy,CLF-01,61,The development team at an e-commerce startup has set up multiple microservices running on EC2 instances under an Application Load Balancer. The team wants to route traffic to multiple back-end services based on the URL path of the HTTP header. So it wants requests for https://www.example.com/orders to go to a specific microservice and requests for https://www.example.com/products to go to another microservice.Which of the following features of Application Load Balancers can be used for this use-case?,B,B,Host-based Routing,Path-based Routing,HTTP header-based routing,Query string parameter-based routing,,,,전자상거래 스타트업의 개발 팀은 Application Load Balancer 아래의 EC2 인스턴스에서 실행되는 여러 마이크로서비스를 설정했습니다. 팀은 HTTP 헤더의 URL 경로를 기반으로 트래픽을 여러 백엔드 서비스로 라우팅하려고 합니다. 따라서 https://www.example.com/orders에 대한 요청이 특정 마이크로 서비스로 이동하고 https://www.example.com/products에 대한 요청이 다른 마이크로 서비스로 이동하기를 원합니다.Application Load Balancer의 다음 기능 중 이 사용 사례에 사용할 수 있는 것은 무엇입니까?,호스트 기반 라우팅,경로 기반 라우팅,HTTP 헤더 기반 라우팅,쿼리 문자열 매개변수 기반 라우팅,,,0,,
udemy,CLF-01,62,"A data analytics company measures what the consumers watch and what advertising they’re exposed to. This real-time data is ingested into its on-premises data center and subsequently, the daily data feed is compressed into a single file and uploaded on Amazon S3 for backup. The typical compressed file size is around 2 GB.Which of the following is the fastest way to upload the daily compressed file into S3?",A,A,Upload the compressed file using multipart upload with S3 transfer acceleration,Upload the compressed file using multipart upload,FTP the compressed file into an EC2 instance that runs in the same region as the S3 bucket. Then transfer the file from the EC2 instance into the S3 bucket,Upload the compressed file in a single operation,,,,데이터 분석 회사는 소비자가 무엇을 보고 어떤 광고에 노출되는지 측정합니다. 이 실시간 데이터는 온프레미스 데이터 센터로 수집된 후 일일 데이터 피드가 단일 파일로 압축되고 백업을 위해 Amazon S3에 업로드됩니다. 일반적인 압축 파일 크기는 약 2GB입니다.다음 중 매일 압축된 파일을 S3에 업로드하는 가장 빠른 방법은 무엇입니까?,S3 전송 가속화와 함께 멀티파트 업로드를 사용하여 압축 파일 업로드,멀티파트 업로드를 사용하여 압축 파일 업로드,압축 파일을 S3 버킷과 동일한 리전에서 실행되는 EC2 인스턴스로 FTP합니다. 그런 다음 EC2 인스턴스에서 S3 버킷으로 파일을 전송합니다.,단일 작업으로 압축 파일 업로드,,,0,,
udemy,CLF-01,63,"The payroll department at a company initiates several computationally intensive workloads on EC2 instances at a designated hour on the last day of every month. The payroll department has noticed a trend of severe performance lag during this hour. The engineering team has figured out a solution by using Auto Scaling Group for these EC2 instances and making sure that 10 EC2 instances are available during this peak usage hour. For normal operations only 2 EC2 instances are enough to cater to the workload.As a solutions architect, which of the following steps would you recommend to implement the solution?",A,A,Configure your Auto Scaling group by creating a scheduled action that kicks-off at the designated hour on the last day of the month. Set the desired capacity of instances to 10. This causes the scale-out to happen before peak traffic kicks in at the designated hour,Configure your Auto Scaling group by creating a scheduled action that kicks-off at the designated hour on the last day of the month. Set the min count as well as the max count of instances to 10. This causes the scale-out to happen before peak traffic kicks in at the designated hour,Configure your Auto Scaling group by creating a simple tracking policy and setting the instance count to 10 at the designated hour. This causes the scale-out to happen before peak traffic kicks in at the designated hour,Configure your Auto Scaling group by creating a target tracking policy and setting the instance count to 10 at the designated hour. This causes the scale-out to happen before peak traffic kicks in at the designated hour,,,,회사의 급여 부서는 매달 마지막 날 지정된 시간에 EC2 인스턴스에서 여러 컴퓨팅 집약적 워크로드를 시작합니다. 급여 부서는 이 시간 동안 심각한 성능 지연 경향을 발견했습니다. 엔지니어링 팀은 이러한 EC2 인스턴스에 대해 Auto Scaling Group을 사용하고 이 피크 사용 시간 동안 10개의 EC2 인스턴스를 사용할 수 있도록 하는 솔루션을 찾았습니다. 일반 작업의 경우 2개의 EC2 인스턴스만 있으면 워크로드를 처리하기에 충분합니다.솔루션 설계자로서 다음 중 솔루션 구현을 위해 권장하는 단계는 무엇입니까?,매월 마지막 날 지정된 시간에 시작되는 예약 작업을 생성하여 Auto Scaling 그룹을 구성합니다. 인스턴스의 원하는 용량을 10으로 설정합니다. 이렇게 하면 지정된 시간에 최대 트래픽이 시작되기 전에 확장이 발생합니다.,매월 마지막 날 지정된 시간에 시작되는 예약 작업을 생성하여 Auto Scaling 그룹을 구성합니다. 최소 인스턴스 수와 최대 인스턴스 수를 10으로 설정합니다. 이렇게 하면 지정된 시간에 피크 트래픽이 시작되기 전에 확장이 발생합니다.,간단한 추적 정책을 생성하고 지정된 시간에 인스턴스 수를 10으로 설정하여 Auto Scaling 그룹을 구성합니다. 이렇게 하면 지정된 시간에 피크 트래픽이 시작되기 전에 확장이 발생합니다.,대상 추적 정책을 생성하고 지정된 시간에 인스턴스 수를 10으로 설정하여 Auto Scaling 그룹을 구성합니다. 이렇게 하면 지정된 시간에 피크 트래픽이 시작되기 전에 확장이 발생합니다.,,,0,,
udemy,CLF-01,64,A retail company has set up a Network Load Balancer (NLB) having a target group that is configured to use an Amazon EC2 Auto Scaling group with multiple EC2 instances (across 3 Availability Zones) that run the web service. The company is getting poor feedback from its customers regarding the application's availability as the NLB is unable to detect HTTP errors for the application. These HTTP errors require a manual restart of the EC2 instances that run the web service.The company has hired you as an AWS Certified Solutions Architect Associate to build the best-fit solution that does not require custom development/scripting effort. Which of the following will you suggest?,D,D,Configure HTTP health checks on the Network Load Balancer (NLB) by pointing to the URL of the application. Leverage the Auto Scaling group to replace unhealthy instances,"Set up a cron job on the EC2 instances to inspect the web application's logs at a regular frequency. When HTTP errors are detected, force an application restart",Set up a CloudWatch alarm to monitor the UnhealthyHostCount metric for the NLB. Leverage the Auto Scaling group to replace unhealthy instances when the alarm is in the ALARM state,Replace the Network Load Balancer (NLB) with an Application Load Balancer (ALB) and configure HTTP health checks on the ALB by pointing to the URL of the application. Leverage the Auto Scaling group to replace unhealthy instances,,,,소매 회사는 웹 서비스를 실행하는 여러 EC2 인스턴스(가용 영역 3개에 걸쳐)와 함께 Amazon EC2 Auto Scaling 그룹을 사용하도록 구성된 대상 그룹이 있는 NLB(Network Load Balancer)를 설정했습니다. NLB가 응용 프로그램에 대한 HTTP 오류를 감지할 수 없기 때문에 회사는 응용 프로그램의 가용성에 대해 고객으로부터 좋지 않은 피드백을 받고 있습니다. 이러한 HTTP 오류는 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 다시 시작해야 합니다.이 회사는 맞춤형 개발/스크립팅 노력이 필요하지 않은 최적의 솔루션을 구축하기 위해 귀하를 AWS 공인 솔루션 아키텍트 어소시에이트로 고용했습니다. 다음 중 무엇을 제안하시겠습니까?,애플리케이션의 URL을 지정하여 NLB(Network Load Balancer)에서 HTTP 상태 확인을 구성합니다. Auto Scaling 그룹을 활용하여 비정상 인스턴스 교체,정기적으로 웹 애플리케이션의 로그를 검사하도록 EC2 인스턴스에 cron 작업을 설정합니다. HTTP 오류가 감지되면 애플리케이션을 강제로 다시 시작합니다.,NLB에 대한 UnhealthyHostCount 지표를 모니터링하도록 CloudWatch 경보를 설정합니다. 경보가 ALARM 상태일 때 Auto Scaling 그룹을 활용하여 비정상 인스턴스 교체,NLB(Network Load Balancer)를 ALB(Application Load Balancer)로 교체하고 애플리케이션의 URL을 지정하여 ALB에서 HTTP 상태 확인을 구성합니다. Auto Scaling 그룹을 활용하여 비정상 인스턴스 교체,,,0,,
udemy,CLF-01,65,"CloudFront offers a multi-tier cache in the form of regional edge caches that improve latency. However, there are certain content types that bypass the regional edge cache, and go directly to the origin.Which of the following content types skip the regional edge cache? (Select two)",AD,AD,"Dynamic content, as determined at request time (cache-behavior configured to forward all headers)",User-generated videos,"Static content such as style sheets, JavaScript files",Proxy methods PUT/POST/PATCH/OPTIONS/DELETE go directly to the origin,E-commerce assets such as product photos,,,CloudFront는 지연 시간을 개선하는 지역 에지 캐시 형태의 다중 계층 캐시를 제공합니다. 그러나 지역 에지 캐시를 우회하고 오리진으로 직접 이동하는 특정 콘텐츠 유형이 있습니다.다음 중 리전 에지 캐시를 건너뛰는 콘텐츠 유형은 무엇인가요? (2개 선택),요청 시 결정되는 동적 콘텐츠(모든 헤더를 전달하도록 구성된 캐시 동작),사용자 제작 동영상,"스타일 시트, JavaScript 파일과 같은 정적 콘텐츠",프록시 메소드 PUT/POST/PATCH/OPTIONS/DELETE는 원본으로 직접 이동합니다.,제품 사진과 같은 전자상거래 자산,,0,,
udemy,CLF-01,66,"A media company is migrating its flagship application from its on-premises data center to AWS for improving the application's read-scaling capability as well as its availability. The existing architecture leverages a Microsoft SQL Server database that sees a heavy read load. The engineering team does a full copy of the production database at the start of the business day to populate a dev database. During this period, application users face high latency leading to a bad user experience.The company is looking at alternate database options and migrating database engines if required. What would you suggest?",D,D,Leverage Amazon RDS for SQL server with a Multi-AZ deployment and read replicas. Use the read replica as the dev database,Leverage Amazon RDS for MySQL with a Multi-AZ deployment and use the standby instance as the dev database,Leverage Amazon Aurora MySQL with Multi-AZ Aurora Replicas and restore the dev database via mysqldump,Leverage Amazon Aurora MySQL with Multi-AZ Aurora Replicas and create the dev database by restoring from the automated backups of Amazon Aurora,,,,한 미디어 회사는 애플리케이션의 읽기 확장 기능과 가용성을 개선하기 위해 주력 애플리케이션을 온프레미스 데이터 센터에서 AWS로 마이그레이션하고 있습니다. 기존 아키텍처는 읽기 로드가 많은 Microsoft SQL Server 데이터베이스를 활용합니다. 엔지니어링 팀은 영업일 시작 시 프로덕션 데이터베이스의 전체 복사본을 만들어 개발 데이터베이스를 채웁니다. 이 기간 동안 애플리케이션 사용자는 지연 시간이 길어져 사용자 경험이 좋지 않습니다.회사는 대체 데이터베이스 옵션을 찾고 필요한 경우 데이터베이스 엔진을 마이그레이션하고 있습니다. 무엇을 제안하시겠습니까?,다중 AZ 배포 및 읽기 전용 복제본이 있는 SQL 서버용 Amazon RDS를 활용합니다. 읽기 전용 복제본을 dev 데이터베이스로 사용,다중 AZ 배포와 함께 Amazon RDS for MySQL을 활용하고 대기 인스턴스를 개발 데이터베이스로 사용,다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL을 활용하고 mysqldump를 통해 dev 데이터베이스를 복원합니다.,다중 AZ Aurora 복제본과 함께 Amazon Aurora MySQL을 활용하고 Amazon Aurora의 자동 백업에서 복원하여 개발 데이터베이스 생성,,,0,,
udemy,CLF-01,67,"A silicon valley based startup has a content management application with the web-tier running on EC2 instances and the database tier running on Amazon Aurora. Currently, the entire infrastructure is located in us-east-1 region. The startup has 90% of its customers in the US and Europe. The engineering team is getting reports of deteriorated application performance from customers in Europe with high application load time.As a solutions architect, which of the following would you recommend addressing these performance issues? (Select two)",BD,BD,Setup another fleet of EC2 instances for the web tier in the eu-west-1 region. Enable failover routing policy in Route 53,Create Amazon Aurora read replicas in the eu-west-1 region,Create Amazon Aurora Multi-AZ standby instance in the eu-west-1 region,Setup another fleet of EC2 instances for the web tier in the eu-west-1 region. Enable latency routing policy in Route 53,Setup another fleet of EC2 instances for the web tier in the eu-west-1 region. Enable geolocation routing policy in Route 53,,,실리콘 밸리 기반 스타트업에는 EC2 인스턴스에서 실행되는 웹 계층과 Amazon Aurora에서 실행되는 데이터베이스 계층이 있는 콘텐츠 관리 애플리케이션이 있습니다. 현재 전체 인프라는 us-east-1 지역에 있습니다. 이 스타트업은 미국과 유럽에 고객의 90%를 보유하고 있습니다. 엔지니어링 팀은 애플리케이션 로드 시간이 긴 유럽 고객으로부터 애플리케이션 성능 저하에 대한 보고를 받고 있습니다.다음 중 솔루션 설계자로서 이러한 성능 문제를 해결하기 위해 권장하는 것은 무엇입니까? (2개 선택),eu-west-1 리전에서 웹 계층에 대한 다른 EC2 인스턴스 플릿을 설정합니다. Route 53에서 장애 조치 라우팅 정책 활성화,eu-west-1 리전에서 Amazon Aurora 읽기 전용 복제본 생성,eu-west-1 리전에서 Amazon Aurora 다중 AZ 대기 인스턴스 생성,eu-west-1 리전에서 웹 계층에 대한 다른 EC2 인스턴스 플릿을 설정합니다. Route 53에서 지연 시간 라우팅 정책 활성화,eu-west-1 리전에서 웹 계층에 대한 다른 EC2 인스턴스 플릿을 설정합니다. Route 53에서 지리적 위치 라우팅 정책 활성화,,0,,
udemy,CLF-01,68,You would like to migrate an AWS account from an AWS Organization A to an AWS Organization B. What are the steps do to it?,A,A,Remove the member account from the old organization. Send an invite to the member account from the new Organization. Accept the invite to the new organization from the member account,Send an invite to the new organization. Accept the invite to the new organization from the member account. Remove the member account from the old organization,Send an invite to the new organization. Remove the member account from the old organization. Accept the invite to the new organization from the member account,Open an AWS Support ticket to ask them to migrate the account,,,,AWS Organization A에서 AWS Organization B로 AWS 계정을 마이그레이션하려고 합니다. 이를 위한 단계는 무엇입니까?,이전 조직에서 멤버 계정을 제거합니다. 새 조직에서 멤버 계정으로 초대를 보냅니다. 회원 계정에서 새 조직에 대한 초대를 수락합니다.,새 조직에 초대를 보냅니다. 회원 계정에서 새 조직에 대한 초대를 수락합니다. 이전 조직에서 멤버 계정 제거,새 조직에 초대를 보냅니다. 이전 조직에서 멤버 계정을 제거합니다. 회원 계정에서 새 조직에 대한 초대를 수락합니다.,AWS Support 티켓을 열어 계정 마이그레이션을 요청하십시오.,,,0,,
udemy,CLF-01,69,You have been hired as a Solutions Architect to advise a company on the various authentication/authorization mechanisms that AWS offers to authorize an API call within the API Gateway. The company would prefer a solution that offers built-in user management.Which of the following solutions would you suggest as the best fit for the given use-case?,B,B,Use API Gateway Lambda authorizer,Use Amazon Cognito User Pools,Use Amazon Cognito Identity Pools,Use AWS_IAM authorization,,,,귀하는 API 게이트웨이 내에서 API 호출을 승인하기 위해 AWS가 제공하는 다양한 인증/권한 부여 메커니즘에 대해 회사에 조언하는 솔루션 아키텍트로 고용되었습니다. 회사는 기본 제공 사용자 관리를 제공하는 솔루션을 선호합니다.다음 중 주어진 사용 사례에 가장 적합한 솔루션은 무엇입니까?,API Gateway Lambda 권한 부여자 사용,Amazon Cognito 사용자 풀 사용,Amazon Cognito 자격 증명 풀 사용,AWS_IAM 권한 부여 사용,,,0,,
udemy,CLF-01,70,"Your company has a monthly big data workload, running for about 2 hours, which can be efficiently distributed across multiple servers of various sizes, with a variable number of CPUs. The solution for the workload should be able to withstand server failures.Which is the MOST cost-optimal solution for this workload?",B,B,Run the workload on Spot Instances,Run the workload on a Spot Fleet,Run the workload on Reserved Instances,Run the workload on Dedicated Hosts,,,,귀하의 회사에는 약 2시간 동안 실행되는 월별 빅 데이터 워크로드가 있으며 가변 개수의 CPU를 사용하여 다양한 크기의 여러 서버에 효율적으로 분산될 수 있습니다. 워크로드에 대한 솔루션은 서버 오류를 견딜 수 있어야 합니다.이 워크로드에 가장 비용 효율적인 솔루션은 무엇입니까?,스팟 인스턴스에서 워크로드 실행,스팟 플릿에서 워크로드 실행,예약 인스턴스에서 워크로드 실행,전용 호스트에서 워크로드 실행,,,0,,
udemy,CLF-01,71,A cybersecurity company uses a fleet of EC2 instances to run a proprietary application. The infrastructure maintenance group at the company wants to be notified via an email whenever the CPU utilization for any of the EC2 instances breaches a certain threshold.Which of the following services would you use for building a solution with the LEAST amount of development effort? (Select two),BC,BC,AWS Step Functions,Amazon CloudWatch,Amazon SNS,AWS Lambda,Amazon SQS,,,사이버 보안 회사는 독점 애플리케이션을 실행하기 위해 여러 EC2 인스턴스를 사용합니다. 회사의 인프라 유지 관리 그룹은 EC2 인스턴스의 CPU 사용률이 특정 임계값을 초과할 때마다 이메일을 통해 알림을 받기를 원합니다.최소한의 개발 노력으로 솔루션을 구축하기 위해 다음 중 어떤 서비스를 사용하시겠습니까? (2개 선택),AWS 단계 기능,아마존 클라우드워치,아마존 SNS,AWS 람다,아마존 SQS,,0,,
udemy,CLF-01,72,The engineering manager for a content management application wants to set up RDS read replicas to provide enhanced performance and read scalability. The manager wants to understand the data transfer charges while setting up RDS read replicas.Which of the following would you identify as correct regarding the data transfer charges for RDS read replicas?,D,D,There are data transfer charges for replicating data within the same AWS Region,There are data transfer charges for replicating data within the same Availability Zone,There are no data transfer charges for replicating data across AWS Regions,There are data transfer charges for replicating data across AWS Regions,,,,콘텐츠 관리 애플리케이션의 엔지니어링 관리자는 향상된 성능과 읽기 확장성을 제공하기 위해 RDS 읽기 복제본을 설정하려고 합니다. 관리자는 RDS 읽기 전용 복제본을 설정하는 동안 데이터 전송 요금을 이해하려고 합니다.다음 중 RDS 읽기 복제본의 데이터 전송 요금과 관련하여 올바른 것으로 식별하는 것은 무엇입니까?,동일한 AWS 리전 내에서 데이터 복제에 대한 데이터 전송 요금이 있습니다.,동일한 가용 영역 내에서 데이터 복제에 대한 데이터 전송 요금이 있습니다.,AWS 리전 간 데이터 복제에 대한 데이터 전송 요금은 없습니다.,AWS 리전 간 데이터 복제에 대한 데이터 전송 요금이 있습니다.,,,0,,
udemy,CLF-01,73,"A developer has configured inbound traffic for the relevant ports in both the Security Group of the EC2 instance as well as the Network Access Control List (NACL) of the subnet for the EC2 instance. The developer is, however, unable to connect to the service running on the Amazon EC2 instance.As a solutions architect, how will you fix this issue?",B,B,"Network ACLs are stateful, so allowing inbound traffic to the necessary ports enables the connection. Security Groups are stateless, so you must allow both inbound and outbound traffic","Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must allow both inbound and outbound traffic",IAM Role defined in the Security Group is different from the IAM Role that is given access in the Network ACLs,Rules associated with Network ACLs should never be modified from command line. An attempt to modify rules from command line blocks the rule and results in an erratic behavior,,,,개발자는 EC2 인스턴스의 보안 그룹과 EC2 인스턴스에 대한 서브넷의 NACL(네트워크 액세스 제어 목록) 모두에서 관련 포트에 대한 인바운드 트래픽을 구성했습니다. 그러나 개발자는 Amazon EC2 인스턴스에서 실행 중인 서비스에 연결할 수 없습니다.솔루션 설계자로서 이 문제를 어떻게 해결할 것입니까?,네트워크 ACL은 상태 저장이므로 필요한 포트에 대한 인바운드 트래픽을 허용하면 연결이 활성화됩니다. 보안 그룹은 상태 비저장이므로 인바운드 및 아웃바운드 트래픽을 모두 허용해야 합니다.,보안 그룹은 상태 저장이므로 필요한 포트에 대한 인바운드 트래픽을 허용하면 연결이 활성화됩니다. 네트워크 ACL은 상태 비저장이므로 인바운드 및 아웃바운드 트래픽을 모두 허용해야 합니다.,보안 그룹에 정의된 IAM 역할이 네트워크 ACL에서 액세스 권한이 부여된 IAM 역할과 다릅니다.,네트워크 ACL과 관련된 규칙은 명령줄에서 수정하면 안 됩니다. 명령줄에서 규칙을 수정하려고 하면 규칙이 차단되고 비정상적인 동작이 발생합니다.,,,0,,
udemy,CLF-01,74,"Your company has an on-premises Distributed File System Replication (DFSR) service to keep files synchronized on multiple Windows servers, and would like to migrate to AWS cloud.What do you recommend as a replacement for the DFSR?",D,D,FSx for Lustre,Amazon S3,EFS,FSx for Windows,,,,귀사는 여러 Windows 서버에서 파일 동기화를 유지하기 위한 온프레미스 DFSR(Distributed File System Replication) 서비스를 보유하고 있으며 AWS 클라우드로 마이그레이션하려고 합니다.DFSR의 대체품으로 무엇을 권장합니까?,광택을 위한 FSx,아마존 S3,EFS,윈도우용 FSx,,,0,,
udemy,CLF-01,75,"The engineering team at a logistics company has noticed that the Auto Scaling group (ASG) is not terminating an unhealthy Amazon EC2 instance.As a Solutions Architect, which of the following options would you suggest to troubleshoot the issue? (Select three)",ADF,ADF,The instance has failed the ELB health check status,A user might have updated the configuration of ASG and increased the minimum number of instances forcing ASG to keep all instances alive,A custom health check might have failed. ASG does not terminate instances that are set unhealthy by custom checks,The health check grace period for the instance has not expired,"The EC2 instance could be a spot instance type, which cannot be terminated by ASG",The instance maybe in Impaired status,,물류 회사의 엔지니어링 팀은 Auto Scaling 그룹(ASG)이 비정상 Amazon EC2 인스턴스를 종료하지 않는다는 사실을 확인했습니다.솔루션 설계자로서 문제 해결을 위해 다음 중 어떤 옵션을 제안하시겠습니까? (3개 선택),인스턴스가 ELB 상태 확인에 실패했습니다.,사용자가 ASG의 구성을 업데이트하고 ASG가 모든 인스턴스를 활성 상태로 유지하도록 하는 최소 인스턴스 수를 늘렸을 수 있습니다.,사용자 지정 상태 확인이 실패했을 수 있습니다. ASG는 사용자 지정 검사에 의해 비정상으로 설정된 인스턴스를 종료하지 않습니다.,인스턴스의 상태 확인 유예 기간이 만료되지 않았습니다.,EC2 인스턴스는 ASG에서 종료할 수 없는 스팟 인스턴스 유형일 수 있습니다.,,0,,인스턴스가 손상됨 상태일 수 있음
udemy,CLF-01,76,"What does this IAM policy do?{  ""Version"": ""2012-10-17"",  ""Statement"": [    {      ""Sid"": ""Mystery Policy"",      ""Action"": [        ""ec2:RunInstances""      ],      ""Effect"": ""Allow"",      ""Resource"": ""*"",      ""Condition"": {        ""IpAddress"": {          ""aws:SourceIp"": ""34.50.31.0/24""        }      }    }  ]}",B,B,It allows starting EC2 instances only when they have a Public IP within the 34.50.31.0/24 CIDR block,It allows starting EC2 instances only when the IP where the call originates is within the 34.50.31.0/24 CIDR block,It allows starting EC2 instances only when they have a Private IP within the 34.50.31.0/24 CIDR block,It allows starting EC2 instances only when they have an Elastic IP within the 34.50.31.0/24 CIDR block,,,,"이 IAM 정책은 무엇을 합니까?{  ""Version"": ""2012-10-17"",  ""Statement"": [    {      ""Sid"": ""Mystery Policy"",      ""Action"": [        ""ec2:RunInstances""      ],      ""Effect"": ""Allow"",      ""Resource"": ""*"",      ""Condition"": {        ""IpAddress"": {          ""aws:SourceIp"": ""34.50.31.0/24""        }      }    }  ]}",34.50.31.0/24CIDR 블록 내에 퍼블릭 IP가 있는 경우에만 EC2 인스턴스 시작을 허용합니다.,호출이 시작된 IP가 34.50.31.0/24CIDR 블록 내에 있는 경우에만 EC2 인스턴스 시작을 허용합니다.,34.50.31.0/24CIDR 블록 내에 개인 IP가 있는 경우에만 EC2 인스턴스 시작을 허용합니다.,34.50.31.0/24CIDR 블록 내에 탄력적 IP가 있는 경우에만 EC2 인스턴스 시작을 허용합니다.,,,0,,
udemy,CLF-01,77,What is true about RDS Read Replicas encryption?,B,B,"If the master database is unencrypted, the read replicas are encrypted","If the master database is encrypted, the read replicas are encrypted","If the master database is encrypted, the read replicas can be either encrypted or unencrypted","If the master database is unencrypted, the read replicas can be either encrypted or unencrypted",,,,RDS 읽기 전용 복제본 암호화에 대한 설명으로 옳은 것은 무엇입니까?,마스터 데이터베이스가 암호화되지 않은 경우 읽기 전용 복제본이 암호화됩니다.,마스터 데이터베이스가 암호화된 경우 읽기 전용 복제본도 암호화됩니다.,마스터 데이터베이스가 암호화된 경우 읽기 복제본은 암호화되거나 암호화되지 않을 수 있습니다.,마스터 데이터베이스가 암호화되지 않은 경우 읽기 복제본은 암호화되거나 암호화되지 않을 수 있습니다.,,,0,,
udemy,CLF-01,78,"A Machine Learning research group uses a proprietary computer vision application hosted on an EC2 instance. Every time the instance needs to be stopped and started again, the application takes about 3 minutes to start as some auxiliary software programs need to be executed so that the application can function. The research group would like to minimize the application boostrap time whenever the system needs to be stopped and then started at a later point in time.As a solutions architect, which of the following solutions would you recommend for this use-case?",A,A,Use EC2 Instance Hibernate,Use EC2 Meta-Data,Create an AMI and launch your EC2 instances from that,Use EC2 User-Data,,,,기계 학습 연구 그룹은 EC2 인스턴스에서 호스팅되는 독점 컴퓨터 비전 애플리케이션을 사용합니다. 인스턴스를 중지했다가 다시 시작해야 할 때마다 애플리케이션이 작동하려면 일부 보조 소프트웨어 프로그램을 실행해야 하므로 애플리케이션을 시작하는 데 약 3분이 걸립니다. 연구 그룹은 시스템을 중지한 다음 나중에 시작해야 할 때마다 애플리케이션 부스트랩 시간을 최소화하려고 합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 중 어떤 솔루션을 추천하시겠습니까?,EC2 인스턴스 최대 절전 모드 사용,EC2 메타데이터 사용,AMI를 생성하고 해당 위치에서 EC2 인스턴스를 시작합니다.,EC2 사용자 데이터 사용,,,0,,
udemy,CLF-01,79,"Amazon EC2 Auto Scaling needs to terminate an instance from Availability Zone (AZ) us-east-1a as it has the most number of instances amongst the AZs being used currently. There are 4 instances in the AZ us-east-1a like so: Instance A has the oldest launch template, Instance B has the oldest launch configuration, Instance C has the newest launch configuration and Instance D is closest to the next billing hour.Which of the following instances would be terminated per the default termination policy?",B,B,Instance A,Instance B,Instance C,Instance D,,,,"us-east-1aAmazon EC2 Auto Scaling 은 현재 사용 중인 AZ(가용 영역) 중에서 인스턴스 수가 가장 많기 때문에 가용 영역(AZ)에서 인스턴스를 종료해야 합니다 . AZ에는 us-east-1a다음과 같은 4개의 인스턴스가 있습니다. 인스턴스 A에는 가장 오래된 시작 템플릿이 있고, 인스턴스 B에는 가장 오래된 시작 구성이 있으며, 인스턴스 C에는 최신 시작 구성이 있고, 인스턴스 D는 다음 결제 시간에 가장 가깝습니다.다음 중 기본 종료 정책에 따라 종료되는 인스턴스는 무엇입니까?",인스턴스 A,인스턴스 B,인스턴스 C,인스턴스 D,,,0,,
udemy,CLF-01,80,A company is developing a healthcare application that cannot afford any downtime for database write operations. The company has hired you as an AWS Certified Solutions Architect Associate to build a solution using Amazon Aurora.Which of the following options would you recommend?,A,A,Set up an Aurora multi-master DB cluster,Set up an Aurora provisioned DB cluster,Set up an Aurora Global Database cluster,Set up an Aurora serverless DB cluster,,,,회사에서 데이터베이스 쓰기 작업을 위한 중단 시간을 허용할 수 없는 의료 응용 프로그램을 개발하고 있습니다. 회사는 Amazon Aurora를 사용하여 솔루션을 구축하기 위해 귀하를 AWS Certified Solutions Architect Associate로 고용했습니다.다음 중 어떤 옵션을 추천하시겠습니까?,Aurora 다중 마스터 DB 클러스터 설정,Aurora 프로비저닝된 DB 클러스터 설정,Aurora 글로벌 데이터베이스 클러스터 설정,Aurora 서버리스 DB 클러스터 설정,,,0,,
udemy,CLF-01,81,A health-care solutions company wants to run their applications on single-tenant hardware to meet regulatory guidelines.Which of the following is the MOST cost-effective way of isolating their Amazon EC2 instances to a single tenant?,A,A,Dedicated Instances,Spot Instances,On-Demand Instances,Dedicated Hosts,,,,의료 솔루션 회사는 규제 지침을 충족하기 위해 단일 테넌트 하드웨어에서 애플리케이션을 실행하려고 합니다.다음 중 Amazon EC2 인스턴스를 단일 테넌트로 격리하는 가장 비용 효율적인 방법은 무엇입니까?,전용 인스턴스,스팟 인스턴스,온디맨드 인스턴스,전용 호스트,,,0,,
udemy,CLF-01,82,"You are establishing a monitoring solution for desktop systems, that will be sending telemetry data into AWS every 1 minute. Data for each system must be processed in order, independently, and you would like to scale the number of consumers to be possibly equal to the number of desktop systems that are being monitored.What do you recommend?",C,C,"Use a Kinesis Data Stream, and send the telemetry data with a Partition ID that uses the value of the Desktop ID","Use an SQS FIFO queue, and send the telemetry data as is","Use an SQS FIFO queue, and make sure the telemetry data is sent with a Group ID attribute representing the value of the Desktop ID","Use an SQS standard queue, and send the telemetry data as is",,,,1분마다 원격 분석 데이터를 AWS로 보낼 데스크톱 시스템용 모니터링 솔루션을 구축하고 있습니다. 각 시스템의 데이터는 순서대로 독립적으로 처리되어야 하며 소비자 수를 모니터링 중인 데스크톱 시스템 수와 동일하게 조정하려고 합니다.추천 메뉴가 무엇인가요?,Kinesis Data Stream을 사용하고 데스크톱 ID 값을 사용하는 파티션 ID와 함께 원격 측정 데이터를 보냅니다.,SQS FIFO 대기열을 사용하고 텔레메트리 데이터를 있는 그대로 보냅니다.,SQS FIFO 대기열을 사용하고 데스크톱 ID 값을 나타내는 그룹 ID 특성과 함께 원격 측정 데이터가 전송되는지 확인합니다.,SQS 표준 대기열을 사용하고 원격 측정 데이터를 있는 그대로 전송,,,0,,
udemy,CLF-01,83,"An HTTP application is deployed on an Auto Scaling Group, is accessible from an Application Load Balancer that provides HTTPS termination, and accesses a PostgreSQL database managed by RDS.How should you configure the security groups? (Select three)",ABD,ABD,The security group of the ALB should have an inbound rule from anywhere on port 443,The security group of RDS should have an inbound rule from the security group of the EC2 instances in the ASG on port 5432,The security group of the EC2 instances should have an inbound rule from the security group of the RDS database on port 5432,The security group of the EC2 instances should have an inbound rule from the security group of the ALB on port 80,The security group of the ALB should have an inbound rule from anywhere on port 80,The security group of RDS should have an inbound rule from the security group of the EC2 instances in the ASG on port 80,,HTTP 애플리케이션은 Auto Scaling 그룹에 배포되고 HTTPS 종료를 제공하는 Application Load Balancer에서 액세스할 수 있으며 RDS에서 관리하는 PostgreSQL 데이터베이스에 액세스합니다.보안 그룹을 어떻게 구성해야 합니까? (3개 선택),ALB의 보안 그룹에는 포트 443의 모든 곳에서 인바운드 규칙이 있어야 합니다.,RDS의 보안 그룹에는 포트 5432의 ASG에 있는 EC2 인스턴스의 보안 그룹에서 인바운드 규칙이 있어야 합니다.,EC2 인스턴스의 보안 그룹에는 포트 5432의 RDS 데이터베이스 보안 그룹의 인바운드 규칙이 있어야 합니다.,EC2 인스턴스의 보안 그룹에는 포트 80에서 ALB 보안 그룹의 인바운드 규칙이 있어야 합니다.,ALB의 보안 그룹에는 포트 80의 모든 위치에서 인바운드 규칙이 있어야 합니다.,,0,,RDS의 보안 그룹에는 포트 80의 ASG에 있는 EC2 인스턴스의 보안 그룹에서 인바운드 규칙이 있어야 합니다.
udemy,CLF-01,84,"A junior DevOps engineer wants to change the default configuration for EBS volume termination. By default, the root volume of an EC2 instance for an EBS-backed AMI is deleted when the instance terminates.Which option below helps change this default behavior to ensure that the volume persists even after the instance terminates?",B,B,Set the TerminateOnDelete attribute to true,Set the DeleteOnTermination attribute to false,Set the TerminateOnDelete attribute to false,Set the DeleteOnTermination attribute to true,,,,하급 DevOps 엔지니어가 EBS 볼륨 종료를 위한 기본 구성을 변경하려고 합니다. 기본적으로 EBS 지원 AMI에 대한 EC2 인스턴스의 루트 볼륨은 인스턴스가 종료될 때 삭제됩니다.다음 중 인스턴스가 종료된 후에도 볼륨이 지속되도록 이 기본 동작을 변경하는 데 도움이 되는 옵션은 무엇입니까?,TerminateOnDelete 특성을 true로 설정합니다.,DeleteOnTermination 특성을 false로 설정합니다.,TerminateOnDelete 특성을 false로 설정합니다.,DeleteOnTermination 특성을 true로 설정합니다.,,,0,,
udemy,CLF-01,85,"A social media application is hosted on an EC2 server fleet running behind an Application Load Balancer. The application traffic is fronted by a CloudFront distribution. The engineering team wants to decouple the user authentication process for the application, so that the application servers can just focus on the business logic.As a Solutions Architect, which of the following solutions would you recommend to the development team so that it requires minimal development effort?",A,A,Use Cognito Authentication via Cognito User Pools for your Application Load Balancer,Use Cognito Authentication via Cognito User Pools for your CloudFront distribution,Use Cognito Authentication via Cognito Identity Pools for your CloudFront distribution,Use Cognito Authentication via Cognito Identity Pools for your Application Load Balancer,,,,소셜 미디어 애플리케이션은 Application Load Balancer 뒤에서 실행되는 EC2 서버 플릿에서 호스팅됩니다. 애플리케이션 트래픽은 CloudFront 배포를 통해 처리됩니다. 엔지니어링 팀은 애플리케이션 서버가 비즈니스 논리에만 집중할 수 있도록 애플리케이션에 대한 사용자 인증 프로세스를 분리하려고 합니다.솔루션 아키텍트로서 다음 중 최소한의 개발 노력이 필요하도록 개발 팀에 추천할 솔루션은 무엇입니까?,Application Load Balancer에 대해 Cognito 사용자 풀을 통해 Cognito 인증 사용,CloudFront 배포를 위해 Cognito 사용자 풀을 통해 Cognito 인증 사용,CloudFront 배포에 Cognito 자격 증명 풀을 통해 Cognito 인증 사용,Application Load Balancer용 Cognito 자격 증명 풀을 통해 Cognito 인증 사용,,,0,,
udemy,CLF-01,86,You have multiple AWS accounts within a single AWS Region managed by AWS Organizations and you would like to ensure all EC2 instances in all these accounts can communicate privately. Which of the following solutions provides the capability at the CHEAPEST cost?,B,B,Create a Transit Gateway and link all the VPC in all the accounts together,Create a VPC in an account and share one or more of its subnets with the other accounts using Resource Access Manager,Create a VPC peering connection between all VPCs,Create a Private Link between all the EC2 instances,,,,AWS Organizations에서 관리하는 단일 AWS 리전 내에 여러 AWS 계정이 있고 이러한 모든 계정의 모든 EC2 인스턴스가 비공개로 통신할 수 있는지 확인하려고 합니다. 다음 중 가장 저렴한 비용으로 기능을 제공하는 솔루션은 무엇입니까?,Transit Gateway를 생성하고 모든 계정의 모든 VPC를 함께 연결,계정에 VPC를 생성하고 Resource Access Manager를 사용하여 하나 이상의 서브넷을 다른 계정과 공유,모든 VPC 간에 VPC 피어링 연결 생성,모든 EC2 인스턴스 간에 Private Link 생성,,,0,,
udemy,CLF-01,87,"A media company has created an AWS Direct Connect connection for migrating its flagship application to the AWS Cloud. The on-premises application writes hundreds of video files into a mounted NFS file system daily. Post-migration, the company will host the application on an Amazon EC2 instance with a mounted EFS file system. Before the migration cutover, the company must build a process that will replicate the newly created on-premises video files to the EFS file system.Which of the following represents the MOST operationally efficient way to meet this requirement?",D,D,Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. Transfer data over the Direct Connect connection to an AWS VPC peering endpoint for Amazon EFS by using a private VIF. Set up a DataSync scheduled task to send the video files to the EFS file system every 24 hours,Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. Transfer data over the Direct Connect connection to an S3 bucket by using public VIF. Set up an AWS Lambda function to process event notifications from Amazon S3 and copy the video files from Amazon S3 to the EFS file system,Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. Transfer data over the Direct Connect connection to an S3 bucket by using an S3 VPC endpoint. Set up an AWS Lambda function to process event notifications from Amazon S3 and copy the video files from Amazon S3 to the EFS file system,Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. Transfer data over the Direct Connect connection to an AWS PrivateLink interface VPC endpoint for Amazon EFS by using a private VIF. Set up a DataSync scheduled task to send the video files to the EFS file system every 24 hours,,,,한 미디어 회사는 주력 애플리케이션을 AWS 클라우드로 마이그레이션하기 위해 AWS Direct Connect 연결을 생성했습니다. 온프레미스 애플리케이션은 매일 수백 개의 비디오 파일을 탑재된 NFS 파일 시스템에 기록합니다. 마이그레이션 후 회사는 탑재된 EFS 파일 시스템이 있는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 마이그레이션 컷오버 전에 회사는 새로 생성된 온프레미스 비디오 파일을 EFS 파일 시스템에 복제하는 프로세스를 구축해야 합니다.다음 중 이 요구 사항을 충족하는 가장 효율적인 운영 방법은 무엇입니까?,NFS 파일 시스템에 대한 액세스 권한이 있는 온프레미스 서버에서 AWS DataSync 에이전트를 구성합니다. 프라이빗 VIF를 사용하여 Direct Connect 연결을 통해 Amazon EFS용 AWS VPC 피어링 엔드포인트로 데이터를 전송합니다. 24시간마다 비디오 파일을 EFS 파일 시스템으로 보내도록 DataSync 예약 작업 설정,NFS 파일 시스템에 대한 액세스 권한이 있는 온프레미스 서버에서 AWS DataSync 에이전트를 구성합니다. 퍼블릭 VIF를 사용하여 Direct Connect 연결을 통해 S3 버킷으로 데이터를 전송합니다. Amazon S3의 이벤트 알림을 처리하고 Amazon S3의 비디오 파일을 EFS 파일 시스템으로 복사하도록 AWS Lambda 함수를 설정합니다.,NFS 파일 시스템에 대한 액세스 권한이 있는 온프레미스 서버에서 AWS DataSync 에이전트를 구성합니다. S3 VPC 엔드포인트를 사용하여 Direct Connect 연결을 통해 S3 버킷으로 데이터를 전송합니다. Amazon S3의 이벤트 알림을 처리하고 Amazon S3의 비디오 파일을 EFS 파일 시스템으로 복사하도록 AWS Lambda 함수를 설정합니다.,NFS 파일 시스템에 대한 액세스 권한이 있는 온프레미스 서버에서 AWS DataSync 에이전트를 구성합니다. 프라이빗 VIF를 사용하여 Direct Connect 연결을 통해 Amazon EFS용 AWS PrivateLink 인터페이스 VPC 엔드포인트로 데이터를 전송합니다. 24시간마다 비디오 파일을 EFS 파일 시스템으로 보내도록 DataSync 예약 작업 설정,,,0,,
udemy,CLF-01,88,"To improve the performance and security of the application, the engineering team at a company has created a CloudFront distribution with an Application Load Balancer as the custom origin. The team has also set up a Web Application Firewall (WAF) with CloudFront distribution. The security team at the company has noticed a surge in malicious attacks from a specific IP address to steal sensitive data stored on the EC2 instances.As a solutions architect, which of the following actions would you recommend to stop the attacks?",C,C,Create a ticket with AWS support to take action against the malicious IP,Create a deny rule for the malicious IP in the Security Groups associated with each of the instances,Create an IP match condition in the WAF to block the malicious IP address,Create a deny rule for the malicious IP in the NACL associated with each of the instances,,,,애플리케이션의 성능과 보안을 개선하기 위해 회사의 엔지니어링 팀은 Application Load Balancer를 사용자 지정 오리진으로 사용하여 CloudFront 배포를 생성했습니다. 또한 팀은 CloudFront 배포를 사용하여 웹 애플리케이션 방화벽(WAF)을 설정했습니다. 회사의 보안 팀은 EC2 인스턴스에 저장된 중요한 데이터를 훔치기 위해 특정 IP 주소에서 악의적인 공격이 급증하고 있음을 발견했습니다.솔루션 설계자로서 다음 중 공격을 중지하기 위해 권장하는 조치는 무엇입니까?,악성 IP에 대해 조치를 취하기 위해 AWS 지원으로 티켓 생성,각 인스턴스와 연결된 보안 그룹에서 악성 IP에 대한 거부 규칙 생성,악의적인 IP 주소를 차단하기 위해 WAF에서 IP 일치 조건을 만듭니다.,각 인스턴스와 연결된 NACL에서 악성 IP에 대한 거부 규칙 생성,,,0,,
udemy,CLF-01,89,"An e-commerce application uses an Amazon Aurora Multi-AZ deployment for its database. While analyzing the performance metrics, the engineering team has found that the database reads are causing high I/O and adding latency to the write requests against the database.As an AWS Certified Solutions Architect Associate, what would you recommend to separate the read requests from the write requests?",C,C,Provision another Amazon Aurora database and link it to the primary database as a read replica,Activate read-through caching on the Amazon Aurora database,Set up a read replica and modify the application to use the appropriate endpoint,Configure the application to read from the Multi-AZ standby instance,,,,전자상거래 애플리케이션은 데이터베이스에 Amazon Aurora 다중 AZ 배포를 사용합니다. 성능 메트릭을 분석하는 동안 엔지니어링 팀은 데이터베이스 읽기가 높은 I/O를 유발하고 데이터베이스에 대한 쓰기 요청에 대기 시간을 추가한다는 사실을 발견했습니다.AWS 공인 솔루션스 아키텍트 어소시에이트로서 읽기 요청과 쓰기 요청을 구분하기 위해 무엇을 추천하시겠습니까?,다른 Amazon Aurora 데이터베이스를 프로비저닝하고 기본 데이터베이스에 읽기 전용 복제본으로 연결,Amazon Aurora 데이터베이스에서 읽기 통과 캐싱 활성화,읽기 전용 복제본을 설정하고 적절한 엔드포인트를 사용하도록 애플리케이션 수정,다중 AZ 대기 인스턴스에서 읽도록 애플리케이션 구성,,,0,,
udemy,CLF-01,90,"A systems administrator has created a private hosted zone and associated it with a Virtual Private Cloud (VPC). However, the DNS queries for the private hosted zone remain unresolved.As a Solutions Architect, can you identify the Amazon VPC options to be configured in order to get the private hosted zone to work?",B,B,"Fix conflicts between your private hosted zone and any Resolver rule that routes traffic to your network for the same domain name, as it results in ambiguity over the route to be taken",Enable DNS hostnames and DNS resolution for private hosted zones,Fix the Name server (NS) record and Start Of Authority (SOA) records that may have been created with wrong configurations,Remove any overlapping namespaces for the private and public hosted zones,,,,시스템 관리자가 프라이빗 호스팅 영역을 생성하고 Virtual Private Cloud(VPC)와 연결했습니다. 그러나 프라이빗 호스팅 영역에 대한 DNS 쿼리는 확인되지 않은 상태로 유지됩니다.솔루션 아키텍트로서 프라이빗 호스팅 영역을 작동시키기 위해 구성할 Amazon VPC 옵션을 식별할 수 있습니까?,프라이빗 호스팅 영역과 동일한 도메인 이름에 대해 네트워크로 트래픽을 라우팅하는 Resolver 규칙 간의 충돌을 수정합니다. 그 결과 취할 경로가 모호해집니다.,프라이빗 호스팅 영역에 대한 DNS 호스트 이름 및 DNS 확인 활성화,잘못된 구성으로 생성되었을 수 있는 NS(이름 서버) 레코드 및 SOA(권한 시작) 레코드 수정,프라이빗 및 퍼블릭 호스팅 영역에 대해 겹치는 네임스페이스를 제거합니다.,,,0,,
udemy,CLF-01,91,"A big data consulting firm needs to set up a data lake on Amazon S3 for a Health-Care client. The data lake is split in raw and refined zones. For compliance reasons, the source data needs to be kept for a minimum of 5 years. The source data arrives in the raw zone and is then processed via an AWS Glue based ETL job into the refined zone. The business analysts run ad-hoc queries only on the data in the refined zone using AWS Athena. The team is concerned about the cost of data storage in both the raw and refined zones as the data is increasing at a rate of 1TB daily in each zone.As a solutions architect, which of the following would you recommend as the MOST cost-optimal solution? (Select two)",BD,BD,Setup a lifecycle policy to transition the refined zone data into Glacier Deep Archive after 1 day of object creation,Use Glue ETL job to write the transformed data in the refined zone using a compressed file format,Use Glue ETL job to write the transformed data in the refined zone using CSV format,Setup a lifecycle policy to transition the raw zone data into Glacier Deep Archive after 1 day of object creation,Create a Lambda function based job to delete the raw zone data after 1 day,,,빅 데이터 컨설팅 회사는 의료 서비스 고객을 위해 Amazon S3에 데이터 레이크를 설정해야 합니다. 데이터 레이크는 원시 영역과 정제된 영역으로 나뉩니다. 규정 준수를 위해 소스 데이터는 최소 5년 동안 보관해야 합니다. 원본 데이터는 원시 영역에 도착한 다음 AWS Glue 기반 ETL 작업을 통해 정제된 영역으로 처리됩니다. 비즈니스 분석가는 AWS Athena를 사용하여 정제된 영역의 데이터에 대해서만 임시 쿼리를 실행합니다. 데이터가 각 영역에서 매일 1TB의 비율로 증가하고 있기 때문에 팀은 원시 영역과 정제된 영역 모두의 데이터 스토리지 비용에 대해 우려하고 있습니다.솔루션 아키텍트로서 다음 중 가장 비용 최적화된 솔루션으로 추천하는 것은 무엇입니까? (2개 선택),객체 생성 1일 후 세분화된 영역 데이터를 Glacier Deep Archive로 전환하는 수명 주기 정책 설정,Glue ETL 작업을 사용하여 압축된 파일 형식을 사용하여 정제된 영역에 변환된 데이터 쓰기,Glue ETL 작업을 사용하여 CSV 형식을 사용하여 정제된 영역에 변환된 데이터 쓰기,객체 생성 1일 후 원시 영역 데이터를 Glacier Deep Archive로 전환하는 수명 주기 정책 설정,1일 후에 원시 영역 데이터를 삭제하는 Lambda 함수 기반 작업 생성,,0,,
udemy,CLF-01,92,An engineering team wants to examine the feasibility of the user data feature of Amazon EC2 for an upcoming project.Which of the following are true about the EC2 user data configuration? (Select two),AC,AC,"By default, user data runs only during the boot cycle when you first launch an instance","By default, user data is executed every time an EC2 instance is re-started","By default, scripts entered as user data are executed with root user privileges","When an instance is running, you can update user data by using root user credentials","By default, scripts entered as user data do not have root user privileges for executing",,,엔지니어링 팀이 user data향후 프로젝트에 대한 Amazon EC2 기능의 실행 가능성을 조사하려고 합니다.다음 중 EC2 사용자 데이터 구성에 대해 참인 것은 무엇입니까? (2개 선택),기본적으로 사용자 데이터는 인스턴스를 처음 시작할 때 부팅 주기 동안에만 실행됩니다.,기본적으로 사용자 데이터는 EC2 인스턴스가 다시 시작될 때마다 실행됩니다.,기본적으로 사용자 데이터로 입력된 스크립트는 루트 사용자 권한으로 실행됩니다.,인스턴스가 실행 중일 때 루트 사용자 자격 증명을 사용하여 사용자 데이터를 업데이트할 수 있습니다.,기본적으로 사용자 데이터로 입력된 스크립트에는 실행을 위한 루트 사용자 권한이 없습니다.,,0,,
udemy,CLF-01,93,"You have a team of developers in your company, and you would like to ensure they can quickly experiment with AWS Managed Policies by attaching them to their accounts, but you would like to prevent them from doing an escalation of privileges, by granting themselves the AdministratorAccess managed policy. How should you proceed?",A,A,"For each developer, define an IAM permission boundary that will restrict the managed policies they can attach to themselves","Attach an IAM policy to your developers, that prevents them from attaching the AdministratorAccess policy","Put the developers into an IAM group, and then define an IAM permission boundary on the group that will restrict the managed policies they can attach to themselves",Create a Service Control Policy (SCP) on your AWS account that restricts developers from attaching themselves the AdministratorAccess policy,,,,AdministratorAccess회사에 개발자 팀이 있고 그들이 AWS 관리형 정책을 자신의 계정에 연결하여 신속하게 실험할 수 있도록 하고 싶지만 관리형 정책을 스스로 부여하여 권한 상승을 방지하고 싶습니다. 정책. 어떻게 진행해야 합니까?,각 개발자에 대해 자신에게 연결할 수 있는 관리형 정책을 제한하는 IAM 권한 경계를 정의합니다.,AdministratorAccess정책을 첨부하지 못하도록 개발자에게 IAM 정책을 첨부합니다.,개발자를 IAM 그룹에 배치한 다음 그룹에서 자신에게 연결할 수 있는 관리형 정책을 제한하는 IAM 권한 경계를 정의합니다.,AdministratorAccess개발자가 정책을 첨부하지 못하도록 제한하는 서비스 제어 정책(SCP)을 AWS 계정에 생성합니다.,,,0,,
udemy,CLF-01,94,A Hollywood studio is planning a series of promotional events leading up to the launch of the trailer of its next sci-fi thriller. The executives at the studio want to create a static website with lots of animations in line with the theme of the movie. The studio has hired you as a solutions architect to build a scalable serverless solution.Which of the following represents the MOST cost-optimal and high-performance solution?,A,A,Build the website as a static website hosted on Amazon S3. Create a CloudFront distribution with Amazon S3 as the origin. Use Amazon Route 53 to create an alias record that points to your CloudFront distribution,Host the website on AWS Lambda. Create a CloudFront distribution with Lambda as the origin,Host the website on an instance in the studio's on-premises data center. Create a CloudFront distribution with this instance as the custom origin,Host the website on an EC2 instance. Create a CloudFront distribution with the EC2 instance as the custom origin,,,,한 할리우드 스튜디오가 차기 SF 스릴러의 예고편 출시를 앞두고 일련의 프로모션 이벤트를 계획하고 있습니다. 스튜디오의 경영진은 영화의 주제와 일치하는 많은 애니메이션이 포함된 정적 웹 사이트를 만들고 싶어합니다. 스튜디오는 확장 가능한 서버리스 솔루션을 구축하기 위해 귀하를 솔루션 설계자로 고용했습니다.다음 중 가장 비용 최적화된 고성능 솔루션을 나타내는 것은 무엇입니까?,Amazon S3에서 호스팅되는 정적 웹사이트로 웹사이트를 구축합니다. Amazon S3를 오리진으로 사용하여 CloudFront 배포를 생성합니다. Amazon Route 53을 사용하여 CloudFront 배포를 가리키는 별칭 레코드 생성,AWS Lambda에서 웹사이트를 호스팅합니다. Lambda를 원본으로 사용하여 CloudFront 배포 생성,스튜디오의 온프레미스 데이터 센터에 있는 인스턴스에서 웹 사이트를 호스팅합니다. 이 인스턴스를 사용자 지정 오리진으로 사용하여 CloudFront 배포 생성,EC2 인스턴스에서 웹 사이트를 호스팅합니다. EC2 인스턴스를 사용자 지정 오리진으로 사용하여 CloudFront 배포 생성,,,0,,
udemy,CLF-01,95,The engineering team at an e-commerce company is working on cost optimizations for EC2 instances. The team wants to manage the workload using a mix of on-demand and spot instances across multiple instance types. They would like to create an Auto Scaling group with a mix of these instances.Which of the following options would allow the engineering team to provision the instances for this use-case?,C,C,"You can neither use a launch configuration nor a launch template to provision capacity across multiple instance types using both On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost","You can only use a launch configuration to provision capacity across multiple instance types using both On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost","You can only use a launch template to provision capacity across multiple instance types using both On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost","You can use a launch configuration or a launch template to provision capacity across multiple instance types using both On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost",,,,전자상거래 회사의 엔지니어링 팀은 EC2 인스턴스의 비용 최적화 작업을 하고 있습니다. 팀은 여러 인스턴스 유형에서 온디맨드 및 스팟 인스턴스를 함께 사용하여 워크로드를 관리하려고 합니다. 이러한 인스턴스가 혼합된 Auto Scaling 그룹을 생성하려고 합니다.다음 중 엔지니어링 팀이 이 사용 사례에 대한 인스턴스를 프로비저닝할 수 있는 옵션은 무엇입니까?,"원하는 규모, 성능 및 비용을 달성하기 위해 시작 구성이나 시작 템플릿을 사용하여 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하는 여러 인스턴스 유형에 용량을 프로비저닝할 수 없습니다.","원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 걸쳐 용량을 프로비저닝하는 데만 시작 구성을 사용할 수 있습니다.","원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 걸쳐 용량을 프로비저닝하는 데는 시작 템플릿만 사용할 수 있습니다.","시작 구성 또는 시작 템플릿을 사용하여 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 걸쳐 용량을 프로비저닝하여 원하는 확장성, 성능 및 비용을 달성할 수 있습니다.",,,0,,
udemy,CLF-01,96,"A company has historically operated only in the us-east-1 region and stores encrypted data in S3 using SSE-KMS. As part of enhancing its security posture as well as improving the backup and recovery architecture, the company wants to store the encrypted data in S3 that is replicated into the us-west-1 AWS region. The security policies mandate that the data must be encrypted and decrypted using the same key in both AWS regions.Which of the following represents the best solution to address these requirements?",C,C,Create a CloudWatch scheduled rule to invoke a Lambda function to copy the daily data from the source bucket in us-east-1 region to the destination bucket in us-west-1 region. Provide AWS KMS key access to the Lambda function for encryption and decryption operations on the data in the source and destination S3 buckets,Change the AWS KMS single region key used for the current S3 bucket into an AWS KMS multi-region key. Enable S3 batch replication for the existing data in the current bucket in us-east-1 region into another bucket in us-west-1 region,Create a new S3 bucket in the us-east-1 region with replication enabled from this new bucket into another bucket in us-west-1 region. Enable SSE-KMS encryption on the new bucket in us-east-1 region by using an AWS KMS multi-region key. Copy the existing data from the current S3 bucket in us-east-1 region into this new S3 bucket in us-east-1 region,Enable replication for the current bucket in us-east-1 region into another bucket in us-west-1 region. Share the existing AWS KMS key from us-east-1 region to us-west-1 region,,,,한 회사는 이전에 지역에서만 운영되었으며 us-east-1SSE-KMS를 사용하여 암호화된 데이터를 S3에 저장했습니다. 보안 태세를 강화하고 백업 및 복구 아키텍처를 개선하는 일환으로 회사는 암호화된 데이터를 AWS us-west-1리전에 복제되는 S3에 저장하려고 합니다. 보안 정책에 따르면 두 AWS 리전에서 동일한 키를 사용하여 데이터를 암호화하고 해독해야 합니다.다음 중 이러한 요구 사항을 해결하기 위한 최상의 솔루션은 무엇입니까?,리전 의 소스 버킷에서 us-east-1리전의 대상 버킷 으로 일별 데이터를 복사하는 Lambda 함수를 호출하는 CloudWatch 예약 규칙을 생성합니다 us-west-1. 소스 및 대상 S3 버킷의 데이터에 대한 암호화 및 암호 해독 작업을 위해 Lambda 함수에 대한 AWS KMS 키 액세스를 제공합니다.,현재 S3 버킷에 사용되는 AWS KMS 단일 지역 키를 AWS KMS 다중 지역 키로 변경합니다. 리전 의 현재 버킷에 있는 기존 데이터를 리전 us-east-1의 다른 버킷으로 S3 배치 복제 활성화us-west-1,us-east-1이 새 버킷에서 리전의 다른 버킷으로 복제가 활성화된 리전 에서 새 S3 버킷을 생성합니다 us-west-1. us-east-1AWS KMS 멀티 리전 키를 사용하여 리전 의 새 버킷에서 SSE-KMS 암호화를 활성화합니다 . 리전 의 현재 S3 버킷에서 리전 us-east-1의 이 새 S3 버킷으로 기존 데이터를 복사합니다.us-east-1,리전 의 현재 버킷을 리전 us-east-1의 다른 버킷으로 복제를 활성화합니다 us-west-1. us-east-1리전 간 us-west-1기존 AWS KMS 키 공유,,,0,,
udemy,CLF-01,97,"You would like to mount a network file system on Linux instances, where files will be stored and accessed frequently at first, and then infrequently. What solution is the MOST cost-effective?",A,A,EFS IA,S3 Intelligent Tiering,FSx for Lustre,Glacier Deep Archive,,,,파일이 처음에는 자주 저장되고 액세스되는 Linux 인스턴스에 네트워크 파일 시스템을 마운트하려고 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?,EFS IA,S3 지능형 계층화,광택을 위한 FSx,글레이셔 딥 아카이브,,,0,,
udemy,CLF-01,98,"A big-data consulting firm is working on a client engagement where the ETL workloads are currently handled via a Hadoop cluster deployed in the on-premises data center. The client wants to migrate their ETL workloads to AWS Cloud. The AWS Cloud solution needs to be highly available with about 50 EC2 instances per Availability Zone.As a solutions architect, which of the following EC2 placement groups would you recommend handling the distributed ETL workload?",C,C,Both Spread placement group and Partition placement group,Spread placement group,Partition placement group,Cluster placement group,,,,빅 데이터 컨설팅 회사는 ETL 워크로드가 현재 온프레미스 데이터 센터에 배포된 Hadoop 클러스터를 통해 처리되는 클라이언트 계약을 진행하고 있습니다. 클라이언트는 ETL 워크로드를 AWS 클라우드로 마이그레이션하려고 합니다. AWS 클라우드 솔루션은 가용 영역당 약 50개의 EC2 인스턴스로 가용성이 높아야 합니다.솔루션 설계자로서 다음 중 분산 ETL 워크로드를 처리하도록 권장하는 EC2 배치 그룹은 무엇입니까?,스프레드 배치 그룹 및 파티션 배치 그룹 모두,스프레드 배치 그룹,파티션 배치 그룹,클러스터 배치 그룹,,,0,,
udemy,CLF-01,99,"An IT company wants to optimize the costs incurred on its fleet of 100 EC2 instances for the next year. Based on historical analyses, the engineering team observed that 70 of these instances handle the compute services of its flagship application and need to be always available. The other 30 instances are used to handle batch jobs that can afford a delay in processing.As a solutions architect, which of the following would you recommend as the MOST cost-optimal solution?",A,A,Purchase 70 reserved instances and 30 spot instances,Purchase 70 reserved instances and 30 on-demand instances,Purchase 70 on-demand instances and 30 spot instances,Purchase 70 on-demand instances and 30 reserved instances,,,,IT 회사는 내년에 100개의 EC2 인스턴스 플릿에서 발생하는 비용을 최적화하려고 합니다. 기록 분석을 기반으로 엔지니어링 팀은 이러한 인스턴스 중 70개가 플래그십 애플리케이션의 컴퓨팅 서비스를 처리하고 항상 사용 가능해야 한다는 것을 관찰했습니다. 다른 30개의 인스턴스는 처리 지연을 허용할 수 있는 배치 작업을 처리하는 데 사용됩니다.솔루션 아키텍트로서 다음 중 가장 비용 최적화된 솔루션으로 추천하는 것은 무엇입니까?,70개의 예약 인스턴스와 30개의 스팟 인스턴스 구매,예약 인스턴스 70개와 온디맨드 인스턴스 30개 구입,온디맨드 인스턴스 70개와 스팟 인스턴스 30개 구입,온디맨드 인스턴스 70개와 예약 인스턴스 30개 구입,,,0,,
udemy,CLF-01,100,A company is looking at storing their less frequently accessed files on AWS that can be concurrently accessed by hundreds of EC2 instances. The company needs the most cost-effective file storage service that provides immediate access to data whenever needed.Which of the following options represents the best solution for the given requirements?,C,C,Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class,Amazon Elastic File System (EFS) Standard storage class,Amazon Elastic File System (EFS) Standard–IA storage class,Amazon Elastic Block Store (EBS),,,,한 회사에서 수백 개의 EC2 인스턴스에서 동시에 액세스할 수 있는 AWS에 자주 액세스하지 않는 파일을 저장하는 방법을 찾고 있습니다. 회사는 필요할 때마다 데이터에 즉시 액세스할 수 있는 가장 비용 효율적인 파일 스토리지 서비스가 필요합니다.다음 옵션 중 주어진 요구 사항에 가장 적합한 솔루션은 무엇입니까?,Amazon S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스,Amazon Elastic File System(EFS) 표준 스토리지 클래스,Amazon Elastic File System(EFS) Standard–IA 스토리지 클래스,아마존 엘라스틱 블록 스토어(EBS),,,0,,
udemy,CLF-01,101,"An application runs big data workloads on EC2 instances. The application runs 24x7 all round the year and needs at least 20 instances to maintain a minimum acceptable performance threshold and the application needs 300 instances to handle spikes in the workload. Based on historical workloads processed by the application, it needs 80 instances 80% of the time.As a solutions architect, which of the following would you recommend as the MOST cost-optimal solution so that it can meet the workload demand in a steady state?",C,C,Purchase 80 spot instances. Use Auto Scaling Group to provision the remaining instances as on-demand instances per the workload demand,Purchase 80 on-demand instances. Provision additional on-demand and spot instances per the workload demand (Use Auto Scaling Group with launch template to provision the mix of on-demand and spot instances),Purchase 80 reserved instances. Provision additional on-demand and spot instances per the workload demand (Use Auto Scaling Group with launch template to provision the mix of on-demand and spot instances),Purchase 20 on-demand instances. Use Auto Scaling Group to provision the remaining instances as spot instances per the workload demand,,,,애플리케이션은 EC2 인스턴스에서 빅 데이터 워크로드를 실행합니다. 애플리케이션은 연중무휴 24시간 실행되며 허용 가능한 최소 성능 임계값을 유지하기 위해 최소 20개의 인스턴스가 필요하고 애플리케이션은 워크로드 급증을 처리하기 위해 300개의 인스턴스가 필요합니다. 애플리케이션에서 처리한 과거 워크로드를 기반으로 시간의 80%에 80개의 인스턴스가 필요합니다.솔루션 아키텍트로서 안정적인 상태에서 워크로드 수요를 충족할 수 있는 가장 비용 최적화된 솔루션으로 다음 중 무엇을 추천하시겠습니까?,80개의 스팟 인스턴스를 구입하십시오. Auto Scaling Group을 사용하여 나머지 인스턴스를 워크로드 수요에 따라 온디맨드 인스턴스로 프로비저닝합니다.,80개의 온디맨드 인스턴스를 구매합니다. 워크로드 수요에 따라 추가 온디맨드 및 스팟 인스턴스 프로비저닝(시작 템플릿과 함께 Auto Scaling 그룹을 사용하여 온디맨드 및 스팟 인스턴스 혼합 프로비저닝),80개의 예약 인스턴스를 구매합니다. 워크로드 수요에 따라 추가 온디맨드 및 스팟 인스턴스 프로비저닝(시작 템플릿과 함께 Auto Scaling 그룹을 사용하여 온디맨드 및 스팟 인스턴스 혼합 프로비저닝),20개의 온디맨드 인스턴스를 구매합니다. Auto Scaling Group을 사용하여 나머지 인스턴스를 워크로드 수요에 따라 스팟 인스턴스로 프로비저닝합니다.,,,0,,
udemy,CLF-01,102,"A startup has just developed a video backup service hosted on a fleet of EC2 instances. The EC2 instances are behind an Application Load Balancer and the instances are using EBS volumes for storage. The service provides authenticated users the ability to upload videos that are then saved on the EBS volume attached to a given instance. On the first day of the beta launch, users start complaining that they can see only some of the videos in their uploaded videos backup. Every time the users log into the website, they claim to see a different subset of their uploaded videos.Which of the following is the MOST optimal solution to make sure that users can view all the uploaded videos? (Select two)",BD,BD,Write a one time job to copy the videos from all EBS volumes to S3 Glacier Deep Archive and then modify the application to use S3 Glacier Deep Archive for storing the videos,Write a one time job to copy the videos from all EBS volumes to S3 and then modify the application to use Amazon S3 standard for storing the videos,Write a one time job to copy the videos from all EBS volumes to RDS and then modify the application to use RDS for storing the videos,Mount EFS on all EC2 instances. Write a one time job to copy the videos from all EBS volumes to EFS. Modify the application to use EFS for storing the videos,Write a one time job to copy the videos from all EBS volumes to DynamoDB and then modify the application to use DynamoDB for storing the videos,,,한 스타트업이 EC2 인스턴스 플릿에서 호스팅되는 비디오 백업 서비스를 막 개발했습니다. EC2 인스턴스는 Application Load Balancer 뒤에 있으며 인스턴스는 저장을 위해 EBS 볼륨을 사용하고 있습니다. 이 서비스는 인증된 사용자에게 비디오를 업로드한 다음 지정된 인스턴스에 연결된 EBS 볼륨에 저장할 수 있는 기능을 제공합니다. 베타 런칭 첫날 사용자들은 자신이 올린 동영상 백업에서 일부 동영상만 보인다는 불만을 제기하기 시작합니다. 사용자가 웹사이트에 로그인할 때마다 업로드한 동영상의 다른 하위 집합을 본다고 주장합니다.다음 중 사용자가 업로드된 모든 동영상을 볼 수 있도록 하는 가장 최적의 솔루션은 무엇입니까? (2개 선택),모든 EBS 볼륨에서 S3 Glacier Deep Archive로 비디오를 복사하는 일회성 작업을 작성한 다음 비디오 저장에 S3 Glacier Deep Archive를 사용하도록 애플리케이션을 수정합니다.,모든 EBS 볼륨에서 S3로 비디오를 복사하는 일회성 작업을 작성한 다음 비디오 저장에 Amazon S3 표준을 사용하도록 애플리케이션을 수정합니다.,모든 EBS 볼륨에서 RDS로 비디오를 복사하는 일회성 작업을 작성한 다음 RDS를 사용하여 비디오를 저장하도록 애플리케이션을 수정합니다.,모든 EC2 인스턴스에 EFS를 탑재합니다. 모든 EBS 볼륨에서 EFS로 비디오를 복사하는 일회성 작업을 작성합니다. 비디오 저장에 EFS를 사용하도록 애플리케이션 수정,모든 EBS 볼륨에서 DynamoDB로 비디오를 복사하는 일회성 작업을 작성한 다음 비디오 저장에 DynamoDB를 사용하도록 애플리케이션을 수정합니다.,,0,,
udemy,CLF-01,103,"A company has recently launched a new mobile gaming application that the users are adopting rapidly. The company uses RDS MySQL as the database. The engineering team wants an urgent solution to this issue where the rapidly increasing workload might exceed the available database storage.As a solutions architect, which of the following solutions would you recommend so that it requires minimum development and systems administration effort to address this requirement?",A,A,Enable storage auto-scaling for RDS MySQL,Migrate RDS MySQL database to Aurora which offers storage auto-scaling,Create read replica for RDS MySQL,Migrate RDS MySQL database to DynamoDB which automatically allocates storage space when required,,,,한 회사가 최근 사용자들이 빠르게 채택하고 있는 새로운 모바일 게임 애플리케이션을 출시했습니다. 회사는 RDS MySQL을 데이터베이스로 사용합니다. 엔지니어링 팀은 빠르게 증가하는 워크로드가 사용 가능한 데이터베이스 스토리지를 초과할 수 있는 이 문제에 대한 긴급한 솔루션을 원합니다.솔루션 설계자로서 다음 중 이 요구 사항을 해결하기 위해 최소한의 개발 및 시스템 관리 노력이 필요하도록 권장하는 솔루션은 무엇입니까?,RDS MySQL에 대한 스토리지 자동 확장 활성화,스토리지 자동 확장을 제공하는 Aurora로 RDS MySQL 데이터베이스 마이그레이션,RDS MySQL용 읽기 복제본 생성,필요할 때 스토리지 공간을 자동으로 할당하는 DynamoDB로 RDS MySQL 데이터베이스 마이그레이션,,,0,,
udemy,CLF-01,104,A financial services company has developed its flagship application on AWS Cloud with data security requirements such that the encryption key must be stored in a custom application running on-premises. The company wants to offload the data storage as well as the encryption process to Amazon S3 but continue to use the existing encryption key.Which of the following S3 encryption options allows the company to leverage Amazon S3 for storing data with given constraints?,C,C,Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3),Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS),Server-Side Encryption with Customer-Provided Keys (SSE-C),Client-Side Encryption with data encryption is done on the client-side before sending it to Amazon S3,,,,금융 서비스 회사는 온프레미스에서 실행되는 사용자 지정 애플리케이션에 암호화 키를 저장해야 한다는 데이터 보안 요구 사항을 포함하여 AWS 클라우드에서 대표 애플리케이션을 개발했습니다. 회사는 데이터 스토리지와 암호화 프로세스를 Amazon S3로 오프로드하지만 기존 암호화 키를 계속 사용하려고 합니다.다음 S3 암호화 옵션 중 회사가 주어진 제약 조건으로 데이터를 저장하기 위해 Amazon S3를 활용할 수 있도록 허용하는 것은 무엇입니까?,Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화,AWS Key Management Service(SSE-KMS)에 저장된 고객 마스터 키(CMK)를 사용한 서버 측 암호화,고객 제공 키를 사용한 서버 측 암호화(SSE-C),데이터 암호화를 사용한 클라이언트 측 암호화는 Amazon S3로 보내기 전에 클라이언트 측에서 수행됩니다.,,,0,,
udemy,CLF-01,105,"Consider the following policy associated with an IAM group containing several users:{    ""Version"":""2012-10-17"",    ""Id"":""EC2TerminationPolicy"",    ""Statement"":[        {            ""Effect"":""Deny"",            ""Action"":""ec2:*"",            ""Resource"":""*"",            ""Condition"":{                ""StringNotEquals"":{                    ""ec2:Region"":""us-west-1""                }            }        },        {            ""Effect"":""Allow"",            ""Action"":""ec2:TerminateInstances"",            ""Resource"":""*"",            ""Condition"":{                ""IpAddress"":{                    ""aws:SourceIp"":""10.200.200.0/24""                }            }        }    ]}Which of the following options is correct?",D,D,Users belonging to the IAM group can terminate an EC2 instance belonging to any region except the us-west-1 region when the user's source IP is 10.200.200.200,Users belonging to the IAM group can terminate an EC2 instance in the us-west-1 region when the EC2 instance's IP address is 10.200.200.200,Users belonging to the IAM group cannot terminate an EC2 instance in the us-west-1 region when the user's source IP is 10.200.200.200,Users belonging to the IAM group can terminate an EC2 instance in the us-west-1 region when the user's source IP is 10.200.200.200,,,,"여러 사용자를 포함하는 IAM 그룹과 관련된 다음 정책을 고려하십시오.{    ""Version"":""2012-10-17"",    ""Id"":""EC2TerminationPolicy"",    ""Statement"":[        {            ""Effect"":""Deny"",            ""Action"":""ec2:*"",            ""Resource"":""*"",            ""Condition"":{                ""StringNotEquals"":{                    ""ec2:Region"":""us-west-1""                }            }        },        {            ""Effect"":""Allow"",            ""Action"":""ec2:TerminateInstances"",            ""Resource"":""*"",            ""Condition"":{                ""IpAddress"":{                    ""aws:SourceIp"":""10.200.200.0/24""                }            }        }    ]}다음 옵션 중 올바른 것은 무엇입니까?",us-west-1IAM 그룹에 속한 사용자는 사용자의 소스 IP가 10.200.200.200인 경우 지역을 제외한 모든 지역에 속한 EC2 인스턴스를 종료할 수 있습니다.,us-west-1IAM 그룹에 속한 사용자는 EC2 인스턴스의 IP 주소가 10.200.200.200인 경우 리전의 EC2 인스턴스를 종료할 수 있습니다.,us-west-1IAM 그룹에 속한 사용자는 사용자의 소스 IP가 10.200.200.200인 경우 리전의 EC2 인스턴스를 종료할 수 없습니다.,us-west-1IAM 그룹에 속한 사용자는 사용자의 소스 IP가 10.200.200.200일 때 리전 의 EC2 인스턴스를 종료할 수 있습니다.,,,0,,
udemy,CLF-01,106,"What does this IAM policy do?{  ""Version"": ""2012-10-17"",  ""Statement"": [    {      ""Sid"": ""Mystery Policy"",      ""Action"": [        ""ec2:RunInstances""      ],      ""Effect"": ""Allow"",      ""Resource"": ""*"",      ""Condition"": {        ""StringEquals"": {          ""aws:RequestedRegion"": ""eu-west-1""        }      }    }  ]}",C,C,It allows running EC2 instances anywhere but in the eu-west-1 region,"It allows to run EC2 instances in the eu-west-1 region, when the API call is made from the eu-west-1 region","It allows running EC2 instances only in the eu-west-1 region, and the API call can be made from anywhere in the world",It allows running EC2 instances in any region when the API call is originating from the eu-west-1 region,,,,"이 IAM 정책은 무엇을 합니까?{  ""Version"": ""2012-10-17"",  ""Statement"": [    {      ""Sid"": ""Mystery Policy"",      ""Action"": [        ""ec2:RunInstances""      ],      ""Effect"": ""Allow"",      ""Resource"": ""*"",      ""Condition"": {        ""StringEquals"": {          ""aws:RequestedRegion"": ""eu-west-1""        }      }    }  ]}",eu-west-1 지역을 제외한 모든 곳에서 EC2 인스턴스를 실행할 수 있습니다.,eu-west-1 지역에서 API 호출이 이루어진 경우 eu-west-1 지역에서 EC2 인스턴스를 실행할 수 있습니다.,eu-west-1 지역에서만 EC2 인스턴스를 실행할 수 있으며 전 세계 어디에서나 API 호출이 가능합니다.,API 호출이 eu-west-1 지역에서 시작될 때 모든 지역에서 EC2 인스턴스를 실행할 수 있습니다.,,,0,,
udemy,CLF-01,107,"An IT company has an Access Control Management (ACM) application that uses Amazon RDS for MySQL but is running into performance issues despite using Read Replicas. The company has hired you as a solutions architect to address these performance-related challenges without moving away from the underlying relational database schema. The company has branch offices across the world, and it needs the solution to work on a global scale.Which of the following will you recommend as the MOST cost-effective and high-performance solution?",A,A,Use Amazon Aurora Global Database to enable fast local reads with low latency in each region,"Use Amazon DynamoDB Global Tables to provide fast, local, read and write performance in each region","Spin up EC2 instances in each AWS region, install MySQL databases and migrate the existing data into these new databases",Spin up a Redshift cluster in each AWS region. Migrate the existing data into Redshift clusters,,,,IT 회사에는 Amazon RDS for MySQL을 사용하는 ACM(액세스 제어 관리) 애플리케이션이 있지만 읽기 전용 복제본을 사용함에도 불구하고 성능 문제가 발생합니다. 회사는 기본 관계형 데이터베이스 스키마에서 벗어나지 않고 이러한 성능 관련 문제를 해결하기 위해 귀하를 솔루션 설계자로 고용했습니다. 이 회사는 전 세계에 지사를 두고 있으며 글로벌 규모로 작업할 솔루션이 필요합니다.다음 중 가장 비용 효율적인 고성능 솔루션으로 추천할 만한 것은 무엇입니까?,Amazon Aurora Global Database를 사용하여 각 리전에서 짧은 지연 시간으로 빠른 로컬 읽기 지원,Amazon DynamoDB 글로벌 테이블을 사용하여 각 리전에서 빠른 로컬 읽기 및 쓰기 성능 제공,"각 AWS 지역에서 EC2 인스턴스 가동, MySQL 데이터베이스 설치 및 기존 데이터를 이러한 새 데이터베이스로 마이그레이션",각 AWS 리전에서 Redshift 클러스터를 가동합니다. 기존 데이터를 Redshift 클러스터로 마이그레이션,,,0,,
udemy,CLF-01,108,A retail company wants to share sensitive accounting data that is stored in an Amazon RDS DB instance with an external auditor. The auditor has its own AWS account and needs its own copy of the database.Which of the following would you recommend to securely share the database with the auditor?,C,C,Create a snapshot of the database in Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket,Set up a read replica of the database and configure IAM standard database authentication to grant the auditor access,"Create an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key","Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket",,,,소매 회사는 Amazon RDS DB 인스턴스에 저장된 민감한 회계 데이터를 외부 감사자와 공유하려고 합니다. 감사자는 자체 AWS 계정이 있으며 자체 데이터베이스 사본이 필요합니다.데이터베이스를 감사자와 안전하게 공유하기 위해 다음 중 무엇을 권장하시겠습니까?,Amazon S3에서 데이터베이스의 스냅샷을 생성하고 감사자에게 IAM 역할을 할당하여 해당 버킷의 객체에 대한 액세스 권한을 부여합니다.,데이터베이스의 읽기 복제본을 설정하고 감사자 액세스 권한을 부여하도록 IAM 표준 데이터베이스 인증을 구성합니다.,"데이터베이스의 암호화된 스냅샷 생성, 스냅샷 공유, AWS Key Management Service(AWS KMS) 암호화 키에 대한 액세스 허용",데이터베이스 콘텐츠를 텍스트 파일로 내보내고 파일을 Amazon S3에 저장하고 해당 버킷에 대한 액세스 권한이 있는 감사자를 위한 새 IAM 사용자를 생성합니다.,,,0,,
udemy,CLF-01,109,"An IT company is working on client engagement to build a real-time data analytics tool for the Internet of Things (IoT) data. The IoT data is funneled into Kinesis Data Streams which further acts as the source of a delivery stream for Kinesis Firehose. The engineering team has now configured a Kinesis Agent to send IoT data from another set of devices to the same Firehose delivery stream. They noticed that data is not reaching Firehose as expected.As a solutions architect, which of the following options would you attribute as the MOST plausible root cause behind this issue?",C,C,Kinesis Firehose delivery stream has reached its limit and needs to be scaled manually,"Kinesis Agent can only write to Kinesis Data Streams, not to Kinesis Firehose",Kinesis Agent cannot write to a Kinesis Firehose for which the delivery stream source is already set as Kinesis Data Streams,The data sent by Kinesis Agent is lost because of a configuration error,,,,한 IT 회사는 사물 인터넷(IoT) 데이터를 위한 실시간 데이터 분석 도구를 구축하기 위해 클라이언트 참여 작업을 진행하고 있습니다. IoT 데이터는 Kinesis Firehose의 전송 스트림 소스 역할을 하는 Kinesis Data Streams로 전달됩니다. 엔지니어링 팀은 이제 다른 디바이스 세트에서 동일한 Firehose 전송 스트림으로 IoT 데이터를 전송하도록 Kinesis 에이전트를 구성했습니다. 그들은 데이터가 예상대로 Firehose에 도달하지 않는다는 것을 알아차렸습니다.솔루션 설계자로서 다음 옵션 중 이 문제의 가장 그럴듯한 근본 원인으로 간주하는 옵션은 무엇입니까?,Kinesis Firehose 전송 스트림이 한도에 도달했으며 수동으로 조정해야 합니다.,Kinesis 에이전트는 Kinesis Firehose가 아닌 Kinesis Data Streams에만 쓸 수 있습니다.,Kinesis 에이전트는 전송 스트림 소스가 이미 Kinesis Data Streams로 설정된 Kinesis Firehose에 쓸 수 없습니다.,구성 오류로 인해 Kinesis 에이전트에서 보낸 데이터가 손실됨,,,0,,
udemy,CLF-01,110,"A company has many VPC in various accounts, that need to be connected in a star network with one another and connected with on-premises networks through Direct Connect.What do you recommend?",B,B,VPN Gateway,Transit Gateway,VPC Peering,Private Link,,,,회사는 다양한 계정에 많은 VPC를 가지고 있으며 서로 스타 네트워크로 연결하고 Direct Connect를 통해 온프레미스 네트워크와 연결해야 합니다.추천 메뉴가 무엇인가요?,VPN 게이트웨이,통과 게이트웨이,VPC 피어링,비공개 링크,,,0,,
udemy,CLF-01,111,"An IT company has built a solution wherein a Redshift cluster writes data to an Amazon S3 bucket belonging to a different AWS account. However, it is found that the files created in the S3 bucket using the UNLOAD command from the Redshift cluster are not even accessible to the S3 bucket owner.What could be the reason for this denial of permission for the bucket owner?",D,D,"When objects are uploaded to S3 bucket from a different AWS account, the S3 bucket owner will get implicit permissions to access these objects. This issue seems to be due to an upload error that can be fixed by providing manual access from AWS console","When two different AWS accounts are accessing an S3 bucket, both the accounts must share the bucket policies. An erroneous policy can lead to such permission failures","The owner of an S3 bucket has implicit access to all objects in his bucket. Permissions are set on objects after they are completely copied to the target location. Since the owner is unable to access the uploaded files, the write operation may be still in progress","By default, an S3 object is owned by the AWS account that uploaded it. So the S3 bucket owner will not implicitly have access to the objects written by the Redshift cluster",,,,IT 회사는 Redshift 클러스터가 다른 AWS 계정에 속한 Amazon S3 버킷에 데이터를 쓰는 솔루션을 구축했습니다. 그러나 Redshift 클러스터에서 UNLOAD 명령을 사용하여 S3 버킷에 생성된 파일은 S3 버킷 소유자도 액세스할 수 없는 것으로 확인되었습니다.버킷 소유자에 대한 권한 거부의 이유는 무엇입니까?,객체가 다른 AWS 계정에서 S3 버킷으로 업로드되면 S3 버킷 소유자는 이러한 객체에 액세스할 수 있는 암시적 권한을 갖게 됩니다. 이 문제는 AWS 콘솔에서 수동 액세스를 제공하여 수정할 수 있는 업로드 오류로 인한 것 같습니다.,서로 다른 두 AWS 계정이 S3 버킷에 액세스하는 경우 두 계정 모두 버킷 정책을 공유해야 합니다. 잘못된 정책으로 인해 이러한 권한 실패가 발생할 수 있습니다.,S3 버킷의 소유자는 자신의 버킷에 있는 모든 객체에 대한 암시적 액세스 권한을 가집니다. 개체가 대상 위치에 완전히 복사된 후 개체에 대한 권한이 설정됩니다. 소유자가 업로드된 파일에 액세스할 수 없으므로 쓰기 작업이 아직 진행 중일 수 있습니다.,기본적으로 S3 객체는 이를 업로드한 AWS 계정이 소유합니다. 따라서 S3 버킷 소유자는 Redshift 클러스터가 작성한 객체에 암시적으로 액세스할 수 없습니다.,,,0,,
udemy,CLF-01,112,"A retail company wants to rollout and test a blue-green deployment for its global application in the next 48 hours. Most of the customers use mobile phones which are prone to DNS caching. The company has only two days left for the annual Thanksgiving sale to commence.As a Solutions Architect, which of the following options would you recommend to test the deployment on as many users as possible in the given time frame?",B,B,Use Route 53 weighted routing to spread traffic across different deployments,Use AWS Global Accelerator to distribute a portion of traffic to a particular deployment,Use AWS CodeDeploy deployment options to choose the right deployment,Use Elastic Load Balancer to distribute traffic across deployments,,,,소매 회사는 앞으로 48시간 내에 글로벌 애플리케이션을 위한 청록색 배포를 롤아웃하고 테스트하려고 합니다. 대부분의 고객은 DNS 캐싱이 발생하기 쉬운 휴대폰을 사용합니다. 회사는 연례 추수감사절 세일을 시작하기까지 이틀밖에 남지 않았습니다.솔루션 아키텍트로서 주어진 시간 내에 가능한 한 많은 사용자에게 배포를 테스트하기 위해 권장하는 옵션은 다음 중 무엇입니까?,Route 53 가중치 라우팅을 사용하여 여러 배포에 트래픽 분산,AWS Global Accelerator를 사용하여 트래픽의 일부를 특정 배포로 분산,AWS CodeDeploy 배포 옵션을 사용하여 올바른 배포 선택,Elastic Load Balancer를 사용하여 배포 간에 트래픽 분산,,,0,,
udemy,CLF-01,113,An analytics company wants to improve the performance of its big data processing workflows running on Amazon EFS. Which of the following performance modes should be used for EFS to address this requirement?,B,B,Provisioned Throughput,Max I/O,Bursting Throughput,General Purpose,,,,분석 회사는 Amazon EFS에서 실행되는 빅 데이터 처리 워크플로의 성능을 개선하려고 합니다. 다음 중 이 요구 사항을 해결하기 위해 EFS에 사용해야 하는 성능 모드는 무엇입니까?,프로비저닝된 처리량,최대 I/O,폭발적인 처리량,범용,,,0,,
udemy,CLF-01,114,"A manufacturing company receives unreliable service from its data center provider because the company is located in an area prone to natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failover environment on AWS in case the on-premises data center fails. The company runs web servers that connect to external vendors. The data available on AWS and on-premises must be uniform.Which of the following solutions would have the LEAST amount of downtime?",A,A,Set up a Route 53 failover record. Run application servers on EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to S3,Set up a Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to S3. Set up an AWS Direct Connect connection between a VPC and the data center,Set up a Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer,Set up a Route 53 failover record. Execute an AWS CloudFormation template from a script to provision EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to S3,,,,제조 회사는 자연 재해가 발생하기 쉬운 지역에 있기 때문에 데이터 센터 공급자로부터 신뢰할 수 없는 서비스를 받습니다. 회사는 AWS 클라우드로 완전히 마이그레이션할 준비가 되지 않았지만 온프레미스 데이터 센터에 장애가 발생할 경우를 대비하여 AWS에서 장애 조치 환경을 원합니다. 회사는 외부 공급업체에 연결하는 웹 서버를 실행합니다. AWS 및 온프레미스에서 사용 가능한 데이터는 균일해야 합니다.다음 중 다운타임이 가장 적은 솔루션은 무엇입니까?,Route 53 장애 조치 레코드를 설정합니다. Auto Scaling 그룹의 Application Load Balancer 뒤에 있는 EC2 인스턴스에서 애플리케이션 서버를 실행합니다. 저장된 볼륨으로 AWS Storage Gateway를 설정하여 데이터를 S3에 백업,Route 53 장애 조치 레코드를 설정합니다. AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 2개의 EC2 인스턴스를 시작합니다. 저장된 볼륨으로 AWS Storage Gateway를 설정하여 데이터를 S3에 백업합니다. VPC와 데이터 센터 간의 AWS Direct Connect 연결 설정,Route 53 장애 조치 레코드를 설정합니다. VPC와 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다. Auto Scaling 그룹의 EC2에서 애플리케이션 서버를 실행합니다. AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 Application Load Balancer 생성,Route 53 장애 조치 레코드를 설정합니다. 스크립트에서 AWS CloudFormation 템플릿을 실행하여 Application Load Balancer 뒤에 EC2 인스턴스를 프로비저닝합니다. 저장된 볼륨으로 AWS Storage Gateway를 설정하여 데이터를 S3에 백업,,,0,,
udemy,CLF-01,115,Which of the following IAM policies provides read-only access to the S3 bucket mybucket and its content?,D,D,"{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket"",
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      },
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket"",
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      },
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      }
   ]
}",,,,다음 중 S3 버킷과 그 콘텐츠에 대한 읽기 전용 액세스를 제공하는 IAM 정책은 무엇입니까 mybucket?,"{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket"",
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      },
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket"",
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      }
   ]
}","{
   ""Version"":""2012-10-17"",
   ""Statement"":[
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:ListBucket""
         ],
         ""Resource"":""arn:aws:s3:::mybucket""
      },
      {
         ""Effect"":""Allow"",
         ""Action"":[
            ""s3:GetObject""
         ],
         ""Resource"":""arn:aws:s3:::mybucket/*""
      }
   ]
}",,,0,,
udemy,CLF-01,116,"Your company has deployed an application that will perform a lot of overwrites and deletes on data and require the latest information to be available anytime data is read via queries on database tables.As a Solutions Architect, which database technology will you recommend?",C,C,Amazon ElastiCache,Amazon Simple Storage Service (Amazon S3),Amazon Relational Database Service (Amazon RDS),Amazon Neptune,,,,귀하의 회사는 데이터에 대해 많은 덮어쓰기 및 삭제를 수행하고 데이터베이스 테이블에 대한 쿼리를 통해 데이터를 읽을 때마다 최신 정보를 요구하는 애플리케이션을 배포했습니다.솔루션 아키텍트로서 추천할 데이터베이스 기술은 무엇입니까?,아마존 엘라스티캐시,Amazon Simple Storage Service(Amazon S3),Amazon 관계형 데이터베이스 서비스(Amazon RDS),아마존 해왕성,,,0,,
udemy,CLF-01,117,An e-commerce company operates multiple AWS accounts and has interconnected these accounts in a hub-and-spoke style using the AWS Transit Gateway. VPCs have been provisioned across these AWS accounts to facilitate network isolation.Which of the following solutions would reduce both the administrative overhead and the costs while providing shared access to services required by workloads in each of the VPCs?,D,D,Use VPCs connected with AWS Direct Connect,Use Transit VPC to reduce cost and share the resources across VPCs,Use Fully meshed VPC Peers,Build a shared services VPC,,,,전자 상거래 회사는 여러 AWS 계정을 운영하고 있으며 이러한 계정을 AWS Transit Gateway를 사용하여 허브 앤 스포크 스타일로 상호 연결했습니다. VPC는 네트워크 격리를 용이하게 하기 위해 이러한 AWS 계정 전체에 프로비저닝되었습니다.다음 중 각 VPC의 워크로드에 필요한 서비스에 대한 공유 액세스를 제공하면서 관리 오버헤드와 비용을 모두 줄이는 솔루션은 무엇입니까?,AWS Direct Connect와 연결된 VPC 사용,Transit VPC를 사용하여 비용을 줄이고 여러 VPC에서 리소스 공유,완전 메시 VPC 피어 사용,공유 서비스 VPC 구축,,,0,,
udemy,CLF-01,118,"Upon a security review of your AWS account, an AWS consultant has found that a few RDS databases are un-encrypted. As a Solutions Architect, what steps must be taken to encrypt the RDS databases?",A,A,"Take a snapshot of the database, copy it as an encrypted snapshot, and restore a database from the encrypted snapshot. Terminate the previous database","Create a Read Replica of the database, and encrypt the read replica. Promote the read replica as a standalone database, and terminate the previous database","Enable Multi-AZ for the database, and make sure the standby instance is encrypted. Stop the main database to that the standby database kicks in, then disable Multi-AZ",Enable encryption on the RDS database using the AWS Console,,,,AWS 계정의 보안 검토 시 AWS 컨설턴트가 몇 개의 RDS 데이터베이스가 암호화되지 않은 것을 발견했습니다. 솔루션 설계자로서 RDS 데이터베이스를 암호화하려면 어떤 조치를 취해야 합니까?,데이터베이스의 스냅샷을 생성하여 암호화된 스냅샷으로 복사하고 암호화된 스냅샷에서 데이터베이스를 복원합니다. 이전 데이터베이스 종료,데이터베이스의 읽기 전용 복제본을 생성하고 읽기 전용 복제본을 암호화합니다. 읽기 전용 복제본을 독립 실행형 데이터베이스로 승격하고 이전 데이터베이스를 종료합니다.,데이터베이스에 대해 다중 AZ를 활성화하고 대기 인스턴스가 암호화되었는지 확인하십시오. 대기 데이터베이스가 시작되는 기본 데이터베이스를 중지한 다음 다중 AZ를 비활성화합니다.,AWS 콘솔을 사용하여 RDS 데이터베이스에서 암호화 활성화,,,0,,
udemy,CLF-01,119,"You would like to store a database password in a secure place, and enable automatic rotation of that password every 90 days. What do you recommend?",A,A,Secrets Manager,SSM Parameter Store,CloudHSM,Key Management Service (KMS),,,,안전한 장소에 데이터베이스 비밀번호를 저장하고 90일마다 해당 비밀번호의 자동 교체를 활성화하려고 합니다. 추천 메뉴가 무엇인가요?,비밀 관리자,SSM 매개변수 저장소,CloudHSM,키 관리 서비스(KMS),,,0,,
udemy,CLF-01,120,"A developer needs to implement a Lambda function in AWS account A that accesses an Amazon S3 bucket in AWS account B.As a Solutions Architect, which of the following will you recommend to meet this requirement?",B,B,Create an IAM role for the Lambda function that grants access to the S3 bucket. Set the IAM role as the Lambda function's execution role and that would give the Lambda function cross-account access to the S3 bucket,Create an IAM role for the Lambda function that grants access to the S3 bucket. Set the IAM role as the Lambda function's execution role. Make sure that the bucket policy also grants access to the Lambda function's execution role,AWS Lambda cannot access resources across AWS accounts. Use Identity federation to work around this limitation of Lambda,The S3 bucket owner should make the bucket public so that it can be accessed by the Lambda function in the other AWS account,,,,개발자는 AWS 계정 B의 Amazon S3 버킷에 액세스하는 AWS 계정 A의 Lambda 함수를 구현해야 합니다.솔루션 아키텍트로서 이 요구 사항을 충족하기 위해 다음 중 무엇을 추천하시겠습니까?,S3 버킷에 대한 액세스 권한을 부여하는 Lambda 함수에 대한 IAM 역할을 생성합니다. IAM 역할을 Lambda 함수의 실행 역할로 설정하고 Lambda 함수에 S3 버킷에 대한 교차 계정 액세스 권한을 부여합니다.,S3 버킷에 대한 액세스 권한을 부여하는 Lambda 함수에 대한 IAM 역할을 생성합니다. IAM 역할을 Lambda 함수의 실행 역할로 설정합니다. 버킷 정책이 Lambda 함수의 실행 역할에 대한 액세스 권한도 부여하는지 확인하십시오.,AWS Lambda는 AWS 계정 전체에서 리소스에 액세스할 수 없습니다. 자격 증명 연합을 사용하여 Lambda의 이러한 제한 사항을 해결하십시오.,S3 버킷 소유자는 다른 AWS 계정의 Lambda 함수에서 액세스할 수 있도록 버킷을 공개해야 합니다.,,,0,,
udemy,CLF-01,121,"An IT company provides S3 bucket access to specific users within the same account for completing project specific work. With changing business requirements, cross-account S3 access requests are also growing every month. The company is looking for a solution that can offer user level as well as account-level access permissions for the data stored in S3 buckets.As a Solutions Architect, which of the following would you suggest as the MOST optimized way of controlling access for this use-case?",B,B,Use Identity and Access Management (IAM) policies,Use Amazon S3 Bucket Policies,Use Security Groups,Use Access Control Lists (ACLs),,,,IT 회사는 프로젝트 특정 작업을 완료하기 위해 동일한 계정 내의 특정 사용자에게 S3 버킷 액세스를 제공합니다. 변화하는 비즈니스 요구 사항에 따라 교차 계정 S3 액세스 요청도 매달 증가하고 있습니다. 회사는 S3 버킷에 저장된 데이터에 대한 계정 수준 액세스 권한뿐 아니라 사용자 수준을 제공할 수 있는 솔루션을 찾고 있습니다.솔루션 아키텍트로서 다음 중 이 사용 사례에 대한 액세스를 제어하는 ​​가장 최적화된 방법으로 제안하는 것은 무엇입니까?,ID 및 액세스 관리(IAM) 정책 사용,Amazon S3 버킷 정책 사용,보안 그룹 사용,액세스 제어 목록(ACL) 사용,,,0,,
udemy,CLF-01,122,"A silicon valley based startup has a two-tier architecture using EC2 instances for its flagship application. The web servers (listening on port 443), which have been assigned security group A, are in public subnets across two Availability Zones and the MSSQL based database instances (listening on port 1433), which have been assigned security group B, are in two private subnets across two Availability Zones. The DevOps team wants to review the security configurations of the application architecture.As a solutions architect, which of the following options would you select as the MOST secure configuration? (Select two)",DE,DE,For security group B: Add an inbound rule that allows traffic only from all sources on port 1433,For security group B: Add an inbound rule that allows traffic only from security group A on port 443,For security group A: Add an inbound rule that allows traffic from all sources on port 443. Add an outbound rule with the destination as security group B on port 443,For security group B: Add an inbound rule that allows traffic only from security group A on port 1433,For security group A: Add an inbound rule that allows traffic from all sources on port 443. Add an outbound rule with the destination as security group B on port 1433,,,실리콘 밸리 기반 스타트업은 주력 애플리케이션에 EC2 인스턴스를 사용하는 2계층 아키텍처를 갖추고 있습니다. 보안 그룹 A가 할당된 웹 서버(포트 443에서 수신)는 두 가용 영역의 퍼블릭 서브넷에 있고 보안 그룹 B가 할당된 MSSQL 기반 데이터베이스 인스턴스(포트 1433에서 수신)는 두 개의 가용 영역에 있습니다. 2개의 가용 영역에 걸친 프라이빗 서브넷. DevOps 팀은 애플리케이션 아키텍처의 보안 구성을 검토하려고 합니다.솔루션 설계자로서 다음 중 가장 안전한 구성으로 선택하는 옵션은 무엇입니까? (2개 선택),보안 그룹 B의 경우: 포트 1433의 모든 소스에서 들어오는 트래픽만 허용하는 인바운드 규칙을 추가합니다.,보안 그룹 B의 경우: 포트 443에서 보안 그룹 A의 트래픽만 허용하는 인바운드 규칙을 추가합니다.,보안 그룹 A의 경우: 포트 443에서 모든 소스의 트래픽을 허용하는 인바운드 규칙을 추가합니다. 포트 443에서 대상이 보안 그룹 B인 아웃바운드 규칙을 추가합니다.,보안 그룹 B의 경우: 포트 1433에서 보안 그룹 A의 트래픽만 허용하는 인바운드 규칙을 추가합니다.,보안 그룹 A의 경우: 포트 443에서 모든 소스의 트래픽을 허용하는 인바운드 규칙을 추가합니다. 포트 1433에서 대상이 보안 그룹 B인 아웃바운드 규칙을 추가합니다.,,0,,
udemy,CLF-01,123,"An application is currently hosted on four EC2 instances (behind Application Load Balancer) deployed in a single Availability Zone (AZ). To maintain an acceptable level of end-user experience, the application needs at least 4 instances to be always available.As a solutions architect, which of the following would you recommend so that the application achieves high availability with MINIMUM cost?",A,A,Deploy the instances in three Availability Zones. Launch two instances in each Availability Zone,Deploy the instances in one Availability Zones. Launch two instances in the Availability Zone,Deploy the instances in two Availability Zones. Launch two instances in each Availability Zone,Deploy the instances in two Availability Zones. Launch four instances in each Availability Zone,,,,애플리케이션은 현재 단일 가용 영역(AZ)에 배포된 4개의 EC2 인스턴스(Application Load Balancer 뒤)에서 호스팅됩니다. 허용 가능한 수준의 최종 사용자 경험을 유지하려면 애플리케이션에 항상 사용 가능한 인스턴스가 4개 이상 있어야 합니다.솔루션 설계자로서 다음 중 애플리케이션이 최소 비용으로 고가용성을 달성하도록 권장하는 것은 무엇입니까?,세 개의 가용 영역에 인스턴스를 배포합니다. 각 가용 영역에서 두 개의 인스턴스 시작,하나의 가용 영역에 인스턴스를 배포합니다. 가용 영역에서 두 개의 인스턴스 시작,2개의 가용 영역에 인스턴스를 배포합니다. 각 가용 영역에서 두 개의 인스턴스 시작,2개의 가용 영역에 인스턴스를 배포합니다. 각 가용 영역에서 4개의 인스턴스 시작,,,0,,
udemy,CLF-01,124,"A financial services company wants a single log processing model for all the log files (consisting of system logs, application logs, database logs, etc) that can be processed in a serverless fashion and then durably stored for downstream analytics. The company wants to use an AWS managed service that automatically scales to match the throughput of the log data and requires no ongoing administration.As a solutions architect, which of the following AWS services would you recommend solving this problem?",B,B,Amazon EMR,Kinesis Data Firehose,AWS Lambda,Kinesis Data Streams,,,,"금융 서비스 회사는 서버리스 방식으로 처리한 다음 다운스트림 분석을 위해 지속적으로 저장할 수 있는 모든 로그 파일(시스템 로그, 애플리케이션 로그, 데이터베이스 로그 등으로 구성)에 대한 단일 로그 처리 모델을 원합니다. 이 회사는 로그 데이터의 처리량에 맞게 자동으로 확장되고 지속적인 관리가 필요하지 않은 AWS 관리형 서비스를 사용하려고 합니다.솔루션 아키텍트로서 다음 중 이 문제를 해결하기 위해 권장하는 AWS 서비스는 무엇입니까?",아마존 EMR,Kinesis Data Firehose,AWS 람다,Kinesis 데이터 스트림,,,0,,
udemy,CLF-01,125,"A social photo-sharing web application is hosted on EC2 instances behind an Elastic Load Balancer. The app gives the users the ability to upload their photos and also shows a leaderboard on the homepage of the app. The uploaded photos are stored in S3 and the leaderboard data is maintained in DynamoDB. The EC2 instances need to access both S3 and DynamoDB for these features.As a solutions architect, which of the following solutions would you recommend as the MOST secure option?",C,C,Configure AWS CLI on the EC2 instances using a valid IAM user's credentials. The application code can then invoke shell scripts to access S3 and DynamoDB via AWS CLI,Save the AWS credentials (access key Id and secret access token) in a configuration file within the application code on the EC2 instances. EC2 instances can use these credentials to access S3 and DynamoDB,Attach the appropriate IAM role to the EC2 instance profile so that the instance can access S3 and DynamoDB,Encrypt the AWS credentials via a custom encryption library and save it in a secret directory on the EC2 instances. The application code can then safely decrypt the AWS credentials to make the API calls to S3 and DynamoDB,,,,소셜 사진 공유 웹 애플리케이션은 Elastic Load Balancer 뒤의 EC2 인스턴스에서 호스팅됩니다. 이 앱은 사용자에게 사진을 업로드할 수 있는 기능을 제공하고 앱 홈페이지에 순위표를 표시합니다. 업로드된 사진은 S3에 저장되고 순위표 데이터는 DynamoDB에 유지됩니다. EC2 인스턴스는 이러한 기능을 위해 S3와 DynamoDB에 모두 액세스해야 합니다.솔루션 설계자로서 다음 중 가장 안전한 옵션으로 추천할 솔루션은 무엇입니까?,유효한 IAM 사용자 자격 증명을 사용하여 EC2 인스턴스에서 AWS CLI를 구성합니다. 그런 다음 애플리케이션 코드는 셸 스크립트를 호출하여 AWS CLI를 통해 S3 및 DynamoDB에 액세스할 수 있습니다.,EC2 인스턴스의 애플리케이션 코드 내 구성 파일에 AWS 자격 증명(액세스 키 ID 및 보안 액세스 토큰)을 저장합니다. EC2 인스턴스는 이러한 자격 증명을 사용하여 S3 및 DynamoDB에 액세스할 수 있습니다.,인스턴스가 S3 및 DynamoDB에 액세스할 수 있도록 적절한 IAM 역할을 EC2 인스턴스 프로필에 연결합니다.,사용자 지정 암호화 라이브러리를 통해 AWS 자격 증명을 암호화하고 EC2 인스턴스의 비밀 디렉터리에 저장합니다. 그런 다음 애플리케이션 코드는 AWS 자격 증명을 안전하게 해독하여 S3 및 DynamoDB에 대한 API 호출을 수행할 수 있습니다.,,,0,,
udemy,CLF-01,126,"An IT company is working on a client project to build a Supply Chain Management application. The web-tier of the application runs on an EC2 instance and the database tier is on Amazon RDS MySQL. For beta testing, all the resources are currently deployed in a single Availability Zone. The development team wants to improve application availability before the go-live.Given that all end users of the web application would be located in the US, which of the following would be the MOST resource-efficient solution?",C,C,"Deploy the web-tier EC2 instances in two regions, behind an Elastic Load Balancer. Deploy the Amazon RDS MySQL database in read replica configuration","Deploy the web-tier EC2 instances in two regions, behind an Elastic Load Balancer. Deploy the Amazon RDS MySQL database in Multi-AZ configuration","Deploy the web-tier EC2 instances in two Availability Zones, behind an Elastic Load Balancer. Deploy the Amazon RDS MySQL database in Multi-AZ configuration","Deploy the web-tier EC2 instances in two Availability Zones, behind an Elastic Load Balancer. Deploy the Amazon RDS MySQL database in read replica configuration",,,,IT 회사에서 공급망 관리 애플리케이션을 구축하기 위한 클라이언트 프로젝트를 진행하고 있습니다. 애플리케이션의 웹 계층은 EC2 인스턴스에서 실행되고 데이터베이스 계층은 Amazon RDS MySQL에 있습니다. 베타 테스트의 경우 현재 모든 리소스가 단일 가용 영역에 배포되어 있습니다. 개발 팀은 가동되기 전에 애플리케이션 가용성을 개선하고자 합니다.웹 애플리케이션의 모든 최종 사용자가 미국에 있는 경우 다음 중 리소스 효율성이 가장 높은 솔루션은 무엇입니까?,Elastic Load Balancer 뒤의 두 지역에 웹 계층 EC2 인스턴스를 배포합니다. 읽기 복제본 구성에서 Amazon RDS MySQL 데이터베이스 배포,Elastic Load Balancer 뒤의 두 지역에 웹 계층 EC2 인스턴스를 배포합니다. 다중 AZ 구성에서 Amazon RDS MySQL 데이터베이스 배포,Elastic Load Balancer 뒤의 두 가용 영역에 웹 계층 EC2 인스턴스를 배포합니다. 다중 AZ 구성에서 Amazon RDS MySQL 데이터베이스 배포,Elastic Load Balancer 뒤의 두 가용 영역에 웹 계층 EC2 인스턴스를 배포합니다. 읽기 복제본 구성에서 Amazon RDS MySQL 데이터베이스 배포,,,0,,
udemy,CLF-01,127,"A financial services company has deployed its flagship application on EC2 instances. Since the application handles sensitive customer data, the security team at the company wants to ensure that any third-party SSL/TLS certificates configured on EC2 instances via the AWS Certificate Manager (ACM) are renewed before their expiry date. The company has hired you as an AWS Certified Solutions Architect Associate to build a solution that notifies the security team 30 days before the certificate expiration. The solution should require the least amount of scripting and maintenance effort.What will you recommend?",D,D,Monitor the days to expiry CloudWatch metric for certificates created via ACM. Create a CloudWatch alarm to monitor such certificates based on the days to expiry metric and then trigger a custom action of notifying the security team,Leverage AWS Config managed rule to check if any SSL/TLS certificates created via ACM are marked for expiration within 30 days. Configure the rule to trigger an SNS notification to the security team if any certificate expires within 30 days,Monitor the days to expiry CloudWatch metric for certificates imported into ACM. Create a CloudWatch alarm to monitor such certificates based on the days to expiry metric and then trigger a custom action of notifying the security team,Leverage AWS Config managed rule to check if any third-party SSL/TLS certificates imported into ACM are marked for expiration within 30 days. Configure the rule to trigger an SNS notification to the security team if any certificate expires within 30 days,,,,금융 서비스 회사는 EC2 인스턴스에 플래그십 애플리케이션을 배포했습니다. 애플리케이션이 민감한 고객 데이터를 처리하기 때문에 회사의 보안 팀은 AWS Certificate Manager(ACM)를 통해 EC2 인스턴스에 구성된 모든 타사 SSL/TLS 인증서가 만료 날짜 전에 갱신되는지 확인하려고 합니다. 이 회사는 인증서 만료 30일 전에 보안 팀에 알리는 솔루션을 구축하기 위해 귀하를 AWS 공인 솔루션 아키텍트 어소시에이트로 고용했습니다. 솔루션에는 최소한의 스크립팅 및 유지 관리 노력이 필요합니다.무엇을 추천하시겠습니까?,ACM을 통해 생성된 인증서에 대한 CloudWatch 지표를 모니터링합니다 days to expiry. 메트릭 을 기반으로 이러한 인증서를 모니터링하는 CloudWatch 경보를 생성한 days to expiry다음 보안 팀에 알리는 사용자 지정 작업을 트리거합니다.,AWS Config 관리형 규칙을 활용하여 ACM을 통해 생성된 SSL/TLS 인증서가 30일 이내에 만료되도록 표시되어 있는지 확인하십시오. 인증서가 30일 이내에 만료되면 보안 팀에 SNS 알림을 트리거하도록 규칙 구성,days to expiryACM으로 가져온 인증서에 대한 CloudWatch 지표를 모니터링합니다 . 메트릭 을 기반으로 이러한 인증서를 모니터링하는 CloudWatch 경보를 생성한 days to expiry다음 보안 팀에 알리는 사용자 지정 작업을 트리거합니다.,AWS Config 관리형 규칙을 활용하여 ACM으로 가져온 타사 SSL/TLS 인증서가 30일 이내에 만료되도록 표시되어 있는지 확인합니다. 인증서가 30일 이내에 만료되면 보안 팀에 SNS 알림을 트리거하도록 규칙 구성,,,0,,
udemy,CLF-01,128,You would like to use Snowball to move on-premises backups into a long term archival tier on AWS. Which solution provides the MOST cost savings?,C,C,Create a Snowball job and target an S3 bucket. Create a lifecycle policy to transition this data to Glacier on the same day,Create a Snowball job and target a Glacier Deep Archive Vault,Create a Snowball job and target an S3 bucket. Create a lifecycle policy to transition this data to Glacier Deep Archive on the same day,Create a Snowball job and target a Glacier Vault,,,,Snowball을 사용하여 온프레미스 백업을 AWS의 장기 보관 계층으로 이동하려고 합니다. 비용 절감 효과가 가장 큰 솔루션은 무엇입니까?,Snowball 작업을 생성하고 S3 버킷을 대상으로 지정합니다. 같은 날 이 데이터를 Glacier로 전환하는 수명 주기 정책을 생성합니다.,Snowball 작업 생성 및 Glacier Deep Archive Vault 대상 지정,Snowball 작업을 생성하고 S3 버킷을 대상으로 지정합니다. 같은 날 이 데이터를 Glacier Deep Archive로 전환하는 수명 주기 정책을 생성합니다.,Snowball 작업 생성 및 Glacier Vault 타겟팅,,,0,,
udemy,CLF-01,129,A financial services company wants to store confidential data in Amazon S3 and it needs to meet the following data security and compliance norms:Encryption key usage must be logged for auditing purposesEncryption Keys must be rotated every yearThe data must be encrypted at restWhich is the MOST operationally efficient solution?,D,D,Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with manual key rotation,Server-side encryption with customer-provided keys (SSE-C) with automatic key rotation,Server-side encryption (SSE-S3) with automatic key rotation,Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic key rotation,,,,금융 서비스 회사는 기밀 데이터를 Amazon S3에 저장하려고 하며 다음 데이터 보안 및 규정 준수 규범을 충족해야 합니다.감사 목적으로 암호화 키 사용을 기록해야 합니다.암호화 키는 매년 교체해야 합니다.유휴 상태에서 데이터를 암호화해야 합니다.운영상 가장 효율적인 솔루션은 무엇입니까?,수동 키 교체로 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화,자동 키 순환이 있는 고객 제공 키(SSE-C)를 사용한 서버 측 암호화,자동 키 순환을 통한 서버 측 암호화(SSE-S3),자동 키 교체가 있는 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화,,,0,,
udemy,CLF-01,130,"A weather forecast agency collects key weather metrics across multiple cities in the US and sends this data in the form of key-value pairs to AWS Cloud at a one-minute frequency.As a solutions architect, which of the following AWS services would you use to build a solution for processing and then reliably storing this data with high availability? (Select two)",DE,DE,ElastiCache,Redshift,RDS,DynamoDB,Lambda,,,일기 예보 기관은 미국의 여러 도시에서 주요 날씨 지표를 수집하고 이 데이터를 키-값 쌍의 형태로 1분 간격으로 AWS 클라우드에 보냅니다.솔루션 설계자로서 다음 중 어떤 AWS 서비스를 사용하여 이 데이터를 고가용성으로 처리하고 안정적으로 저장하기 위한 솔루션을 구축하시겠습니까? (2개 선택),ElastiCache,적색편이,RDS,DynamoDB,람다,,0,,
udemy,CLF-01,131,A healthcare company has deployed its web application on Amazon ECS container instances running behind an Application Load Balancer (ALB). The website slows down when the traffic spikes and the website availability is also reduced. The development team has configured CloudWatch alarms to receive notifications whenever there is an availability constraint so the team can scale out resources. The company wants an automated solution to respond to such events.Which of the following addresses the given use case?,C,C,Configure AWS Auto Scaling to scale out the ECS cluster when the CloudWatch alarm's CPU utilization rises above a threshold,Configure AWS Auto Scaling to scale out the ECS cluster when the ALB's CPU utilization rises above a threshold,Configure AWS Auto Scaling to scale out the ECS cluster when the ECS service's CPU utilization rises above a threshold,Configure AWS Auto Scaling to scale out the ECS cluster when the ALB target group's CPU utilization rises above a threshold,,,,의료 회사는 ALB(Application Load Balancer) 뒤에서 실행되는 Amazon ECS 컨테이너 인스턴스에 웹 애플리케이션을 배포했습니다. 트래픽이 급증하고 웹사이트 가용성도 감소하면 웹사이트 속도가 느려집니다. 개발 팀은 팀이 리소스를 확장할 수 있도록 가용성 제약이 있을 때마다 알림을 수신하도록 CloudWatch 경보를 구성했습니다. 회사는 이러한 이벤트에 대응할 수 있는 자동화된 솔루션을 원합니다.다음 중 주어진 사용 사례를 다루는 것은 무엇입니까?,CloudWatch 경보의 CPU 사용률이 임계값을 초과하면 ECS 클러스터를 확장하도록 AWS Auto Scaling 구성,ALB의 CPU 사용률이 임계값을 초과하면 ECS 클러스터를 확장하도록 AWS Auto Scaling 구성,ECS 서비스의 CPU 사용률이 임계값을 초과하면 ECS 클러스터를 확장하도록 AWS Auto Scaling 구성,ALB 대상 그룹의 CPU 사용률이 임계값을 초과하면 ECS 클러스터를 확장하도록 AWS Auto Scaling 구성,,,0,,
udemy,CLF-01,132,"A startup has created a new web application for users to complete a risk assessment survey for COVID-19 symptoms via a self-administered questionnaire. The startup has purchased the domain covid19survey.com using Route 53. The web development team would like to create a Route 53 record so that all traffic for covid19survey.com is routed to www.covid19survey.com.As a solutions architect, which of the following is the MOST cost-effective solution that you would recommend to the web development team?",D,D,Create a CNAME record for covid19survey.com that routes traffic to www.covid19survey.com,Create an MX record for covid19survey.com that routes traffic to www.covid19survey.com,Create an NS record for covid19survey.com that routes traffic to www.covid19survey.com,Create an alias record for covid19survey.com that routes traffic to www.covid19survey.com,,,,한 신생 기업이 사용자가 자가 관리 설문지를 통해 COVID-19 증상에 대한 위험 평가 설문 조사를 완료할 수 있는 새로운 웹 애플리케이션을 만들었습니다. 이 스타트업은 Route 53을 사용하여 covid19survey.com 도메인을 구입했습니다. 웹 개발 팀은 covid19survey.com의 모든 트래픽이 www.covid19survey.com으로 라우팅되도록 Route 53 레코드를 생성하고자 합니다.다음 중 솔루션 아키텍트로서 웹 개발 팀에 추천할 가장 비용 효율적인 솔루션은 무엇입니까?,트래픽을 www.covid19survey.com으로 라우팅하는 covid19survey.com용 CNAME 레코드 생성,트래픽을 www.covid19survey.com으로 라우팅하는 covid19survey.com에 대한 MX 레코드 생성,트래픽을 www.covid19survey.com으로 라우팅하는 covid19survey.com에 대한 NS 레코드 생성,트래픽을 www.covid19survey.com으로 라우팅하는 covid19survey.com에 대한 별칭 레코드 생성,,,0,,
udemy,CLF-01,133,"The engineering team at a company wants to use Amazon SQS to decouple components of the underlying application architecture. However, the team is concerned about the VPC-bound components accessing SQS over the public internet.As a solutions architect, which of the following solutions would you recommend to address this use-case?",D,D,Use Internet Gateway to access Amazon SQS,Use VPN connection to access Amazon SQS,Use Network Address Translation (NAT) instance to access Amazon SQS,Use VPC endpoint to access Amazon SQS,,,,회사의 엔지니어링 팀은 Amazon SQS를 사용하여 기본 애플리케이션 아키텍처의 구성 요소를 분리하려고 합니다. 그러나 팀은 공용 인터넷을 통해 SQS에 액세스하는 VPC 바인딩 구성 요소에 대해 우려하고 있습니다.솔루션 설계자로서 이 사용 사례를 해결하기 위해 다음 중 어떤 솔루션을 권장하시겠습니까?,인터넷 게이트웨이를 사용하여 Amazon SQS에 액세스,VPN 연결을 사용하여 Amazon SQS에 액세스,NAT(Network Address Translation) 인스턴스를 사용하여 Amazon SQS에 액세스,VPC 엔드포인트를 사용하여 Amazon SQS에 액세스,,,0,,
udemy,CLF-01,134,An AWS Organization is using Service Control Policies (SCP) for central control over the maximum available permissions for all accounts in their organization. This allows the organization to ensure that all accounts stay within the organization’s access control guidelines.Which of the given scenarios are correct regarding the permissions described below? (Select three),ABF,ABF,"SCPs affect all users and roles in attached accounts, including the root user",SCPs do not affect service-linked role,"SCPs affect all users and roles in attached accounts, excluding the root user",SCPs affect service-linked roles,"If a user or role has an IAM permission policy that grants access to an action that is either not allowed or explicitly denied by the applicable SCPs, the user or role can still perform that action","If a user or role has an IAM permission policy that grants access to an action that is either not allowed or explicitly denied by the applicable SCPs, the user or role can't perform that action",,AWS 조직은 조직의 모든 계정에 대해 사용 가능한 최대 권한을 중앙에서 제어하기 위해 서비스 제어 정책(SCP)을 사용하고 있습니다. 이를 통해 조직은 모든 ​​계정이 조직의 액세스 제어 지침 내에서 유지되도록 할 수 있습니다.아래에 설명된 권한과 관련하여 주어진 시나리오 중 올바른 것은 무엇입니까? (3개 선택),SCP는 루트 사용자를 포함하여 연결된 계정의 모든 사용자 및 역할에 영향을 미칩니다.,SCP는 서비스 연결 역할에 영향을 미치지 않습니다.,SCP는 루트 사용자를 제외한 연결된 계정의 모든 사용자 및 역할에 영향을 미칩니다.,SCP는 서비스 연결 역할에 영향을 미칩니다.,사용자 또는 역할에 해당 SCP에 의해 허용되지 않거나 명시적으로 거부된 작업에 대한 액세스 권한을 부여하는 IAM 권한 정책이 있는 경우 사용자 또는 역할은 여전히 ​​해당 작업을 수행할 수 있습니다.,,0,,사용자 또는 역할에 해당 SCP에 의해 허용되지 않거나 명시적으로 거부된 작업에 대한 액세스 권한을 부여하는 IAM 권한 정책이 있는 경우 사용자 또는 역할은 해당 작업을 수행할 수 없습니다.
udemy,CLF-01,135,"A gaming company uses Application Load Balancers (ALBs) in front of Amazon EC2 instances for different services and microservices. The architecture has now become complex with too many ALBs in multiple AWS Regions. Security updates, firewall configurations, and traffic routing logic have become complex with too many IP addresses and configurations.The company is looking at an easy and effective way to bring down the number of IP addresses allowed by the firewall and easily manage the entire network infrastructure. Which of these options represents an appropriate solution for this requirement?",D,D,Set up a Network Load Balancer (NLB) with Elastic IPs. Register the private IPs of all the ALBs as targets of this NLB,"Assign an Elastic IP to an Auto Scaling Group (ASG), and set up multiple Amazon EC2 instances to run behind the ASGs, for each of the Regions",Configure Elastic IPs for each of the ALBs in each Region,Launch AWS Global Accelerator and create endpoints for all the Regions. Register the ALBs of each Region to the corresponding endpoints,,,,"게임 회사는 다양한 서비스 및 마이크로 서비스를 위해 Amazon EC2 인스턴스 앞에 Application Load Balancer(ALB)를 사용합니다. 아키텍처는 이제 여러 AWS 리전에서 너무 많은 ALB로 인해 복잡해졌습니다. 너무 많은 IP 주소와 구성으로 인해 보안 업데이트, 방화벽 구성 및 트래픽 라우팅 논리가 복잡해졌습니다.회사는 방화벽에서 허용하는 IP 주소 수를 줄이고 전체 네트워크 인프라를 쉽게 관리할 수 있는 쉽고 효과적인 방법을 찾고 있습니다. 다음 옵션 중 이 요구 사항에 적합한 솔루션은 무엇입니까?",탄력적 IP로 NLB(Network Load Balancer)를 설정합니다. 모든 ALB의 사설 IP를 이 NLB의 대상으로 등록합니다.,ASG(Auto Scaling Group)에 탄력적 IP를 할당하고 각 지역에 대해 ASG 뒤에서 실행할 여러 Amazon EC2 인스턴스를 설정합니다.,각 지역의 각 ALB에 대한 탄력적 IP 구성,AWS Global Accelerator를 시작하고 모든 지역에 대한 엔드포인트를 생성합니다. 각 지역의 ALB를 해당 엔드포인트에 등록,,,0,,
udemy,CLF-01,136,"A media startup is looking at hosting their web application on AWS Cloud. The application will be accessed by users from different geographic regions of the world to upload and download video files that can reach a maximum size of 10GB. The startup wants the solution to be cost-effective and scalable with the lowest possible latency for a great user experience.As a Solutions Architect, which of the following will you suggest as an optimal solution to meet the given requirements?",B,B,"Use Amazon EC2 with Global Accelerator for faster distribution of content, while using Amazon S3 as storage service",Use Amazon S3 for hosting the web application and use S3 Transfer Acceleration to reduce the latency that geographically dispersed users might face,"Use Amazon EC2 with ElastiCache for faster distribution of content, while Amazon S3 can be used as a storage service",Use Amazon S3 for hosting the web application and use Amazon CloudFront for faster distribution of content to geographically dispersed users,,,,미디어 스타트업이 AWS 클라우드에서 웹 애플리케이션을 호스팅하려고 합니다. 응용 프로그램은 최대 10GB 크기에 도달할 수 있는 비디오 파일을 업로드하고 다운로드하기 위해 전 세계 여러 지역의 사용자가 액세스할 수 있습니다. 스타트업은 뛰어난 사용자 경험을 위해 지연 시간을 최소화하면서 비용 효율적이고 확장 가능한 솔루션을 원합니다.Solutions Architect로서 주어진 요구 사항을 충족하는 최적의 솔루션으로 다음 중 무엇을 제안하시겠습니까?,Amazon S3를 스토리지 서비스로 사용하면서 더 빠른 콘텐츠 배포를 위해 Amazon EC2를 Global Accelerator와 함께 사용,Amazon S3를 사용하여 웹 애플리케이션을 호스팅하고 S3 Transfer Acceleration을 사용하여 지리적으로 분산된 사용자가 직면할 수 있는 지연 시간을 줄입니다.,ElastiCache와 함께 Amazon EC2를 사용하여 콘텐츠를 더 빠르게 배포하고 Amazon S3를 스토리지 서비스로 사용할 수 있습니다.,Amazon S3를 사용하여 웹 애플리케이션 호스팅 및 Amazon CloudFront를 사용하여 지리적으로 분산된 사용자에게 더 빠르게 콘텐츠 배포,,,0,,
udemy,CLF-01,137,"A startup has recently moved their monolithic web application to AWS Cloud. The application runs on a single EC2 instance. Currently, the user base is small and the startup does not want to spend effort on elaborate disaster recovery strategies or Auto Scaling Group. The application can afford a maximum downtime of 10 minutes.In case of a failure, which of these options would you suggest as a cost-effective and automatic recovery procedure for the instance?",A,A,"Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance, in case the instance fails. The instance, however, should only be configured with an EBS volume","Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance, in case the instance fails. The instance can be configured with EBS volume or with instance store volumes",Configure AWS Trusted Advisor to monitor the health check of EC2 instance and provide a remedial action in case an unhealthy flag is detected,"Configure Amazon EventBridge events that can trigger the recovery of the EC2 instance, in case the instance or the application fails",,,,한 스타트업이 최근 모놀리식 웹 애플리케이션을 AWS 클라우드로 옮겼습니다. 애플리케이션은 단일 EC2 인스턴스에서 실행됩니다. 현재 사용자 기반이 작고 스타트업은 정교한 재해 복구 전략이나 Auto Scaling Group에 노력을 기울이고 싶지 않습니다. 애플리케이션은 최대 10분의 가동 중지 시간을 허용할 수 있습니다.장애가 발생한 경우 인스턴스에 대한 비용 효율적인 자동 복구 절차로 제안할 옵션은 무엇입니까?,인스턴스가 실패할 경우 EC2 인스턴스 복구를 트리거하는 Amazon CloudWatch 경보를 구성합니다. 그러나 인스턴스는 EBS 볼륨으로만 구성해야 합니다.,인스턴스가 실패할 경우 EC2 인스턴스 복구를 트리거하는 Amazon CloudWatch 경보를 구성합니다. 인스턴스는 EBS 볼륨 또는 인스턴스 스토어 볼륨으로 구성할 수 있습니다.,EC2 인스턴스의 상태 확인을 모니터링하고 비정상 플래그가 감지된 경우 수정 조치를 제공하도록 AWS Trusted Advisor를 구성합니다.,인스턴스 또는 애플리케이션이 실패하는 경우 EC2 인스턴스 복구를 트리거할 수 있는 Amazon EventBridge 이벤트 구성,,,0,,
udemy,CLF-01,138,"A media company wants a low-latency way to distribute live sports results which are delivered via a proprietary application using UDP protocol.As a solutions architect, which of the following solutions would you recommend such that it offers the BEST performance for this use case?",D,D,Use Auto Scaling group to provide a low latency way to distribute live sports results,Use Elastic Load Balancer to provide a low latency way to distribute live sports results,Use CloudFront to provide a low latency way to distribute live sports results,Use Global Accelerator to provide a low latency way to distribute live sports results,,,,한 미디어 회사는 UDP 프로토콜을 사용하는 독점 애플리케이션을 통해 전달되는 라이브 스포츠 결과를 배포하기 위해 대기 시간이 짧은 방법을 원합니다.솔루션 아키텍트로서 다음 중 이 사용 사례에 가장 적합한 성능을 제공하는 솔루션은 무엇입니까?,Auto Scaling 그룹을 사용하여 실시간 스포츠 결과를 배포하는 짧은 대기 시간 방법 제공,Elastic Load Balancer를 사용하여 실시간 스포츠 결과를 배포하는 지연 시간이 짧은 방법 제공,CloudFront를 사용하여 지연 시간이 짧은 실시간 스포츠 결과 배포 방법 제공,Global Accelerator를 사용하여 실시간 스포츠 결과를 배포하는 짧은 대기 시간 방법 제공,,,0,,
udemy,CLF-01,139,"A financial services company is migrating their messaging queues from self-managed message-oriented middleware systems to Amazon SQS. The development team at the company wants to minimize the costs of using SQS.As a solutions architect, which of the following options would you recommend for the given use-case?",C,C,Use SQS visibility timeout to retrieve messages from your Amazon SQS queues,Use SQS message timer to retrieve messages from your Amazon SQS queues,Use SQS long polling to retrieve messages from your Amazon SQS queues,Use SQS short polling to retrieve messages from your Amazon SQS queues,,,,금융 서비스 회사는 메시징 대기열을 자체 관리형 메시지 지향 미들웨어 시스템에서 Amazon SQS로 마이그레이션하고 있습니다. 회사의 개발 팀은 SQS 사용 비용을 최소화하려고 합니다.솔루션 설계자로서 주어진 사용 사례에 대해 다음 중 어떤 옵션을 권장하시겠습니까?,SQS 가시성 제한 시간을 사용하여 Amazon SQS 대기열에서 메시지 검색,SQS 메시지 타이머를 사용하여 Amazon SQS 대기열에서 메시지 검색,SQS 긴 폴링을 사용하여 Amazon SQS 대기열에서 메시지 검색,SQS 짧은 폴링을 사용하여 Amazon SQS 대기열에서 메시지 검색,,,0,,
udemy,CLF-01,140,"A retail company uses AWS Cloud to manage its IT infrastructure. The company has set up ""AWS Organizations"" to manage several departments running their AWS accounts and using resources such as EC2 instances and RDS databases. The company wants to provide shared and centrally-managed VPCs to all departments using applications that need a high degree of interconnectivity.As a solutions architect, which of the following options would you choose to facilitate this use-case?",B,B,Use VPC sharing to share a VPC with other AWS accounts belonging to the same parent organization from AWS Organizations,Use VPC sharing to share one or more subnets with other AWS accounts belonging to the same parent organization from AWS Organizations,Use VPC peering to share one or more subnets with other AWS accounts belonging to the same parent organization from AWS Organizations,Use VPC peering to share a VPC with other AWS accounts belonging to the same parent organization from AWS Organizations,,,,"소매 회사는 AWS 클라우드를 사용하여 IT 인프라를 관리합니다. 이 회사는 AWS 계정을 실행하고 EC2 인스턴스 및 RDS 데이터베이스와 같은 리소스를 사용하는 여러 부서를 관리하기 위해 ""AWS 조직""을 설정했습니다. 이 회사는 높은 수준의 상호 연결이 필요한 애플리케이션을 사용하는 모든 부서에 공유되고 중앙에서 관리되는 VPC를 제공하려고 합니다.솔루션 설계자로서 이 사용 사례를 용이하게 하기 위해 다음 중 어떤 옵션을 선택하시겠습니까?",VPC 공유를 사용하여 AWS Organizations에서 동일한 상위 조직에 속한 다른 AWS 계정과 VPC를 공유합니다.,VPC 공유를 사용하여 AWS Organizations에서 동일한 상위 조직에 속한 다른 AWS 계정과 하나 이상의 서브넷을 공유합니다.,VPC 피어링을 사용하여 AWS Organizations에서 동일한 상위 조직에 속한 다른 AWS 계정과 하나 이상의 서브넷을 공유합니다.,VPC 피어링을 사용하여 AWS Organizations에서 동일한 상위 조직에 속한 다른 AWS 계정과 VPC를 공유,,,0,,
udemy,CLF-01,141,"A company has a license-based, expensive, legacy commercial database solution deployed at its on-premises data center. The company wants to migrate this database to a more efficient, open-source, and cost-effective option on AWS Cloud. The CTO at the company wants a solution that can handle complex database configurations such as secondary indexes, foreign keys, and stored procedures.As a solutions architect, which of the following AWS services should be combined to handle this use-case? (Select two)",BC,BC,AWS Glue,AWS Schema Conversion Tool,AWS Database Migration Service,Basic Schema Copy,AWS Snowball Edge,,,"회사는 온프레미스 데이터 센터에 라이선스 기반의 고가의 레거시 상용 데이터베이스 솔루션을 배포했습니다. 이 회사는 이 데이터베이스를 AWS 클라우드에서 보다 효율적이고 비용 효율적인 오픈 소스 옵션으로 마이그레이션하려고 합니다. 회사의 CTO는 보조 인덱스, 외래 키 및 저장 프로시저와 같은 복잡한 데이터베이스 구성을 처리할 수 있는 솔루션을 원합니다.솔루션 설계자로서 이 사용 사례를 처리하기 위해 다음 AWS 서비스 중 무엇을 결합해야 합니까? (2개 선택)",AWS 글루,AWS 스키마 변환 도구,AWS 데이터베이스 마이그레이션 서비스,기본 스키마 복사,AWS 스노우볼 에지,,0,,
udemy,CLF-01,142,"A legacy application is built using a tightly-coupled monolithic architecture. Due to a sharp increase in the number of users, the application performance has degraded. The company now wants to decouple the architecture and adopt AWS microservices architecture. Some of these microservices need to handle fast running processes whereas other microservices need to handle slower processes.Which of these options would you identify as the right way of connecting these microservices?",C,C,Use Amazon SNS to decouple microservices running faster processes from the microservices running slower ones,Configure Amazon Kinesis Data Streams to decouple microservices running faster processes from the microservices running slower ones,Configure Amazon SQS queue to decouple microservices running faster processes from the microservices running slower ones,Add Amazon EventBridge to decouple the complex architecture,,,,레거시 애플리케이션은 밀접하게 결합된 모놀리식 아키텍처를 사용하여 구축됩니다. 사용자의 급격한 증가로 인해 애플리케이션 성능이 저하되었습니다. 회사는 이제 아키텍처를 분리하고 AWS 마이크로서비스 아키텍처를 채택하기를 원합니다. 이러한 마이크로 서비스 중 일부는 빠르게 실행되는 프로세스를 처리해야 하는 반면 다른 마이크로 서비스는 느린 프로세스를 처리해야 합니다.다음 중 이러한 마이크로서비스를 연결하는 올바른 방법으로 식별할 수 있는 옵션은 무엇입니까?,Amazon SNS를 사용하여 더 느린 프로세스를 실행하는 마이크로서비스에서 더 빠른 프로세스를 실행하는 마이크로서비스를 분리합니다.,더 느린 프로세스를 실행하는 마이크로서비스에서 더 빠른 프로세스를 실행하는 마이크로서비스를 분리하도록 Amazon Kinesis Data Streams 구성,더 느린 프로세스를 실행하는 마이크로서비스에서 더 빠른 프로세스를 실행하는 마이크로서비스를 분리하도록 Amazon SQS 대기열 구성,Amazon EventBridge를 추가하여 복잡한 아키텍처 분리,,,0,,
udemy,CLF-01,143,"The DevOps team at an IT company has recently migrated to AWS and they are configuring security groups for their two-tier application with public web servers and private database servers. The team wants to understand the allowed configuration options for an inbound rule for a security group.As a solutions architect, which of the following would you identify as an INVALID option for setting up such a configuration?",A,A,You can use an Internet Gateway ID as the custom source for the inbound rule,You can use an IP address as the custom source for the inbound rule,You can use a security group as the custom source for the inbound rule,You can use a range of IP addresses in CIDR block notation as the custom source for the inbound rule,,,,IT 회사의 DevOps 팀은 최근 AWS로 마이그레이션했으며 공용 웹 서버와 개인 데이터베이스 서버로 2계층 애플리케이션에 대한 보안 그룹을 구성하고 있습니다. 팀은 보안 그룹의 인바운드 규칙에 대해 허용되는 구성 옵션을 이해하려고 합니다.솔루션 설계자로서 다음 중 그러한 구성을 설정하기 위한 잘못된 옵션으로 식별할 수 있는 것은 무엇입니까?,인터넷 게이트웨이 ID를 인바운드 규칙의 사용자 정의 소스로 사용할 수 있습니다.,인바운드 규칙의 사용자 정의 소스로 IP 주소를 사용할 수 있습니다.,인바운드 규칙의 사용자 지정 소스로 보안 그룹을 사용할 수 있습니다.,CIDR 블록 표기법의 IP 주소 범위를 인바운드 규칙의 사용자 정의 소스로 사용할 수 있습니다.,,,0,,
udemy,CLF-01,144,"A social media startup uses AWS Cloud to manage its IT infrastructure. The engineering team at the startup wants to perform weekly database rollovers for a MySQL database server using a serverless cron job that typically takes about 5 minutes to execute the database rollover script written in Python. The database rollover will archive the past week’s data from the production database to keep the database small while still keeping its data accessible.As a solutions architect, which of the following would you recommend as the MOST cost-efficient and reliable solution?",A,A,Schedule a weekly EventBridge event cron expression to invoke a Lambda function that runs the database rollover job,Provision an EC2 scheduled reserved instance to run the database rollover script to be run via an OS-based weekly cron expression,Create a time-based schedule option within an AWS Glue job to invoke itself every week and run the database rollover script,Provision an EC2 spot instance to run the database rollover script to be run via an OS-based weekly cron expression,,,,소셜 미디어 스타트업은 AWS 클라우드를 사용하여 IT 인프라를 관리합니다. 스타트업의 엔지니어링 팀은 일반적으로 Python으로 작성된 데이터베이스 롤오버 스크립트를 실행하는 데 약 5분이 소요되는 서버리스 크론 작업을 사용하여 MySQL 데이터베이스 서버에 대한 주간 데이터베이스 롤오버를 수행하려고 합니다. 데이터베이스 롤오버는 프로덕션 데이터베이스에서 지난 주 데이터를 보관하여 데이터베이스를 작게 유지하면서 데이터에 계속 액세스할 수 있도록 합니다.솔루션 아키텍트로서 다음 중 가장 비용 효율적이고 안정적인 솔루션으로 추천하는 것은 무엇입니까?,주간 EventBridge 이벤트 cron 표현식을 예약하여 데이터베이스 롤오버 작업을 실행하는 Lambda 함수를 호출합니다.,OS 기반 주간 Cron 표현식을 통해 실행할 데이터베이스 롤오버 스크립트를 실행하도록 EC2 예약 예약 인스턴스 프로비저닝,매주 스스로 호출하고 데이터베이스 롤오버 스크립트를 실행하기 위해 AWS Glue 작업 내에서 시간 기반 일정 옵션을 생성합니다.,OS 기반 주간 Cron 표현식을 통해 실행할 데이터베이스 롤오버 스크립트를 실행하도록 EC2 스팟 인스턴스를 프로비저닝합니다.,,,0,,
udemy,CLF-01,145,Which of the following AWS services provides a highly available and fault-tolerant solution to capture the clickstream events from the source and then provide a concurrent feed of the data stream to the downstream applications?,A,A,AWS Kinesis Data Streams,AWS Kinesis Data Firehose,AWS Kinesis Data Analytics,Amazon SQS,,,,다음 중 소스에서 클릭스트림 이벤트를 캡처한 다음 데이터 스트림의 동시 피드를 다운스트림 애플리케이션에 제공하는 고가용성 및 내결함성 솔루션을 제공하는 AWS 서비스는 무엇입니까?,AWS Kinesis 데이터 스트림,AWS Kinesis Data Firehose,AWS Kinesis 데이터 분석,아마존 SQS,,,0,,
udemy,CLF-01,146,The DevOps team at a multi-national company is helping its subsidiaries standardize EC2 instances by using the same Amazon Machine Image (AMI). Some of these subsidiaries are in the same AWS region but use different AWS accounts whereas others are in different AWS regions but use the same AWS account as the parent company. The DevOps team has hired you as a solutions architect for this project.Which of the following would you identify as CORRECT regarding the capabilities of AMIs? (Select three),ADE,ADE,You can copy an AMI across AWS Regions,Copying an AMI backed by an encrypted snapshot results in an unencrypted target snapshot,You cannot share an AMI with another AWS account,Copying an AMI backed by an encrypted snapshot cannot result in an unencrypted target snapshot,You can share an AMI with another AWS account,You cannot copy an AMI across AWS Regions,,다국적 기업의 DevOps 팀은 자회사가 동일한 Amazon Machine Image(AMI)를 사용하여 EC2 인스턴스를 표준화하도록 돕고 있습니다. 이러한 자회사 중 일부는 동일한 AWS 지역에 있지만 다른 AWS 계정을 사용하는 반면 다른 자회사는 다른 AWS 지역에 있지만 모회사와 동일한 AWS 계정을 사용합니다. DevOps 팀은 귀하를 이 프로젝트의 솔루션 설계자로 고용했습니다.AMI의 기능과 관련하여 다음 중 올바른 것으로 식별하는 것은 무엇입니까? (3개 선택),AWS 리전 간에 AMI를 복사할 수 있습니다.,암호화된 스냅샷이 지원하는 AMI를 복사하면 암호화되지 않은 대상 스냅샷이 생성됨,다른 AWS 계정과 AMI를 공유할 수 없습니다.,암호화된 스냅샷이 지원하는 AMI를 복사하면 암호화되지 않은 대상 스냅샷이 생성될 수 없습니다.,다른 AWS 계정과 AMI를 공유할 수 있습니다.,,0,,AWS 리전 간에 AMI를 복사할 수 없습니다.
udemy,CLF-01,147,A retail organization is moving some of its on-premises data to AWS Cloud. The DevOps team at the organization has set up an AWS Managed IPSec VPN Connection between their remote on-premises network and their Amazon VPC over the internet.Which of the following represents the correct configuration for the IPSec VPN Connection?,C,C,Create a Virtual Private Gateway on the on-premises side of the VPN and a Customer Gateway on the AWS side of the VPN,Create a Virtual Private Gateway on both the AWS side of the VPN as well as the on-premises side of the VPN,Create a Virtual Private Gateway on the AWS side of the VPN and a Customer Gateway on the on-premises side of the VPN,Create a Customer Gateway on both the AWS side of the VPN as well as the on-premises side of the VPN,,,,소매 조직은 일부 온프레미스 데이터를 AWS 클라우드로 이동하고 있습니다. 조직의 DevOps 팀은 인터넷을 통해 원격 온프레미스 네트워크와 Amazon VPC 간에 AWS 관리형 IPSec VPN 연결을 설정했습니다.다음 중 IPSec VPN 연결에 대한 올바른 구성을 나타내는 것은 무엇입니까?,VPN의 온프레미스 측에 가상 프라이빗 게이트웨이를 생성하고 VPN의 AWS 측에 고객 게이트웨이를 생성합니다.,VPN의 AWS 측과 VPN의 온프레미스 측 모두에 가상 프라이빗 게이트웨이 생성,VPN의 AWS 측에 가상 프라이빗 게이트웨이를 생성하고 VPN의 온프레미스 측에 고객 게이트웨이를 생성합니다.,VPN의 AWS 측과 VPN의 온프레미스 측 모두에서 고객 게이트웨이 생성,,,0,,
udemy,CLF-01,148,"A company has set up ""AWS Organizations"" to manage several departments running their own AWS accounts. The departments operate from different countries and are spread across various AWS Regions. The company wants to set up a consistent resource provisioning process across departments so that each resource follows pre-defined configurations such as using a specific type of EC2 instances, specific IAM roles for Lambda functions, etc.As a solutions architect, which of the following options would you recommend for this use-case?",A,A,Use AWS CloudFormation StackSets to deploy the same template across AWS accounts and regions,Use AWS CloudFormation stacks to deploy the same template across AWS accounts and regions,Use AWS Resource Access Manager (RAM) to deploy the same template across AWS accounts and regions,Use AWS CloudFormation templates to deploy the same template across AWS accounts and regions,,,,"회사에서 자체 AWS 계정을 실행하는 여러 부서를 관리하기 위해 ""AWS 조직""을 설정했습니다. 부서는 여러 국가에서 운영되며 다양한 AWS 리전에 분산되어 있습니다. 회사는 각 리소스가 특정 유형의 EC2 인스턴스 사용, Lambda 함수에 대한 특정 IAM 역할 등과 같은 사전 정의된 구성을 따르도록 부서 간에 일관된 리소스 프로비저닝 프로세스를 설정하려고 합니다.솔루션 설계자로서 이 사용 사례에 대해 다음 중 어떤 옵션을 권장하시겠습니까?",AWS CloudFormation StackSets를 사용하여 AWS 계정 및 리전에 동일한 템플릿 배포,AWS CloudFormation 스택을 사용하여 AWS 계정 및 리전에 동일한 템플릿 배포,AWS Resource Access Manager(RAM)를 사용하여 AWS 계정 및 리전에 동일한 템플릿 배포,AWS CloudFormation 템플릿을 사용하여 AWS 계정 및 리전에 동일한 템플릿 배포,,,0,,
udemy,CLF-01,149,"An e-commerce company has deployed its application on several EC2 instances that are configured in a private subnet using IPv4. These EC2 instances read and write a huge volume of data to and from Amazon S3 in the same AWS region. The company has set up subnet routing to direct all the internet-bound traffic through a NAT gateway. The company wants to build the most cost-optimal solution without impacting the application's ability to communicate with Amazon S3 or the internet.As an AWS Certified Solutions Architect Associate, which of the following would you recommend?",A,A,Set up a VPC gateway endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct the S3-bound traffic to the VPC endpoint,Provision an internet gateway. Update the route table in the private subnet to route traffic to the internet gateway. Update the network ACL to allow the S3-bound traffic,Set up an egress-only internet gateway in the public subnet. Update the route table in the private subnet to route traffic to the internet gateway. Update the network ACL to allow the S3-bound traffic,Set up a gateway load balancer endpoint for Amazon S3. Update the route table in the private subnet to direct the S3-bound traffic via the gateway load balancer endpoint,,,,전자 상거래 회사는 IPv4를 사용하여 프라이빗 서브넷에 구성된 여러 EC2 인스턴스에 애플리케이션을 배포했습니다. 이러한 EC2 인스턴스는 동일한 AWS 지역의 Amazon S3에서 엄청난 양의 데이터를 읽고 씁니다. 회사는 NAT 게이트웨이를 통해 모든 인터넷 바인딩 트래픽을 전달하기 위해 서브넷 라우팅을 설정했습니다. 이 회사는 애플리케이션이 Amazon S3 또는 인터넷과 통신하는 기능에 영향을 주지 않으면서 가장 비용 최적화된 솔루션을 구축하고자 합니다.AWS 공인 솔루션스 아키텍트 어소시에이트로서 다음 중 무엇을 추천하시겠습니까?,Amazon S3에 대한 VPC 게이트웨이 엔드포인트를 설정합니다. 끝점 정책을 끝점에 연결합니다. 라우팅 테이블을 업데이트하여 S3 바운드 트래픽을 VPC 엔드포인트로 보냅니다.,인터넷 게이트웨이를 프로비저닝합니다. 트래픽을 인터넷 게이트웨이로 라우팅하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. S3 바인딩 트래픽을 허용하도록 네트워크 ACL 업데이트,퍼블릭 서브넷에서 외부 전용 인터넷 게이트웨이를 설정합니다. 트래픽을 인터넷 게이트웨이로 라우팅하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. S3 바인딩 트래픽을 허용하도록 네트워크 ACL 업데이트,Amazon S3에 대한 게이트웨이 로드 밸런서 엔드포인트를 설정합니다. 게이트웨이 로드 밸런서 엔드포인트를 통해 S3 바인딩 트래픽을 전달하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.,,,0,,
udemy,CLF-01,150,"A small business has been running its IT systems on the on-premises infrastructure but the business now plans to migrate to AWS Cloud for operational efficiencies.As a Solutions Architect, can you suggest a cost-effective serverless solution for its flagship application that has both static and dynamic content?",D,D,Host both the static and dynamic content of the web application on Amazon S3 and use Amazon CloudFront for distribution across diverse regions/countries,Host both the static and dynamic content of the web application on Amazon EC2 with RDS as database. Amazon CloudFront should be configured to distribute the content across geographically disperse regions,"Host the static content on Amazon S3 and use Amazon EC2 with RDS for generating the dynamic content. Amazon CloudFront can be configured in front of EC2 instance, to make global distribution easy",Host the static content on Amazon S3 and use Lambda with DynamoDB for the serverless web application that handles dynamic content. Amazon CloudFront will sit in front of Lambda for distribution across diverse regions,,,,중소기업은 온프레미스 인프라에서 IT 시스템을 실행해 왔지만 이제 운영 효율성을 위해 AWS 클라우드로 마이그레이션할 계획입니다.솔루션 아키텍트로서 정적 콘텐츠와 동적 콘텐츠가 모두 있는 주력 애플리케이션을 위한 비용 효율적인 서버리스 솔루션을 제안할 수 있습니까?,Amazon S3에서 웹 애플리케이션의 정적 및 동적 콘텐츠를 모두 호스팅하고 Amazon CloudFront를 사용하여 다양한 지역/국가에 배포,RDS를 데이터베이스로 사용하여 Amazon EC2에서 웹 애플리케이션의 정적 및 동적 콘텐츠를 모두 호스팅합니다. 지리적으로 분산된 지역에 콘텐츠를 배포하도록 Amazon CloudFront를 구성해야 합니다.,Amazon S3에서 정적 콘텐츠를 호스팅하고 RDS와 함께 Amazon EC2를 사용하여 동적 콘텐츠를 생성합니다. EC2 인스턴스 앞에 Amazon CloudFront를 구성하여 글로벌 배포를 쉽게 할 수 있습니다.,Amazon S3에서 정적 콘텐츠를 호스팅하고 동적 콘텐츠를 처리하는 서버리스 웹 애플리케이션을 위해 DynamoDB와 함께 Lambda를 사용합니다. Amazon CloudFront는 다양한 지역에 배포하기 위해 Lambda 앞에 위치합니다.,,,0,,
udemy,CLF-01,151,A retail company has its flagship application running on a fleet of EC2 instances behind an Elastic Load Balancer (ELB). The engineering team has been seeing recurrent issues wherein the in-flight requests from the ELB to the EC2 instances are getting dropped when an instance becomes unhealthy.Which of the following features can be used to address this issue?,D,D,Idle Timeout,Sticky Sessions,Cross Zone load balancing,Connection Draining,,,,소매 회사는 ELB(Elastic Load Balancer) 뒤의 EC2 인스턴스 플릿에서 주력 애플리케이션을 실행하고 있습니다. 엔지니어링 팀은 인스턴스가 비정상이 되면 ELB에서 EC2 인스턴스로의 진행 중인 요청이 삭제되는 반복적인 문제를 확인했습니다.다음 중 이 문제를 해결하는 데 사용할 수 있는 기능은 무엇인가요?,유휴 시간 초과,고정 세션,교차 영역 로드 밸런싱,연결 배수,,,0,,
udemy,CLF-01,152,"An e-commerce company uses Microsoft Active Directory to provide users and groups with access to resources on the on-premises infrastructure. The company has extended its IT infrastructure to AWS in the form of a hybrid cloud. The engineering team at the company wants to run directory-aware workloads on AWS for a SQL Server-based application. The team also wants to configure a trust relationship to enable single sign-on (SSO) for its users to access resources in either domain.As a solutions architect, which of the following AWS services would you recommend for this use-case?",B,B,AD Connector,AWS Managed Microsoft AD,Simple AD,Amazon Cloud Directory,,,,전자 상거래 회사는 Microsoft Active Directory를 사용하여 사용자 및 그룹에게 온프레미스 인프라의 리소스에 대한 액세스 권한을 제공합니다. 이 회사는 IT 인프라를 하이브리드 클라우드의 형태로 AWS로 확장했습니다. 회사의 엔지니어링 팀은 SQL Server 기반 애플리케이션을 위해 AWS에서 디렉터리 인식 워크로드를 실행하려고 합니다. 또한 팀은 사용자가 두 도메인 중 하나의 리소스에 액세스할 수 있도록 SSO(Single Sign-On)를 사용할 수 있도록 트러스트 관계를 구성하려고 합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 AWS 서비스 중 어떤 것을 추천하시겠습니까?,AD 커넥터,AWS 관리형 Microsoft AD,단순광고,아마존 클라우드 디렉터리,,,0,,
udemy,CLF-01,153,"A financial services company has recently migrated from on-premises infrastructure to AWS Cloud. The DevOps team wants to implement a solution that allows all resource configurations to be reviewed and make sure that they meet compliance guidelines. Also, the solution should be able to offer the capability to look into the resource configuration history across the application stack.As a solutions architect, which of the following solutions would you recommend to the team?",D,D,Use AWS CloudTrail to review resource configurations to meet compliance guidelines and maintain a history of resource configuration changes,Use AWS Systems Manager to review resource configurations to meet compliance guidelines and maintain a history of resource configuration changes,Use Amazon CloudWatch to review resource configurations to meet compliance guidelines and maintain a history of resource configuration changes,Use AWS Config to review resource configurations to meet compliance guidelines and maintain a history of resource configuration changes,,,,금융 서비스 회사는 최근 온프레미스 인프라에서 AWS 클라우드로 마이그레이션했습니다. DevOps 팀은 모든 리소스 구성을 검토하고 규정 준수 지침을 충족하는지 확인할 수 있는 솔루션을 구현하려고 합니다. 또한 솔루션은 애플리케이션 스택 전체에서 리소스 구성 기록을 조사하는 기능을 제공할 수 있어야 합니다.솔루션 설계자로서 다음 중 팀에 추천할 솔루션은 무엇입니까?,규정 준수 지침을 충족하고 리소스 구성 변경 기록을 유지하기 위해 AWS CloudTrail을 사용하여 리소스 구성을 검토합니다.,규정 준수 지침을 충족하고 리소스 구성 변경 내역을 유지하기 위해 AWS Systems Manager를 사용하여 리소스 구성을 검토합니다.,Amazon CloudWatch를 사용하여 규정 준수 지침을 충족하고 리소스 구성 변경 기록을 유지하기 위해 리소스 구성을 검토합니다.,규정 준수 지침을 충족하고 리소스 구성 변경 기록을 유지하기 위해 AWS Config를 사용하여 리소스 구성을 검토합니다.,,,0,,
udemy,CLF-01,154,"A financial services company wants to identify any sensitive data stored on its Amazon S3 buckets. The company also wants to monitor and protect all data stored on S3 against any malicious activity.As a solutions architect, which of the following solutions would you recommend to help address the given requirements?",B,B,Use Amazon GuardDuty to monitor any malicious activity on data stored in S3 as well as to identify any sensitive data stored on S3,Use Amazon GuardDuty to monitor any malicious activity on data stored in S3. Use Amazon Macie to identify any sensitive data stored on S3,Use Amazon Macie to monitor any malicious activity on data stored in S3 as well as to identify any sensitive data stored on S3,Use Amazon Macie to monitor any malicious activity on data stored in S3. Use Amazon GuardDuty to identify any sensitive data stored on S3,,,,금융 서비스 회사는 Amazon S3 버킷에 저장된 민감한 데이터를 식별하려고 합니다. 회사는 또한 악의적인 활동으로부터 S3에 저장된 모든 데이터를 모니터링하고 보호하기를 원합니다.솔루션 설계자로서 다음 중 주어진 요구 사항을 해결하는 데 도움이 되는 솔루션은 무엇입니까?,Amazon GuardDuty를 사용하여 S3에 저장된 데이터에 대한 악의적인 활동을 모니터링하고 S3에 저장된 민감한 데이터를 식별합니다.,Amazon GuardDuty를 사용하여 S3에 저장된 데이터에 대한 모든 악의적인 활동을 모니터링합니다. Amazon Macie를 사용하여 S3에 저장된 민감한 데이터 식별,Amazon Macie를 사용하여 S3에 저장된 데이터에 대한 악의적인 활동을 모니터링하고 S3에 저장된 민감한 데이터를 식별합니다.,Amazon Macie를 사용하여 S3에 저장된 데이터에 대한 악의적인 활동을 모니터링합니다. Amazon GuardDuty를 사용하여 S3에 저장된 민감한 데이터 식별,,,0,,
udemy,CLF-01,155,"A developer has configured inbound traffic for the relevant ports in both the Security Group of the EC2 instance as well as the Network Access Control List (NACL) of the subnet for the EC2 instance. The developer is, however, unable to connect to the service running on the Amazon EC2 instance.As a solutions architect, how will you fix this issue?",D,D,"Network ACLs are stateful, so allowing inbound traffic to the necessary ports enables the connection. Security Groups are stateless, so you must allow both inbound and outbound traffic",IAM Role defined in the Security Group is different from the IAM Role that is given access in the Network ACLs,Rules associated with Network ACLs should never be modified from command line. An attempt to modify rules from command line blocks the rule and results in an erratic behavior,"Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must allow both inbound and outbound traffic",,,,개발자는 EC2 인스턴스의 보안 그룹과 EC2 인스턴스에 대한 서브넷의 NACL(네트워크 액세스 제어 목록) 모두에서 관련 포트에 대한 인바운드 트래픽을 구성했습니다. 그러나 개발자는 Amazon EC2 인스턴스에서 실행 중인 서비스에 연결할 수 없습니다.솔루션 설계자로서 이 문제를 어떻게 해결할 것입니까?,네트워크 ACL은 상태 저장이므로 필요한 포트에 대한 인바운드 트래픽을 허용하면 연결이 활성화됩니다. 보안 그룹은 상태 비저장이므로 인바운드 및 아웃바운드 트래픽을 모두 허용해야 합니다.,보안 그룹에 정의된 IAM 역할이 네트워크 ACL에서 액세스 권한이 부여된 IAM 역할과 다릅니다.,네트워크 ACL과 관련된 규칙은 명령줄에서 수정하면 안 됩니다. 명령줄에서 규칙을 수정하려고 하면 규칙이 차단되고 비정상적인 동작이 발생합니다.,보안 그룹은 상태 저장이므로 필요한 포트에 대한 인바운드 트래픽을 허용하면 연결이 활성화됩니다. 네트워크 ACL은 상태 비저장이므로 인바운드 및 아웃바운드 트래픽을 모두 허용해야 합니다.,,,0,,
udemy,CLF-01,156,"An e-commerce company runs its web application on EC2 instances in an Auto Scaling group and it's configured to handle consumer orders in an SQS queue for downstream processing. The DevOps team has observed that the performance of the application goes down in case of a sudden spike in orders received.As a solutions architect, which of the following solutions would you recommend to address this use-case?",A,A,Use a target tracking scaling policy based on a custom Amazon SQS queue metric,Use a simple scaling policy based on a custom Amazon SQS queue metric,Use a step scaling policy based on a custom Amazon SQS queue metric,Use a scheduled scaling policy based on a custom Amazon SQS queue metric,,,,전자 상거래 회사는 Auto Scaling 그룹의 EC2 인스턴스에서 웹 애플리케이션을 실행하고 다운스트림 처리를 위해 SQS 대기열에서 소비자 주문을 처리하도록 구성되었습니다. DevOps 팀은 주문이 갑자기 급증하는 경우 애플리케이션의 성능이 저하되는 것을 관찰했습니다.솔루션 설계자로서 이 사용 사례를 해결하기 위해 다음 중 어떤 솔루션을 권장하시겠습니까?,사용자 지정 Amazon SQS 대기열 지표를 기반으로 대상 추적 조정 정책 사용,사용자 지정 Amazon SQS 대기열 지표를 기반으로 간단한 조정 정책 사용,사용자 지정 Amazon SQS 대기열 지표를 기반으로 단계 조정 정책 사용,사용자 지정 Amazon SQS 대기열 지표를 기반으로 예약된 조정 정책 사용,,,0,,
udemy,CLF-01,157,"A global pharmaceutical company wants to move most of the on-premises data into Amazon S3, Amazon EFS, and Amazon FSx for Windows File Server easily, quickly, and cost-effectively.As a solutions architect, which of the following solutions would you recommend as the BEST fit to automate and accelerate online data transfers to these AWS storage services?",D,D,Use AWS Snowball Edge Storage Optimized device to automate and accelerate online data transfers to the given AWS storage services,Use File Gateway to automate and accelerate online data transfers to the given AWS storage services,Use AWS Transfer Family to automate and accelerate online data transfers to the given AWS storage services,Use AWS DataSync to automate and accelerate online data transfers to the given AWS storage services,,,,"한 글로벌 제약 회사는 대부분의 온프레미스 데이터를 Amazon S3, Amazon EFS 및 Amazon FSx for Windows File Server로 쉽고 빠르고 비용 효율적으로 이동하려고 합니다.솔루션 아키텍트로서 다음 중 이러한 AWS 스토리지 서비스로의 온라인 데이터 전송을 자동화하고 가속화하는 데 가장 적합한 솔루션으로 권장하는 솔루션은 무엇입니까?",AWS Snowball Edge Storage Optimized 디바이스를 사용하여 지정된 AWS 스토리지 서비스로의 온라인 데이터 전송을 자동화 및 가속화,파일 게이트웨이를 사용하여 지정된 AWS 스토리지 서비스로의 온라인 데이터 전송을 자동화 및 가속화,AWS Transfer Family를 사용하여 지정된 AWS 스토리지 서비스로의 온라인 데이터 전송을 자동화 및 가속화,AWS DataSync를 사용하여 지정된 AWS 스토리지 서비스로의 온라인 데이터 전송을 자동화 및 가속화,,,0,,
udemy,CLF-01,158,"A global manufacturing company with facilities in the US, Europe, and Asia is designing a new distributed application to optimize its procurement workflow. The orders booked in one AWS Region should be visible to all AWS Regions in a second or less. The database should be able to facilitate failover with a short Recovery Time Objective (RTO). The uptime of the application is critical to ensure that the manufacturing processes are not impacted.As a solutions architect, which of the following will you recommend as the MOST cost-effective solution?",C,C,Provision Amazon RDS for MySQL with a cross-Region read replica,Provision Amazon RDS for PostgreSQL with a cross-Region read replica,Provision Amazon Aurora Global Database,Provision Amazon DynamoDB global tables,,,,"미국, 유럽 및 아시아에 시설을 갖춘 글로벌 제조 회사는 조달 워크플로우를 최적화하기 위해 새로운 분산 애플리케이션을 설계하고 있습니다. 한 AWS 리전에서 예약된 주문은 1초 이내에 모든 AWS 리전에서 볼 수 있어야 합니다. 데이터베이스는 짧은 RTO(복구 시간 목표)로 장애 조치를 용이하게 할 수 있어야 합니다. 응용 프로그램의 가동 시간은 제조 프로세스가 영향을 받지 않도록 하는 데 중요합니다.솔루션 아키텍트로서 다음 중 가장 비용 효율적인 솔루션으로 추천할 것은 무엇입니까?",리전 간 읽기 전용 복제본으로 Amazon RDS for MySQL 프로비저닝,리전 간 읽기 전용 복제본으로 Amazon RDS for PostgreSQL 프로비저닝,Amazon Aurora 글로벌 데이터베이스 프로비저닝,Amazon DynamoDB 전역 테이블 프로비저닝,,,0,,
udemy,CLF-01,159,"A leading bank has moved its IT infrastructure to AWS Cloud and they have been using Amazon EC2 Auto Scaling for their web servers. This has helped them deal with traffic spikes effectively. But, their MySQL relational database has now become a bottleneck and they urgently need a fully managed auto scaling solution for their relational database to address any unpredictable changes in the traffic.Can you identify the AWS service that is best suited for this use-case?",C,C,Amazon Aurora,Amazon ElastiCache,Amazon Aurora Serverless,Amazon DynamoDB,,,,한 주요 은행은 IT 인프라를 AWS 클라우드로 이전했으며 웹 서버에 Amazon EC2 Auto Scaling을 사용하고 있습니다. 이를 통해 트래픽 급증을 효과적으로 처리할 수 있었습니다. 그러나 MySQL 관계형 데이터베이스는 이제 병목 현상이 발생했으며 예측할 수 없는 트래픽 변화를 해결하기 위해 관계형 데이터베이스를 위한 완전 관리형 자동 확장 솔루션이 시급히 필요합니다.이 사용 사례에 가장 적합한 AWS 서비스를 식별할 수 있습니까?,Amazon Aurora,아마존 엘라스티캐시,아마존 오로라 서버리스,아마존 다이나모DB,,,0,,
udemy,CLF-01,160,"The DevOps team at an IT company is provisioning a two-tier application in a VPC with a public subnet and a private subnet. The team wants to use either a NAT instance or a NAT gateway in the public subnet to enable instances in the private subnet to initiate outbound IPv4 traffic to the internet but needs some technical assistance in terms of the configuration options available for the NAT instance and the NAT gateway.As a solutions architect, which of the following options would you identify as CORRECT? (Select three)",BCD,BCD,NAT gateway can be used as a bastion server,NAT instance can be used as a bastion server,Security Groups can be associated with a NAT instance,NAT instance supports port forwarding,Security Groups can be associated with a NAT gateway,NAT gateway supports port forwarding,,IT 회사의 DevOps 팀은 퍼블릭 서브넷과 프라이빗 서브넷이 있는 VPC에서 2계층 애플리케이션을 프로비저닝하고 있습니다. 팀은 퍼블릭 서브넷의 NAT 인스턴스 또는 NAT 게이트웨이를 사용하여 프라이빗 서브넷의 인스턴스가 인터넷에 대한 아웃바운드 IPv4 트래픽을 시작할 수 있도록 하려고 하지만 NAT 인스턴스 및 NAT 게이트웨이.솔루션 아키텍트로서 다음 중 올바른 것으로 식별할 수 있는 옵션은 무엇입니까? (3개 선택),NAT 게이트웨이를 배스천 서버로 사용할 수 있습니다.,NAT 인스턴스를 배스천 서버로 사용할 수 있습니다.,보안 그룹은 NAT 인스턴스와 연결될 수 있습니다.,NAT 인스턴스는 포트 전달을 지원합니다.,보안 그룹은 NAT 게이트웨이와 연결될 수 있습니다.,,0,,NAT 게이트웨이는 포트 전달을 지원합니다.
udemy,CLF-01,161,"A retail company has connected its on-premises data center to the AWS Cloud via AWS Direct Connect. The company wants to be able to resolve DNS queries for any resources in the on-premises network from the AWS VPC and also resolve any DNS queries for resources in the AWS VPC from the on-premises network.As a solutions architect, which of the following solutions can be combined to address the given use case? (Select two)",AB,AB,Create an outbound endpoint on Route 53 Resolver and then Route 53 Resolver can conditionally forward queries to resolvers on the on-premises network via this endpoint,Create an inbound endpoint on Route 53 Resolver and then DNS resolvers on the on-premises network can forward DNS queries to Route 53 Resolver via this endpoint,Create an outbound endpoint on Route 53 Resolver and then DNS resolvers on the on-premises network can forward DNS queries to Route 53 Resolver via this endpoint,Create an inbound endpoint on Route 53 Resolver and then Route 53 Resolver can conditionally forward queries to resolvers on the on-premises network via this endpoint,Create a universal endpoint on Route 53 Resolver and then Route 53 Resolver can receive and forward queries to resolvers on the on-premises network via this endpoint,,,소매 회사는 AWS Direct Connect를 통해 온프레미스 데이터 센터를 AWS 클라우드에 연결했습니다. 회사는 AWS VPC에서 온프레미스 네트워크의 모든 리소스에 대한 DNS 쿼리를 해결하고 온프레미스 네트워크에서 AWS VPC의 리소스에 대한 DNS 쿼리를 해결할 수 있기를 원합니다.솔루션 아키텍트로서 다음 중 주어진 사용 사례를 해결하기 위해 결합할 수 있는 솔루션은 무엇입니까? (2개 선택),Route 53 Resolver에서 아웃바운드 엔드포인트를 생성하면 Route 53 Resolver가 조건부로 이 엔드포인트를 통해 온프레미스 네트워크의 해석기에 쿼리를 전달할 수 있습니다.,Route 53 Resolver에서 인바운드 엔드포인트를 생성하면 온프레미스 네트워크의 DNS 해석기가 이 엔드포인트를 통해 DNS 쿼리를 Route 53 Resolver로 전달할 수 있습니다.,Route 53 Resolver에서 아웃바운드 엔드포인트를 생성하면 온프레미스 네트워크의 DNS 해석기가 이 엔드포인트를 통해 DNS 쿼리를 Route 53 Resolver로 전달할 수 있습니다.,Route 53 Resolver에서 인바운드 엔드포인트를 생성하면 Route 53 Resolver가 조건부로 이 엔드포인트를 통해 온프레미스 네트워크의 해석기에 쿼리를 전달할 수 있습니다.,Route 53 Resolver에서 범용 엔드포인트를 생성하면 Route 53 Resolver가 이 엔드포인트를 통해 온프레미스 네트워크의 해석기에 쿼리를 수신 및 전달할 수 있습니다.,,0,,
udemy,CLF-01,162,"An IT training company hosted its website on Amazon S3 a couple of years ago. Due to COVID-19 related travel restrictions, the training website has suddenly gained traction. With an almost 300% increase in the requests served per day, the company's AWS costs have sky-rocketed for just the S3 outbound data costs.As a Solutions Architect, can you suggest an alternate method to reduce costs while keeping the latency low?",C,C,"To reduce S3 cost, the data can be saved on an EBS volume connected to an EC2 instance that can host the application","Configure S3 Batch Operations to read data in bulk at one go, to reduce the number of calls made to S3 buckets",Configure Amazon CloudFront to distribute the data hosted on Amazon S3 cost-effectively,"Use Amazon EFS service, as it provides a shared, scalable, fully managed elastic NFS file system for storing AWS Cloud or on-premises data",,,,IT 교육 회사는 몇 년 전에 Amazon S3에서 웹 사이트를 호스팅했습니다. COVID-19 관련 여행 제한으로 인해 교육 웹 사이트가 갑자기 인기를 얻었습니다. 하루에 제공되는 요청이 거의 300% 증가함에 따라 회사의 AWS 비용은 S3 아웃바운드 데이터 비용만으로 급증했습니다.솔루션 아키텍트로서 대기 시간을 낮게 유지하면서 비용을 절감할 수 있는 대체 방법을 제안할 수 있습니까?,S3 비용을 줄이기 위해 애플리케이션을 호스팅할 수 있는 EC2 인스턴스에 연결된 EBS 볼륨에 데이터를 저장할 수 있습니다.,한 번에 데이터를 대량으로 읽도록 S3 배치 작업을 구성하여 S3 버킷에 대한 호출 수를 줄입니다.,Amazon S3에서 호스팅되는 데이터를 비용 효율적으로 배포하도록 Amazon CloudFront 구성,AWS 클라우드 또는 온프레미스 데이터를 저장하기 위한 공유되고 확장 가능하며 완전 관리되는 탄력적 NFS 파일 시스템을 제공하는 Amazon EFS 서비스를 사용합니다.,,,0,,
udemy,CLF-01,163,"A company wants to improve its gaming application by adding a leaderboard that uses a complex proprietary algorithm based on the participating user's performance metrics to identify the top users on a real-time basis. The technical requirements mandate high elasticity, low latency, and real-time processing to deliver customizable user data for the community of users. The leaderboard would be accessed by millions of users simultaneously.Which of the following options support the case for using ElastiCache to meet the given requirements? (Select two)",AE,AE,Use ElastiCache to improve the performance of compute-intensive workloads,Use ElastiCache to improve latency and throughput for write-heavy application workloads,Use ElastiCache to run highly complex JOIN queries,Use ElastiCache to improve the performance of Extract-Transform-Load (ETL) workloads,Use ElastiCache to improve latency and throughput for read-heavy application workloads,,,"회사는 실시간으로 상위 사용자를 식별하기 위해 참여 사용자의 성능 메트릭을 기반으로 하는 복잡한 독점 알고리즘을 사용하는 순위표를 추가하여 게임 응용 프로그램을 개선하려고 합니다. 기술 요구 사항은 사용자 커뮤니티를 위해 사용자 지정 가능한 사용자 데이터를 제공하기 위해 높은 탄력성, 짧은 대기 시간 및 실시간 처리를 요구합니다. 리더보드는 수백만 명의 사용자가 동시에 액세스할 수 있습니다.다음 중 주어진 요구 사항을 충족하기 위해 ElastiCache를 사용하는 경우를 지원하는 옵션은 무엇입니까? (2개 선택)",ElastiCache를 사용하여 컴퓨팅 집약적인 워크로드의 성능 향상,ElastiCache를 사용하여 쓰기 작업이 많은 애플리케이션 워크로드의 지연 시간 및 처리량 개선,ElastiCache를 사용하여 매우 복잡한 JOIN 쿼리 실행,ElastiCache를 사용하여 ETL(Extract-Transform-Load) 워크로드의 성능 향상,ElastiCache를 사용하여 읽기가 많은 애플리케이션 워크로드의 지연 시간 및 처리량 개선,,0,,
udemy,CLF-01,164,A financial services company wants to move the Windows file server clusters out of their datacenters. They are looking for cloud file storage offerings that provide full Windows compatibility. Can you identify the AWS storage services that provide highly reliable file storage that is accessible over the industry-standard Server Message Block (SMB) protocol compatible with Windows systems? (Select two),CE,CE,Simple Storage Service (Amazon S3),Elastic File System,Amazon FSx for Windows File Server,Elastic Block Storage,File Gateway Configuration of AWS Storage Gateway,,,금융 서비스 회사는 Windows 파일 서버 클러스터를 데이터 센터 외부로 이동하려고 합니다. 그들은 완전한 Windows 호환성을 제공하는 클라우드 파일 스토리지 제품을 찾고 있습니다. Windows 시스템과 호환되는 업계 표준 SMB(Server Message Block) 프로토콜을 통해 액세스할 수 있는 매우 안정적인 파일 스토리지를 제공하는 AWS 스토리지 서비스를 식별할 수 있습니까? (2개 선택),단순 스토리지 서비스(Amazon S3),탄력적 파일 시스템,Windows 파일 서버용 Amazon FSx,탄력적 블록 스토리지,AWS Storage Gateway의 파일 게이트웨이 구성,,0,,
udemy,CLF-01,165,An online gaming application has a large chunk of its traffic coming from users who download static assets such as historic leaderboard reports and the game tactics for various games. The current infrastructure and design are unable to cope up with the traffic and application freezes on most of the pages.Which of the following is a cost-optimal solution that does not need provisioning of infrastructure?,D,D,Configure AWS Lambda with an RDS database to provide a serverless architecture,Use AWS Lambda with ElastiCache and Amazon RDS for serving static assets at high speed and low latency,Use Amazon CloudFront with DynamoDB for greater speed and low latency access to static assets,Use Amazon CloudFront with S3 as the storage solution for the static assets,,,,온라인 게임 애플리케이션에는 기록 순위표 보고서 및 다양한 게임에 대한 게임 전술과 같은 정적 자산을 다운로드하는 사용자로부터 많은 트래픽이 발생합니다. 현재 인프라와 디자인으로는 대부분의 페이지에서 트래픽과 애플리케이션 정지를 처리할 수 없습니다.다음 중 인프라 프로비저닝이 필요하지 않은 비용 최적화 솔루션은 무엇입니까?,서버리스 아키텍처를 제공하기 위해 RDS 데이터베이스로 AWS Lambda 구성,ElastiCache 및 Amazon RDS와 함께 AWS Lambda를 사용하여 고속 및 짧은 지연 시간으로 정적 자산 제공,DynamoDB와 함께 Amazon CloudFront를 사용하여 정적 자산에 대한 액세스 속도를 높이고 대기 시간을 단축하십시오.,S3와 함께 Amazon CloudFront를 정적 자산용 스토리지 솔루션으로 사용,,,0,,
udemy,CLF-01,166,"The engineering team at a company is moving the static content from the company's logistics website hosted on EC2 instances to an S3 bucket. The team wants to use a CloudFront distribution to deliver the static content. The security group used by the EC2 instances allows the website to be accessed by a limited set of IP ranges from the company's suppliers. Post-migration to CloudFront, access to the static content should only be allowed from the aforementioned IP addresses.Which options would you combine to build a solution to meet these requirements? (Select two)",AC,AC,Configure an origin access identity (OAI) and associate it with the CloudFront distribution. Set up the permissions in the S3 bucket policy so that only the OAI can read the objects,Create an AWS WAF ACL and use an IP match condition to allow traffic only from those IPs that are allowed in the EC2 security group. Associate this new WAF ACL with the S3 bucket policy,Create an AWS WAF ACL and use an IP match condition to allow traffic only from those IPs that are allowed in the EC2 security group. Associate this new WAF ACL with the CloudFront distribution,Create a new security group that allows traffic from the same IPs as specified in the current EC2 security group. Associate this new security group with the CloudFront distribution,Create a new NACL that allows traffic from the same IPs as specified in the current EC2 security group. Associate this new NACL with the CloudFront distribution,,,회사의 엔지니어링 팀은 EC2 인스턴스에서 호스팅되는 회사의 물류 웹 사이트에서 S3 버킷으로 정적 콘텐츠를 이동하고 있습니다. 팀은 CloudFront 배포를 사용하여 정적 콘텐츠를 제공하려고 합니다. EC2 인스턴스에서 사용하는 보안 그룹을 사용하면 회사 공급업체의 제한된 IP 범위 집합에서 웹 사이트에 액세스할 수 있습니다. CloudFront로 마이그레이션한 후 정적 콘텐츠에 대한 액세스는 앞서 언급한 IP 주소에서만 허용되어야 합니다.이러한 요구 사항을 충족하는 솔루션을 구축하기 위해 어떤 옵션을 결합하시겠습니까? (2개 선택),OAI(원본 액세스 ID)를 구성하고 CloudFront 배포와 연결합니다. OAI만 객체를 읽을 수 있도록 S3 버킷 정책에서 권한을 설정합니다.,AWS WAF ACL을 생성하고 IP 일치 조건을 사용하여 EC2 보안 그룹에서 허용되는 IP의 트래픽만 허용합니다. 이 새 WAF ACL을 S3 버킷 정책과 연결,AWS WAF ACL을 생성하고 IP 일치 조건을 사용하여 EC2 보안 그룹에서 허용되는 IP의 트래픽만 허용합니다. 이 새로운 WAF ACL을 CloudFront 배포와 연결,현재 EC2 보안 그룹에 지정된 것과 동일한 IP의 트래픽을 허용하는 새 보안 그룹을 생성합니다. 이 새 보안 그룹을 CloudFront 배포와 연결,현재 EC2 보안 그룹에 지정된 것과 동일한 IP의 트래픽을 허용하는 새 NACL을 생성합니다. 이 새로운 NACL을 CloudFront 배포와 연결,,0,,
udemy,CLF-01,167,The development team at a retail company wants to optimize the cost of EC2 instances. The team wants to move certain nightly batch jobs to spot instances. The team has hired you as a solutions architect to provide the initial guidance.Which of the following would you identify as CORRECT regarding the capabilities of spot instances? (Select three),DEF,DEF,"Spot blocks are designed to be interrupted, just like a spot instance","If a spot request is persistent, then it is opened again after you stop the Spot Instance","When you cancel an active spot request, it terminates the associated instance as well",Spot blocks are designed not to be interrupted,"If a spot request is persistent, then it is opened again after your Spot Instance is interrupted","When you cancel an active spot request, it does not terminate the associated instance",,소매 회사의 개발 팀은 EC2 인스턴스의 비용을 최적화하려고 합니다. 팀은 특정 야간 배치 작업을 스팟 인스턴스로 이동하려고 합니다. 팀은 초기 지침을 제공하기 위해 귀하를 솔루션 설계자로 고용했습니다.스팟 인스턴스의 기능과 관련하여 다음 중 올바른 것으로 식별하는 것은 무엇입니까? (3개 선택),스팟 블록은 스팟 인스턴스처럼 중단되도록 설계되었습니다.,스팟 요청이 지속되면 스팟 인스턴스를 중지한 후 다시 열립니다.,활성 스팟 요청을 취소하면 연결된 인스턴스도 종료됩니다.,스팟 블록은 중단되지 않도록 설계되었습니다.,스팟 요청이 지속되면 스팟 인스턴스가 중단된 후 다시 열립니다.,,0,,활성 스팟 요청을 취소해도 연결된 인스턴스는 종료되지 않습니다.
udemy,CLF-01,168,"An IT company is using SQS queues for decoupling the various components of application architecture. As the consuming components need additional time to process SQS messages, the company wants to postpone the delivery of new messages to the queue for a few seconds.As a solutions architect, which of the following solutions would you suggest to the company?",C,C,Use FIFO queues to postpone the delivery of new messages to the queue for a few seconds,Use visibility timeout to postpone the delivery of new messages to the queue for a few seconds,Use delay queues to postpone the delivery of new messages to the queue for a few seconds,Use dead-letter queues to postpone the delivery of new messages to the queue for a few seconds,,,,IT 회사는 애플리케이션 아키텍처의 다양한 구성 요소를 분리하기 위해 SQS 대기열을 사용하고 있습니다. 소비 구성 요소가 SQS 메시지를 처리하는 데 추가 시간이 필요하므로 회사는 새 메시지를 대기열로 전달하는 것을 몇 초 동안 연기하려고 합니다.솔루션 설계자로서 다음 중 회사에 제안할 솔루션은 무엇입니까?,FIFO 대기열을 사용하여 몇 초 동안 대기열에 대한 새 메시지 배달 연기,가시성 제한 시간을 사용하여 몇 초 동안 대기열에 대한 새 메시지 배달 연기,지연 대기열을 사용하여 몇 초 동안 대기열에 대한 새 메시지 배달을 연기합니다.,배달 못한 편지 대기열을 사용하여 몇 초 동안 대기열에 대한 새 메시지 배달 연기,,,0,,
udemy,CLF-01,169,"A media company has its corporate headquarters in Los Angeles with an on-premises data center using an AWS Direct Connect connection to the AWS VPC. The branch offices in San Francisco and Miami use Site-to-Site VPN connections to connect to the AWS VPC. The company is looking for a solution to have the branch offices send and receive data with each other as well as with their corporate headquarters.As a solutions architect, which of the following AWS services would you recommend addressing this use-case?",C,C,VPC Endpoint,VPC Peering,VPN CloudHub,Software VPN,,,,미디어 회사는 AWS VPC에 대한 AWS Direct Connect 연결을 사용하는 온프레미스 데이터 센터가 있는 로스앤젤레스에 본사가 있습니다. 샌프란시스코와 마이애미의 지사는 Site-to-Site VPN 연결을 사용하여 AWS VPC에 연결합니다. 회사는 지사 간에는 물론 본사와도 데이터를 주고받을 수 있는 솔루션을 찾고 있습니다.솔루션 아키텍트로서 다음 중 이 사용 사례를 해결하기 위해 권장하는 AWS 서비스는 무엇입니까?,VPC 엔드포인트,VPC 피어링,VPN 클라우드허브,소프트웨어 VPN,,,0,,
udemy,CLF-01,170,"A company has a hybrid cloud structure for its on-premises data center and AWS Cloud infrastructure. The company wants to build a web log archival solution such that only the most frequently accessed logs are available as cached data locally while backing up all logs on Amazon S3.As a solutions architect, which of the following solutions would you recommend for this use-case?",C,C,Use AWS Volume Gateway - Stored Volume - to store the most frequently accessed logs locally for low-latency access while storing the full volume with all logs in its Amazon S3 service bucket,Use AWS Snowball Edge Storage Optimized device to store the most frequently accessed logs locally for low-latency access while storing the full backup of logs in an Amazon S3 bucket,Use AWS Volume Gateway - Cached Volume - to store the most frequently accessed logs locally for low-latency access while storing the full volume with all logs in its Amazon S3 service bucket,Use AWS direct connect to store the most frequently accessed logs locally for low-latency access while storing the full backup of logs in an Amazon S3 bucket,,,,회사는 온프레미스 데이터 센터와 AWS 클라우드 인프라를 위한 하이브리드 클라우드 구조를 가지고 있습니다. 이 회사는 Amazon S3에 모든 로그를 백업하면서 가장 자주 액세스하는 로그만 로컬에 캐시된 데이터로 사용할 수 있는 웹 로그 보관 솔루션을 구축하려고 합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 중 어떤 솔루션을 추천하시겠습니까?,AWS Volume Gateway - 저장된 볼륨을 사용하여 Amazon S3 서비스 버킷에 모든 로그와 함께 전체 볼륨을 저장하는 동시에 지연 시간이 짧은 액세스를 위해 가장 자주 액세스하는 로그를 로컬에 저장합니다.,AWS Snowball Edge Storage Optimized 디바이스를 사용하여 Amazon S3 버킷에 로그의 전체 백업을 저장하면서 지연 시간이 짧은 액세스를 위해 가장 자주 액세스하는 로그를 로컬에 저장합니다.,AWS Volume Gateway - 캐싱된 볼륨 - Amazon S3 서비스 버킷에 모든 로그가 포함된 전체 볼륨을 저장하면서 지연 시간이 짧은 액세스를 위해 가장 자주 액세스하는 로그를 로컬에 저장합니다.,Amazon S3 버킷에 로그의 전체 백업을 저장하는 동안 짧은 지연 시간 액세스를 위해 AWS Direct Connect를 사용하여 가장 자주 액세스하는 로그를 로컬에 저장,,,0,,
udemy,CLF-01,171,"A financial services company is looking to move its on-premises IT infrastructure to AWS Cloud. The company has multiple long-term server bound licenses across the application stack and the CTO wants to continue to utilize those licenses while moving to AWS.As a solutions architect, which of the following would you recommend as the MOST cost-effective solution?",B,B,Use EC2 dedicated instances,Use EC2 dedicated hosts,Use EC2 reserved instances,Use EC2 on-demand instances,,,,금융 서비스 회사는 온프레미스 IT 인프라를 AWS 클라우드로 이전하려고 합니다. 이 회사는 애플리케이션 스택 전반에 걸쳐 여러 장기 서버 바인딩 라이선스를 보유하고 있으며 CTO는 AWS로 이동하는 동안 해당 라이선스를 계속 활용하기를 원합니다.솔루션 아키텍트로서 다음 중 가장 비용 효율적인 솔루션으로 추천하는 것은 무엇입니까?,EC2 전용 인스턴스 사용,EC2 전용 호스트 사용,EC2 예약 인스턴스 사용,EC2 온디맨드 인스턴스 사용,,,0,,
udemy,CLF-01,172,"The engineering team at an e-commerce company wants to migrate from SQS Standard queues to FIFO queues with batching.As a solutions architect, which of the following steps would you have in the migration checklist? (Select three)",BDF,BDF,Make sure that the throughput for the target FIFO queue does not exceed 300 messages per second,"Make sure that the throughput for the target FIFO queue does not exceed 3,000 messages per second",Convert the existing standard queue into a FIFO queue,Delete the existing standard queue and recreate it as a FIFO queue,Make sure that the name of the FIFO queue is the same as the standard queue,Make sure that the name of the FIFO queue ends with the .fifo suffix,,전자 상거래 회사의 엔지니어링 팀은 SQS 표준 대기열에서 일괄 처리가 있는 FIFO 대기열로 마이그레이션하려고 합니다.솔루션 설계자로서 다음 중 마이그레이션 체크리스트에 포함할 단계는 무엇입니까? (3개 선택),대상 FIFO 대기열의 처리량이 초당 300개 메시지를 초과하지 않는지 확인하십시오.,"대상 FIFO 대기열의 처리량이 초당 3,000개 메시지를 초과하지 않는지 확인하십시오.",기존 표준 대기열을 FIFO 대기열로 변환,기존 표준 대기열을 삭제하고 FIFO 대기열로 다시 생성,FIFO 대기열의 이름이 표준 대기열과 동일한지 확인하십시오.,,0,,FIFO 대기열의 이름이 .fifo 접미사로 끝나는지 확인하십시오.
udemy,CLF-01,173,"The business analytics team at a company has been running ad-hoc queries on Oracle and PostgreSQL services on Amazon RDS to prepare daily reports for senior management. To facilitate the business analytics reporting, the engineering team now wants to continuously replicate this data and consolidate these databases into a petabyte-scale data warehouse by streaming data to Amazon Redshift.As a solutions architect, which of the following would you recommend as the MOST resource-efficient solution that requires the LEAST amount of development time without the need to manage the underlying infrastructure?",A,A,Use AWS Database Migration Service to replicate the data from the databases into Amazon Redshift,Use AWS Glue to replicate the data from the databases into Amazon Redshift,Use AWS EMR to replicate the data from the databases into Amazon Redshift,Use Amazon Kinesis Data Streams to replicate the data from the databases into Amazon Redshift,,,,회사의 비즈니스 분석 팀은 Amazon RDS의 Oracle 및 PostgreSQL 서비스에 대한 임시 쿼리를 실행하여 고위 경영진을 위한 일일 보고서를 준비했습니다. 비즈니스 분석 보고를 용이하게 하기 위해 이제 엔지니어링 팀은 데이터를 Amazon Redshift로 스트리밍하여 이 데이터를 지속적으로 복제하고 이러한 데이터베이스를 페타바이트 규모의 데이터 웨어하우스로 통합하려고 합니다.솔루션 아키텍트로서 다음 중 기본 인프라를 관리할 필요 없이 개발 시간이 가장 적게 필요한 가장 리소스 효율적인 솔루션으로 추천하는 것은 무엇입니까?,AWS Database Migration Service를 사용하여 데이터베이스의 데이터를 Amazon Redshift로 복제,AWS Glue를 사용하여 데이터베이스에서 Amazon Redshift로 데이터 복제,AWS EMR을 사용하여 데이터베이스에서 Amazon Redshift로 데이터 복제,Amazon Kinesis Data Streams를 사용하여 데이터베이스에서 Amazon Redshift로 데이터 복제,,,0,,
udemy,CLF-01,174,"A DevOps engineer at an IT company just upgraded an EC2 instance type from t2.nano (0.5G of RAM, 1 vCPU) to u-12tb1.metal (12.3 TB of RAM, 448 vCPUs). How would you categorize this upgrade?",C,C,This is a scale-out example of vertical scalability,This is an example of high availability,This is a scale-up example of vertical scalability,This is a scale-up example of horizontal scalability,,,,"IT 회사의 DevOps 엔지니어는 방금 EC2 인스턴스 유형을 t2.nano(0.5G RAM, 1 vCPU)에서 u-12tb1.metal(12.3TB RAM, 448 vCPU)로 업그레이드했습니다. 이 업그레이드를 어떻게 분류하시겠습니까?",이것은 수직 확장성의 스케일 아웃 예입니다.,고가용성의 예입니다.,이것은 수직적 확장성의 스케일업 예입니다.,수평적 확장성의 스케일업 예시입니다.,,,0,,
udemy,CLF-01,175,An engineering lead is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow EC2 instances to download software updates.Which of the following options represents the correct solution to set up internet access for the private subnets?,C,C,"Set up three Internet gateways, one in each private subnet in each AZ. Create a custom route table for each AZ that forwards non-local traffic to the Internet gateway in its AZ","Set up three NAT gateways, one in each private subnet in each AZ. Create a custom route table for each AZ that forwards non-local traffic to the NAT gateway in its AZ","Set up three NAT gateways, one in each public subnet in each AZ. Create a custom route table for each AZ that forwards non-local traffic to the NAT gateway in its AZ","Set up three egress-only internet gateways, one in each public subnet in each AZ. Create a custom route table for each AZ that forwards non-local traffic to the egress-only internet gateway in its AZ",,,,엔지니어링 책임자가 퍼블릭 및 프라이빗 서브넷이 있는 VPC를 설계하고 있습니다. VPC와 서브넷은 IPv4 CIDR 블록을 사용합니다. 고가용성을 위해 3개의 가용 영역(AZ) 각각에 퍼블릭 서브넷 1개와 프라이빗 서브넷 1개가 있습니다. 인터넷 게이트웨이는 퍼블릭 서브넷에 대한 인터넷 액세스를 제공하는 데 사용됩니다. 프라이빗 서브넷은 EC2 인스턴스가 소프트웨어 업데이트를 다운로드할 수 있도록 인터넷에 액세스해야 합니다.다음 옵션 중 프라이빗 서브넷에 대한 인터넷 액세스를 설정하는 올바른 솔루션은 무엇입니까?,각 AZ의 각 프라이빗 서브넷에 하나씩 세 개의 인터넷 게이트웨이를 설정합니다. 로컬이 아닌 트래픽을 해당 AZ의 인터넷 게이트웨이로 전달하는 각 AZ에 대한 사용자 지정 라우팅 테이블 생성,각 AZ의 각 프라이빗 서브넷에 하나씩 세 개의 NAT 게이트웨이를 설정합니다. 로컬이 아닌 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ에 대한 사용자 지정 라우팅 테이블 생성,각 AZ의 각 퍼블릭 서브넷에 하나씩 세 개의 NAT 게이트웨이를 설정합니다. 로컬이 아닌 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ에 대한 사용자 지정 라우팅 테이블 생성,각 AZ의 각 퍼블릭 서브넷에 하나씩 세 개의 외부 전용 인터넷 게이트웨이를 설정합니다. 로컬이 아닌 트래픽을 해당 AZ의 외부 전용 인터넷 게이트웨이로 전달하는 각 AZ에 대한 사용자 지정 라우팅 테이블 생성,,,0,,
udemy,CLF-01,176,"A data analytics company manages an application that stores user data in a DynamoDB table. The development team has observed that once in a while, the application writes corrupted data in the DynamoDB table. As soon as the issue is detected, the team needs to remove the corrupted data at the earliest.What do you recommend?",C,C,Use DynamoDB Streams to restore the table to the state just before corrupted data was written,Use DynamoDB on-demand backup to restore the table to the state just before corrupted data was written,Use DynamoDB point in time recovery to restore the table to the state just before corrupted data was written,Configure the DynamoDB table as a global table and point the application to use the table from another AWS region that has no corrupted data,,,,데이터 분석 회사는 사용자 데이터를 DynamoDB 테이블에 저장하는 애플리케이션을 관리합니다. 개발 팀은 이따금씩 애플리케이션이 손상된 데이터를 DynamoDB 테이블에 쓰는 것을 관찰했습니다. 문제가 감지되는 즉시 팀은 손상된 데이터를 최대한 빨리 제거해야 합니다.추천 메뉴가 무엇인가요?,DynamoDB Streams를 사용하여 손상된 데이터가 기록되기 직전의 상태로 테이블 복원,DynamoDB 온디맨드 백업을 사용하여 손상된 데이터가 기록되기 직전 상태로 테이블 복원,DynamoDB 특정 시점 복구를 사용하여 손상된 데이터가 기록되기 직전의 상태로 테이블 복원,DynamoDB 테이블을 전역 테이블로 구성하고 손상된 데이터가 없는 다른 AWS 리전의 테이블을 사용하도록 애플리케이션을 지정합니다.,,,0,,
udemy,CLF-01,177,"An IT company is looking to move its on-premises infrastructure to AWS Cloud. The company has a portfolio of applications with a few of them using server bound licenses that are valid for the next year. To utilize the licenses, the CTO wants to use dedicated hosts for a one year term and then migrate the given instances to default tenancy thereafter.As a solutions architect, which of the following options would you identify as CORRECT for changing the tenancy of an instance after you have launched it? (Select two)",CD,CD,You can change the tenancy of an instance from dedicated to default,You can change the tenancy of an instance from default to dedicated,You can change the tenancy of an instance from host to dedicated,You can change the tenancy of an instance from dedicated to host,You can change the tenancy of an instance from default to host,,,IT 회사는 온프레미스 인프라를 AWS 클라우드로 이전하려고 합니다. 이 회사는 내년에 유효한 서버 바운드 라이선스를 사용하는 애플리케이션 포트폴리오를 보유하고 있습니다. 라이선스를 활용하기 위해 CTO는 1년 동안 전용 호스트를 사용한 다음 해당 인스턴스를 기본 테넌시로 마이그레이션하려고 합니다.솔루션 아키텍트로서 인스턴스를 시작한 후 인스턴스의 테넌시를 변경하기 위해 다음 중 올바른 옵션은 무엇입니까? (2개 선택),인스턴스의 테넌시를 전용에서 기본값으로 변경할 수 있습니다.,인스턴스의 테넌시를 기본값에서 전용으로 변경할 수 있습니다.,인스턴스의 테넌시를 호스트에서 전용으로 변경할 수 있습니다.,인스턴스의 테넌시를 전용에서 호스트로 변경할 수 있습니다.,인스턴스의 테넌시를 기본값에서 호스트로 변경할 수 있습니다.,,0,,
udemy,CLF-01,178,"The DevOps team at an IT company has created a custom VPC (V1) and attached an Internet Gateway (I1) to the VPC. The team has also created a subnet (S1) in this custom VPC and added a route to this subnet's route table (R1) that directs internet-bound traffic to the Internet Gateway. Now the team launches an EC2 instance (E1) in the subnet S1 and assigns a public IPv4 address to this instance. Next the team also launches a NAT instance (N1) in the subnet S1.Under the given infrastructure setup, which of the following entities is doing the Network Address Translation for the EC2 instance E1?",B,B,Subnet (S1),Internet Gateway (I1),NAT instance (N1),Route Table (R1),,,,IT 회사의 DevOps 팀은 사용자 지정 VPC(V1)를 만들고 VPC에 인터넷 게이트웨이(I1)를 연결했습니다. 팀은 또한 이 사용자 지정 VPC에 서브넷(S1)을 생성하고 인터넷 바인딩 트래픽을 인터넷 게이트웨이로 보내는 이 서브넷의 경로 테이블(R1)에 경로를 추가했습니다. 이제 팀은 서브넷 S1에서 EC2 인스턴스(E1)를 시작하고 이 인스턴스에 퍼블릭 IPv4 주소를 할당합니다. 다음으로 팀은 서브넷 S1에서 NAT 인스턴스(N1)도 시작합니다.주어진 인프라 설정에서 다음 엔티티 중 EC2 인스턴스 E1에 대한 네트워크 주소 변환을 수행하는 엔티티는 무엇입니까?,서브넷(S1),인터넷 게이트웨이(I1),NAT 인스턴스(N1),경로 테이블(R1),,,0,,
udemy,CLF-01,179,"A leading online gaming company is migrating its flagship application to AWS Cloud for delivering its online games to users across the world. The company would like to use a Network Load Balancer (NLB) to handle millions of requests per second. The engineering team has provisioned multiple instances in a public subnet and specified these instance IDs as the targets for the NLB.As a solutions architect, can you help the engineering team understand the correct routing mechanism for these target instances?",B,B,Traffic is routed to instances using the primary elastic IP address specified in the primary network interface for the instance,Traffic is routed to instances using the primary private IP address specified in the primary network interface for the instance,Traffic is routed to instances using the instance ID specified in the primary network interface for the instance,Traffic is routed to instances using the primary public IP address specified in the primary network interface for the instance,,,,선도적인 온라인 게임 회사는 전 세계 사용자에게 온라인 게임을 제공하기 위해 플래그십 애플리케이션을 AWS 클라우드로 마이그레이션하고 있습니다. 회사는 NLB(Network Load Balancer)를 사용하여 초당 수백만 건의 요청을 처리하려고 합니다. 엔지니어링 팀은 퍼블릭 서브넷에서 여러 인스턴스를 프로비저닝하고 이러한 인스턴스 ID를 NLB의 대상으로 지정했습니다.솔루션 설계자로서 엔지니어링 팀이 이러한 대상 인스턴스에 대한 올바른 라우팅 메커니즘을 이해하도록 도울 수 있습니까?,트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 탄력적 IP 주소를 사용하여 인스턴스로 라우팅됩니다.,트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 프라이빗 IP 주소를 사용하여 인스턴스로 라우팅됩니다.,트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 인스턴스 ID를 사용하여 인스턴스로 라우팅됩니다.,트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 퍼블릭 IP 주소를 사용하여 인스턴스로 라우팅됩니다.,,,0,,
udemy,CLF-01,180,A company recently experienced a database outage in its on-premises data center. The company now wants to migrate to a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes.Which of the following solutions meets these requirements?,A,A,Set up an RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data,Set up an RDS MySQL DB instance and then create a read replica in another Availability Zone that synchronously replicates the data,Set up an EC2 instance with a MySQL DB engine installed that triggers an AWS Lambda function to synchronously replicate the data to an RDS MySQL DB instance,Set up an RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data,,,,한 회사가 최근 온프레미스 데이터 센터에서 데이터베이스 중단을 경험했습니다. 이제 회사는 데이터 손실을 최소화하고 모든 트랜잭션을 최소 2개의 노드에 저장하는 안정적인 AWS 데이터베이스 솔루션으로 마이그레이션하려고 합니다.다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?,데이터를 동기식으로 복제하도록 활성화된 다중 AZ 기능으로 RDS MySQL DB 인스턴스 설정,RDS MySQL DB 인스턴스를 설정한 다음 데이터를 동기식으로 복제하는 다른 가용 영역에 읽기 전용 복제본을 생성합니다.,데이터를 RDS MySQL DB 인스턴스에 동기식으로 복제하기 위해 AWS Lambda 함수를 트리거하는 MySQL DB 엔진이 설치된 EC2 인스턴스를 설정합니다.,RDS MySQL DB 인스턴스를 설정한 다음 데이터를 동기식으로 복제하는 별도의 AWS 리전에 읽기 전용 복제본을 생성합니다.,,,0,,
udemy,CLF-01,181,"A leading news aggregation company offers hundreds of digital products and services for customers ranging from law firms to banks to consumers. The company bills its clients based on per unit of clickstream data provided to the clients. As the company operates in a regulated industry, it needs to have the same ordered clickstream data available for auditing within a window of 7 days.As a solutions architect, which of the following AWS services provides the ability to run the billing process and auditing process on the given clickstream data in the same order?",C,C,Amazon SQS,AWS Kinesis Data Analytics,AWS Kinesis Data Streams,AWS Kinesis Data Firehose,,,,"선도적인 뉴스 집계 회사는 법률 회사에서 은행, 소비자에 이르기까지 다양한 고객을 위해 수백 가지의 디지털 제품과 서비스를 제공합니다. 회사는 고객에게 제공된 클릭 스트림 데이터 단위를 기준으로 고객에게 비용을 청구합니다. 회사는 규제 산업에서 운영되기 때문에 7일의 기간 내에 감사에 사용할 수 있는 동일한 주문 클릭스트림 데이터가 있어야 합니다.솔루션 아키텍트로서 다음 중 주어진 클릭 스트림 데이터에 대해 결제 프로세스와 감사 프로세스를 동일한 순서로 실행할 수 있는 기능을 제공하는 AWS 서비스는 무엇입니까?",아마존 SQS,AWS Kinesis 데이터 분석,AWS Kinesis 데이터 스트림,AWS Kinesis Data Firehose,,,0,,
udemy,CLF-01,182,"The database backend for a retail company's website is hosted on Amazon RDS for MySQL having a primary instance and three read replicas to support read scalability. The company has mandated that the read replicas should lag no more than 1 second behind the primary instance to provide the best possible user experience. The read replicas are falling further behind during periods of peak traffic spikes, resulting in a bad user experience as the searches produce inconsistent results.You have been hired as an AWS Certified Solutions Architect Associate to reduce the replication lag as much as possible with minimal changes to the application code or the effort required to manage the underlying resources.Which of the following will you recommend?",C,C,Set up database migration from RDS MySQL to DynamoDB. Provision a large number of read capacity units (RCUs) to support the required throughput and enable Auto-Scaling,Host the MySQL primary database on a memory-optimized EC2 instance. Spin up additional compute-optimized EC2 instances to host the read replicas,Set up database migration from RDS MySQL to Aurora MySQL. Swap out the MySQL read replicas with Aurora Replicas. Configure Aurora Auto Scaling,Set up an Amazon ElastiCache for Redis cluster in front of the MySQL database. Update the website to check the cache before querying the read replicas,,,,소매 회사 웹 사이트의 데이터베이스 백엔드는 읽기 확장성을 지원하기 위해 기본 인스턴스와 3개의 읽기 복제본이 있는 MySQL용 Amazon RDS에서 호스팅됩니다. 회사는 최상의 사용자 경험을 제공하기 위해 읽기 전용 복제본이 기본 인스턴스보다 1초 이상 뒤쳐지지 않아야 한다고 규정했습니다. 읽기 전용 복제본은 최대 트래픽 급증 기간 동안 더 뒤처져 검색 결과가 일관되지 않아 사용자 경험이 나빠집니다.애플리케이션 코드를 최소한으로 변경하거나 기본 리소스를 관리하는 데 필요한 노력으로 복제 지연을 최대한 줄이기 위해 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용되었습니다.다음 중 어떤 것을 추천하시겠습니까?,RDS MySQL에서 DynamoDB로의 데이터베이스 마이그레이션을 설정합니다. 필요한 처리량을 지원하고 Auto-Scaling을 활성화하기 위해 다수의 RCU(읽기 용량 단위)를 프로비저닝합니다.,메모리 최적화 EC2 인스턴스에서 MySQL 기본 데이터베이스를 호스팅합니다. 읽기 전용 복제본을 호스팅하기 위해 컴퓨팅에 최적화된 추가 EC2 인스턴스 가동,RDS MySQL에서 Aurora MySQL로의 데이터베이스 마이그레이션을 설정합니다. MySQL 읽기 전용 복제본을 Aurora 복제본으로 교체하십시오. Aurora Auto Scaling 구성,MySQL 데이터베이스 앞에 Redis 클러스터용 Amazon ElastiCache를 설정합니다. 읽기 복제본을 쿼리하기 전에 캐시를 확인하도록 웹 사이트 업데이트,,,0,,
udemy,CLF-01,183,"A company has its application servers in the public subnet that connect to the RDS instances in the private subnet. For regular maintenance, the RDS instances need patch fixes that need to be downloaded from the internet.Considering the company uses only IPv4 addressing and is looking for a fully managed service, which of the following would you suggest as an optimal solution?",D,D,Configure the Internet Gateway of the VPC to be accessible to the private subnet resources by changing the route tables,Configure a NAT instance in the public subnet of the VPC,Configure an Egress-only internet gateway for the resources in the private subnet of the VPC,Configure a NAT Gateway in the public subnet of the VPC,,,,회사는 프라이빗 서브넷의 RDS 인스턴스에 연결하는 퍼블릭 서브넷의 애플리케이션 서버를 보유하고 있습니다. 정기 유지 관리를 위해 RDS 인스턴스에는 인터넷에서 다운로드해야 하는 패치 수정이 필요합니다.회사가 IPv4 주소만 사용하고 완전 관리형 서비스를 찾고 있다는 점을 고려할 때 다음 중 최적의 솔루션으로 제안할 수 있는 것은 무엇입니까?,라우팅 테이블을 변경하여 프라이빗 서브넷 리소스에 액세스할 수 있도록 VPC의 인터넷 게이트웨이를 구성합니다.,VPC의 퍼블릭 서브넷에서 NAT 인스턴스 구성,VPC의 프라이빗 서브넷에 있는 리소스에 대한 외부 전용 인터넷 게이트웨이 구성,VPC의 퍼블릭 서브넷에서 NAT 게이트웨이 구성,,,0,,
udemy,CLF-01,184,"A big data analytics company is working on a real-time vehicle tracking solution. The data processing workflow involves both I/O intensive and throughput intensive database workloads. The development team needs to store this real-time data in a NoSQL database hosted on an EC2 instance and needs to support up to 25,000 IOPS per volume.As a solutions architect, which of the following EBS volume types would you recommend for this use-case?",D,D,Cold HDD (sc1),Throughput Optimized HDD (st1),General Purpose SSD (gp2),Provisioned IOPS SSD (io1),,,,"빅데이터 분석 회사에서 실시간 차량 추적 솔루션을 개발하고 있습니다. 데이터 처리 워크플로우에는 I/O 집약적 및 처리량 집약적 데이터베이스 워크로드가 모두 포함됩니다. 개발 팀은 이 실시간 데이터를 EC2 인스턴스에서 호스팅되는 NoSQL 데이터베이스에 저장해야 하며 볼륨당 최대 25,000 IOPS를 지원해야 합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 EBS 볼륨 유형 중 어떤 것을 추천하시겠습니까?",콜드 HDD(sc1),처리량 최적화 HDD(st1),범용 SSD(gp2),프로비저닝된 IOPS SSD(io1),,,0,,
udemy,CLF-01,185,"An e-commerce company is using an Elastic Load Balancer for its fleet of EC2 instances spread across two Availability Zones, with one instance as a target in Availability Zone A and four instances as targets in Availability Zone B. The company is doing benchmarking for server performance when cross-zone load balancing is enabled compared to the case when cross-zone load balancing is disabled.As a solutions architect, which of the following traffic distribution outcomes would you identify as correct?",B,B,"With cross-zone load balancing enabled, one instance in Availability Zone A receives 20% traffic and four instances in Availability Zone B receive 20% traffic each. With cross-zone load balancing disabled, one instance in Availability Zone A receives no traffic and four instances in Availability Zone B receive 25% traffic each","With cross-zone load balancing enabled, one instance in Availability Zone A receives 20% traffic and four instances in Availability Zone B receive 20% traffic each. With cross-zone load balancing disabled, one instance in Availability Zone A receives 50% traffic and four instances in Availability Zone B receive 12.5% traffic each","With cross-zone load balancing enabled, one instance in Availability Zone A receives 50% traffic and four instances in Availability Zone B receive 12.5% traffic each. With cross-zone load balancing disabled, one instance in Availability Zone A receives 20% traffic and four instances in Availability Zone B receive 20% traffic each","With cross-zone load balancing enabled, one instance in Availability Zone A receives no traffic and four instances in Availability Zone B receive 25% traffic each. With cross-zone load balancing disabled, one instance in Availability Zone A receives 50% traffic and four instances in Availability Zone B receive 12.5% traffic each",,,,"전자 상거래 회사는 두 개의 가용 영역에 분산된 EC2 인스턴스 플릿에 Elastic Load Balancer를 사용하고 있습니다. 하나의 인스턴스는 가용 영역 A의 대상으로, 4개의 인스턴스는 가용 영역 B의 대상으로 이 회사는 서버에 대한 벤치마킹을 수행하고 있습니다. 교차 영역 로드 밸런싱이 비활성화된 경우와 비교하여 교차 영역 로드 밸런싱이 활성화된 경우의 성능.솔루션 설계자로서 다음 트래픽 분포 결과 중 올바른 것으로 식별하는 것은 무엇입니까?",교차 영역 로드 밸런싱이 활성화된 상태에서 가용 영역 A의 한 인스턴스는 20%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 20%의 트래픽을 수신합니다. 교차 영역 로드 밸런싱이 비활성화된 상태에서 가용 영역 A의 인스턴스 1개는 트래픽을 수신하지 않고 가용 영역 B의 인스턴스 4개는 각각 25%의 트래픽을 수신합니다.,교차 영역 로드 밸런싱이 활성화된 상태에서 가용 영역 A의 한 인스턴스는 20%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 20%의 트래픽을 수신합니다. 교차 영역 로드 밸런싱이 비활성화된 상태에서 가용 영역 A의 한 인스턴스는 50%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 12.5%의 트래픽을 수신합니다.,교차 영역 로드 밸런싱이 활성화된 상태에서 가용 영역 A의 한 인스턴스는 50%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 12.5%의 트래픽을 수신합니다. 교차 영역 로드 밸런싱이 비활성화된 상태에서 가용 영역 A의 인스턴스 1개는 각각 20%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 20%의 트래픽을 수신합니다.,교차 영역 로드 밸런싱이 활성화된 상태에서 가용 영역 A의 인스턴스 1개는 트래픽을 수신하지 않고 가용 영역 B의 인스턴스 4개는 각각 25%의 트래픽을 수신합니다. 교차 영역 로드 밸런싱이 비활성화된 상태에서 가용 영역 A의 한 인스턴스는 50%의 트래픽을 수신하고 가용 영역 B의 인스턴스 4개는 각각 12.5%의 트래픽을 수신합니다.,,,0,,
udemy,CLF-01,186,"A video conferencing application is hosted on a fleet of EC2 instances which are part of an Auto Scaling group (ASG). The ASG uses a Launch Configuration (LC1) with ""dedicated"" instance placement tenancy but the VPC (V1) used by the Launch Configuration LC1 has the instance tenancy set to default. Later the DevOps team creates a new Launch Configuration (LC2) with ""default"" instance placement tenancy but the VPC (V2) used by the Launch Configuration LC2 has the instance tenancy set to dedicated.Which of the following is correct regarding the instances launched via Launch Configuration LC1 and Launch Configuration LC2?",C,C,The instances launched by both Launch Configuration LC1 and Launch Configuration LC2 will have default instance tenancy,The instances launched by Launch Configuration LC1 will have dedicated instance tenancy while the instances launched by the Launch Configuration LC2 will have default instance tenancy,The instances launched by both Launch Configuration LC1 and Launch Configuration LC2 will have dedicated instance tenancy,The instances launched by Launch Configuration LC1 will have default instance tenancy while the instances launched by the Launch Configuration LC2 will have dedicated instance tenancy,,,,"화상 회의 애플리케이션은 ASG(Auto Scaling 그룹)의 일부인 EC2 인스턴스 플릿에서 호스팅됩니다. ASG는 ""전용"" 인스턴스 배치 테넌시가 있는 시작 구성(LC1)을 사용하지만 시작 구성 LC1에서 사용하는 VPC(V1)에는 인스턴스 테넌시가 기본값으로 설정되어 있습니다. 나중에 DevOps 팀은 ""기본"" 인스턴스 배치 테넌시를 사용하여 새 시작 구성(LC2)을 생성하지만 시작 구성 LC2에서 사용하는 VPC(V2)의 인스턴스 테넌시는 전용으로 설정됩니다.Launch Configuration LC1 및 Launch Configuration LC2를 통해 시작된 인스턴스와 관련하여 다음 중 올바른 것은 무엇입니까?",Launch Configuration LC1과 Launch Configuration LC2 모두에서 시작된 인스턴스에는 기본 인스턴스 테넌시가 있습니다.,Launch Configuration LC1에 의해 시작된 인스턴스에는 전용 인스턴스 테넌시가 있고 Launch Configuration LC2에 의해 시작된 인스턴스에는 기본 인스턴스 테넌시가 있습니다.,Launch Configuration LC1과 Launch Configuration LC2 모두에 의해 시작된 인스턴스에는 전용 인스턴스 테넌시가 있습니다.,Launch Configuration LC1에 의해 시작된 인스턴스에는 기본 인스턴스 테넌시가 있고 Launch Configuration LC2에 의해 시작된 인스턴스에는 전용 인스턴스 테넌시가 있습니다.,,,0,,
udemy,CLF-01,187,"The application maintenance team at a company has noticed that the production application is very slow when the business reports are run on the RDS database. These reports fetch a large amount of data and have complex queries with multiple joins, spanning across multiple business-critical core tables. CPU, memory, and storage metrics are around 50% of the total capacity.Can you recommend an improved and cost-effective way of generating the business reports while keeping the production application unaffected?",C,C,Increase the size of RDS instance,Migrate from General Purpose SSD to magnetic storage to enhance IOPS,Create a read replica and connect the report generation tool/application to it,"Configure the RDS instance to be Multi-AZ DB instance, and connect the report generation tool to the DB instance in a different AZ",,,,"회사의 애플리케이션 유지 관리 팀은 비즈니스 보고서가 RDS 데이터베이스에서 실행될 때 프로덕션 애플리케이션이 매우 느리다는 것을 알게 되었습니다. 이러한 보고서는 많은 양의 데이터를 가져오고 비즈니스에 중요한 여러 코어 테이블에 걸쳐 여러 조인이 포함된 복잡한 쿼리를 포함합니다. CPU, 메모리 및 스토리지 메트릭은 총 용량의 약 50%입니다.프로덕션 애플리케이션에 영향을 주지 않으면서 비즈니스 보고서를 생성하는 개선되고 비용 효율적인 방법을 추천해 주실 수 있습니까?",RDS 인스턴스 크기 늘리기,범용 SSD에서 마그네틱 스토리지로 마이그레이션하여 IOPS 향상,읽기 복제본 생성 및 보고서 생성 도구/애플리케이션 연결,RDS 인스턴스를 다중 AZ DB 인스턴스로 구성하고 보고서 생성 도구를 다른 AZ의 DB 인스턴스에 연결합니다.,,,0,,
udemy,CLF-01,188,"An IT consultant is helping a small business revamp their technology infrastructure on the AWS Cloud. The business has two AWS accounts and all resources are provisioned in the us-west-2 region. The IT consultant is trying to launch an EC2 instance in each of the two AWS accounts such that the instances are in the same Availability Zone of the us-west-2 region. Even after selecting the same default subnet (us-west-2a) while launching the instances in each of the AWS accounts, the IT consultant notices that the Availability Zones are still different.As a solutions architect, which of the following would you suggest resolving this issue?",B,B,Use the default VPC to uniquely identify the Availability Zones across the two AWS Accounts,Use AZ ID to uniquely identify the Availability Zones across the two AWS Accounts,Use the default subnet to uniquely identify the Availability Zones across the two AWS Accounts,Reach out to AWS Support for creating the EC2 instances in the same Availability Zone across the two AWS accounts,,,,한 IT 컨설턴트가 중소기업이 AWS 클라우드에서 기술 인프라를 개선하도록 돕고 있습니다. 비즈니스에는 두 개의 AWS 계정이 있으며 모든 리소스는 us-west-2 리전에 프로비저닝됩니다. IT 컨설턴트는 인스턴스가 us-west-2 지역의 동일한 가용 영역에 있도록 두 AWS 계정 각각에서 EC2 인스턴스를 시작하려고 합니다. 각 AWS 계정에서 인스턴스를 시작하는 동안 동일한 기본 서브넷(us-west-2a)을 선택한 후에도 IT 컨설턴트는 가용 영역이 여전히 다르다는 것을 알게 됩니다.다음 중 솔루션 아키텍트로서 이 문제를 해결하기 위해 제안하는 것은 무엇입니까?,기본 VPC를 사용하여 두 AWS 계정에서 가용 영역을 고유하게 식별,AZ ID를 사용하여 두 AWS 계정에서 가용 영역을 고유하게 식별,기본 서브넷을 사용하여 두 AWS 계정에서 가용 영역을 고유하게 식별,두 AWS 계정의 동일한 가용 영역에서 EC2 인스턴스를 생성하려면 AWS Support에 문의하십시오.,,,0,,
udemy,CLF-01,189,"Your application is hosted by a provider on yourapp.provider.com. You would like to have your users access your application using www.your-domain.com, which you own and manage under Route 53.What Route 53 record should you create?",A,A,Create a CNAME record,Create an Alias Record,Create an A record,Create a PTR record,,,,애플리케이션은 yourapp.provider.com의 공급자가 호스팅합니다. 사용자가 Route 53에서 소유하고 관리하는 www.your-domain.com을 사용하여 애플리케이션에 액세스하도록 하고 싶습니다.어떤 Route 53 레코드를 생성해야 합니까?,CNAME 레코드 생성,별칭 레코드 만들기,A 레코드 만들기,PTR 레코드 만들기,,,0,,
udemy,CLF-01,190,"A media streaming company is looking to migrate its on-premises infrastructure into the AWS Cloud. The engineering team is looking for a fully managed NoSQL persistent data store with in-memory caching to maintain low latency that is critical for real-time scenarios such as video streaming and interactive content. The team expects the number of concurrent users to touch up to a million so the database should be able to scale elastically.As a solutions architect, which of the following AWS services would you recommend for this use-case?",B,B,ElastiCache,DynamoDB,RDS,DocumentDB,,,,미디어 스트리밍 회사는 온프레미스 인프라를 AWS 클라우드로 마이그레이션하려고 합니다. 엔지니어링 팀은 비디오 스트리밍 및 대화형 콘텐츠와 같은 실시간 시나리오에 중요한 낮은 대기 시간을 유지하기 위해 메모리 내 캐싱이 포함된 완전 관리형 NoSQL 영구 데이터 저장소를 찾고 있습니다. 팀은 데이터베이스가 탄력적으로 확장될 수 있도록 동시 사용자 수가 최대 100만 명에 달할 것으로 예상합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 AWS 서비스 중 어떤 것을 추천하시겠습니까?,ElastiCache,DynamoDB,RDS,문서DB,,,0,,
udemy,CLF-01,191,"An IT company hosts windows based applications on its on-premises data center. The company is looking at moving the business to the AWS Cloud. The cloud solution should offer shared storage space that multiple applications can access without a need for replication. Also, the solution should integrate with the company's self-managed Active Directory domain.Which of the following solutions addresses these requirements with the minimal integration effort?",A,A,Use Amazon FSx for Windows File Server as a shared storage solution,Use Amazon Elastic File System (Amazon EFS) as a shared storage solution,Use File Gateway of AWS Storage Gateway to create a hybrid storage solution,Use Amazon FSx for Lustre as a shared storage solution with millisecond latencies,,,,IT 회사는 온프레미스 데이터 센터에서 Windows 기반 애플리케이션을 호스팅합니다. 회사는 비즈니스를 AWS 클라우드로 이전하는 것을 고려하고 있습니다. 클라우드 솔루션은 여러 애플리케이션이 복제할 필요 없이 액세스할 수 있는 공유 스토리지 공간을 제공해야 합니다. 또한 솔루션은 회사의 자체 관리 Active Directory 도메인과 통합되어야 합니다.다음 중 최소한의 통합 노력으로 이러한 요구 사항을 해결하는 솔루션은 무엇입니까?,Amazon FSx for Windows File Server를 공유 스토리지 솔루션으로 사용,Amazon Elastic File System(Amazon EFS)을 공유 스토리지 솔루션으로 사용,AWS Storage Gateway의 파일 게이트웨이를 사용하여 하이브리드 스토리지 솔루션 생성,지연 시간이 밀리초인 공유 스토리지 솔루션으로 Amazon FSx for Lustre 사용,,,0,,
udemy,CLF-01,192,A company has hired you as an AWS Certified Solutions Architect to help with redesigning a real-time data processor. The company wants to build custom applications that process and analyze the streaming data for its specialized needs.Which solution will you recommend to address this use-case?,C,C,Use SQS to process the data streams as well as decouple the producers and consumers for the real-time data processor,Use Kinesis Data Firehose to process the data streams as well as decouple the producers and consumers for the real-time data processor,Use Kinesis Data Streams to process the data streams as well as decouple the producers and consumers for the real-time data processor,Use SNS to process the data streams as well as decouple the producers and consumers for the real-time data processor,,,,한 회사에서 실시간 데이터 프로세서 재설계를 돕기 위해 귀하를 AWS 공인 솔루션스 아키텍트로 고용했습니다. 이 회사는 특수한 요구 사항에 맞게 스트리밍 데이터를 처리하고 분석하는 사용자 지정 애플리케이션을 구축하려고 합니다.이 사용 사례를 해결하기 위해 어떤 솔루션을 권장하시겠습니까?,SQS를 사용하여 데이터 스트림을 처리하고 실시간 데이터 프로세서를 위해 생산자와 소비자를 분리합니다.,Kinesis Data Firehose를 사용하여 데이터 스트림을 처리하고 실시간 데이터 프로세서를 위해 생산자와 소비자를 분리합니다.,Kinesis Data Streams를 사용하여 데이터 스트림을 처리하고 실시간 데이터 프로세서를 위해 생산자와 소비자를 분리합니다.,SNS를 사용하여 데이터 스트림을 처리하고 실시간 데이터 프로세서를 위해 생산자와 소비자를 분리합니다.,,,0,,
udemy,CLF-01,193,"A health care application processes the real-time health data of the patients into an analytics workflow. With a sharp increase in the number of users, the system has become slow and sometimes even unresponsive as it does not have a retry mechanism. The startup is looking at a scalable solution that has minimal implementation overhead.Which of the following would you recommend as a scalable alternative to the current solution?",A,A,"Use Amazon Kinesis Data Streams to ingest the data, process it using AWS Lambda or run analytics using Kinesis Data Analytics",Use Amazon SNS for data ingestion and configure Lambda to trigger logic for downstream processing,Use Amazon API Gateway with the existing REST-based interface to create a high performing architecture,Use Amazon SQS for data ingestion and configure Lambda to trigger logic for downstream processing,,,,건강 관리 애플리케이션은 환자의 실시간 건강 데이터를 분석 워크플로로 처리합니다. 사용자 수가 급격히 증가함에 따라 재시도 메커니즘이 없기 때문에 시스템이 느려지고 때로는 응답하지 않는 경우도 있습니다. 스타트업은 최소한의 구현 오버헤드가 있는 확장 가능한 솔루션을 찾고 있습니다.다음 중 현재 솔루션에 대한 확장 가능한 대안으로 권장하는 것은 무엇입니까?,Amazon Kinesis Data Streams를 사용하여 데이터를 수집하거나 AWS Lambda를 사용하여 처리하거나 Kinesis Data Analytics를 사용하여 분석을 실행합니다.,데이터 수집에 Amazon SNS를 사용하고 다운스트림 처리를 위한 로직을 트리거하도록 Lambda 구성,기존 REST 기반 인터페이스와 함께 Amazon API Gateway를 사용하여 고성능 아키텍처 생성,데이터 수집에 Amazon SQS를 사용하고 다운스트림 처리를 위한 로직을 트리거하도록 Lambda 구성,,,0,,
udemy,CLF-01,194,"A biotechnology company has multiple High Performance Computing (HPC) workflows that quickly and accurately process and analyze genomes for hereditary diseases. The company is looking to migrate these workflows from their on-premises infrastructure to AWS Cloud.As a solutions architect, which of the following networking components would you recommend on the EC2 instances running these HPC workflows?",B,B,Elastic Network Adapter,Elastic Fabric Adapter,Elastic IP Address,Elastic Network Interface,,,,생명 공학 회사는 유전병에 대한 게놈을 빠르고 정확하게 처리하고 분석하는 여러 HPC(고성능 컴퓨팅) 워크플로를 보유하고 있습니다. 이 회사는 이러한 워크플로를 온프레미스 인프라에서 AWS 클라우드로 마이그레이션하려고 합니다.솔루션 설계자로서 이러한 HPC 워크플로를 실행하는 EC2 인스턴스에서 다음 네트워킹 구성 요소 중 어떤 것을 권장하시겠습니까?,탄력적 네트워크 어댑터,탄성 패브릭 어댑터,탄력적 IP 주소,탄력적 네트워크 인터페이스,,,0,,
udemy,CLF-01,195,"The engineering team at a social media company wants to use Amazon CloudWatch alarms to automatically recover EC2 instances if they become impaired. The team has hired you as a solutions architect to provide subject matter expertise.As a solutions architect, which of the following statements would you identify as CORRECT regarding this automatic recovery process? (Select two)",AE,AE,"A recovered instance is identical to the original instance, including the instance ID, private IP addresses, Elastic IP addresses, and all instance metadata","If your instance has a public IPv4 address, it does not retain the public IPv4 address after recovery","During instance recovery, the instance is migrated during an instance reboot, and any data that is in-memory is retained",Terminated EC2 instances can be recovered if they are configured at the launch of instance,"If your instance has a public IPv4 address, it retains the public IPv4 address after recovery",,,소셜 미디어 회사의 엔지니어링 팀은 Amazon CloudWatch 경보를 사용하여 EC2 인스턴스가 손상된 경우 자동으로 복구하려고 합니다. 팀은 주제 관련 전문 지식을 제공하기 위해 귀하를 솔루션 설계자로 고용했습니다.솔루션 아키텍트로서 이 자동 복구 프로세스와 관련하여 다음 중 올바른 설명은 무엇입니까? (2개 선택),"복구된 인스턴스는 인스턴스 ID, 프라이빗 IP 주소, 탄력적 IP 주소 및 모든 인스턴스 메타데이터를 포함하여 원본 인스턴스와 동일합니다.",인스턴스에 퍼블릭 IPv4 주소가 있는 경우 복구 후 퍼블릭 IPv4 주소가 유지되지 않습니다.,인스턴스 복구 중에 인스턴스 재부팅 중에 인스턴스가 마이그레이션되고 메모리에 있는 모든 데이터가 유지됩니다.,종료된 EC2 인스턴스는 인스턴스 시작 시 구성된 경우 복구할 수 있습니다.,인스턴스에 퍼블릭 IPv4 주소가 있는 경우 복구 후에도 퍼블릭 IPv4 주소를 유지합니다.,,0,,
udemy,CLF-01,196,"A startup's cloud infrastructure consists of a few Amazon EC2 instances, Amazon RDS instances and Amazon S3 storage. A year into their business operations, the startup is incurring costs that seem too high for their business requirements.Which of the following options represents a valid cost-optimization solution?",B,B,Use AWS Compute Optimizer recommendations to help you choose the optimal Amazon EC2 purchasing options and help reserve your instance capacities at reduced costs,Use AWS Cost Explorer Resource Optimization to get a report of EC2 instances that are either idle or have low utilization and use AWS Compute Optimizer to look at instance type recommendations,Use Amazon S3 Storage class analysis to get recommendations for transitions of objects to S3 Glacier storage classes to reduce storage costs. You can also automate moving these objects into lower-cost storage tier using Lifecycle Policies,Use AWS Trusted Advisor checks on Amazon EC2 Reserved Instances to automatically renew Reserved Instances. Trusted advisor also suggests Amazon RDS idle DB instances,,,,"스타트업의 클라우드 인프라는 몇 개의 Amazon EC2 인스턴스, Amazon RDS 인스턴스 및 Amazon S3 스토리지로 구성됩니다. 사업 운영을 시작한지 ​​1년이 된 신생 기업은 사업 요구 사항에 비해 너무 높은 비용을 발생시키고 있습니다.다음 중 유효한 비용 최적화 솔루션을 나타내는 옵션은 무엇입니까?",AWS Compute Optimizer 권장 사항을 사용하여 최적의 Amazon EC2 구매 옵션을 선택하고 저렴한 비용으로 인스턴스 용량을 예약할 수 있습니다.,AWS Cost Explorer Resource Optimization을 사용하여 유휴 상태이거나 사용률이 낮은 EC2 인스턴스에 대한 보고서를 받고 AWS Compute Optimizer를 사용하여 인스턴스 유형 권장 사항 확인,Amazon S3 스토리지 클래스 분석을 사용하여 객체를 S3 Glacier 스토리지 클래스로 전환하여 스토리지 비용을 줄이기 위한 권장 사항을 얻습니다. 수명 주기 정책을 사용하여 이러한 개체를 더 저렴한 스토리지 계층으로 자동으로 이동할 수도 있습니다.,Amazon EC2 예약 인스턴스에서 AWS Trusted Advisor 검사를 사용하여 예약 인스턴스를 자동으로 갱신합니다. Trusted Advisor는 Amazon RDS 유휴 DB 인스턴스도 제안합니다.,,,0,,
udemy,CLF-01,197,"An e-commerce company tracks user clicks on its flagship website and performs analytics to provide near-real-time product recommendations. An EC2 instance receives data from the website and sends the data to an Aurora DB instance. Another EC2 instance continuously checks the changes in the database and executes SQL queries to provide recommendations. Now, the company wants a redesign to decouple and scale the infrastructure. The solution must ensure that data can be analyzed in real-time without any data loss even when the company sees huge traffic spikes.What would you recommend as an AWS Certified Solutions Architect Associate?",A,A,"Leverage Amazon Kinesis Data Streams to capture the data from the website and feed it into Amazon Kinesis Data Analytics which can query the data in real time. Lastly, the analyzed feed is output into Kinesis Data Firehose to persist the data on Amazon S3","Leverage Amazon Kinesis Data Streams to capture the data from the website and feed it into Kinesis Data Firehose to persist the data on Amazon S3. Lastly, use Amazon Athena to analyze the data in real time","Leverage Amazon Kinesis Data Streams to capture the data from the website and feed it into Amazon QuickSight which can query the data in real time. Lastly, the analyzed feed is output into Kinesis Data Firehose to persist the data on Amazon S3",Leverage Amazon SQS to capture the data from the website. Configure a fleet of EC2 instances under an Auto scaling group to process messages from the SQS queue and trigger the scaling policy based on the number of pending messages in the queue. Perform real-time analytics using a third-party library on the EC2 instances,,,,전자상거래 회사는 주력 웹사이트에서 사용자 클릭을 추적하고 분석을 수행하여 거의 실시간으로 제품 추천을 제공합니다. EC2 인스턴스는 웹 사이트에서 데이터를 수신하고 데이터를 Aurora DB 인스턴스로 보냅니다. 또 다른 EC2 인스턴스는 데이터베이스의 변경 사항을 지속적으로 확인하고 SQL 쿼리를 실행하여 권장 사항을 제공합니다. 이제 회사는 인프라를 분리하고 확장하기 위한 재설계를 원합니다. 이 솔루션은 회사에서 엄청난 트래픽 급증이 발생하는 경우에도 데이터 손실 없이 실시간으로 데이터를 분석할 수 있도록 보장해야 합니다.AWS 공인 솔루션스 아키텍트 어소시에이트로 무엇을 추천하시겠습니까?,Amazon Kinesis Data Streams를 활용하여 웹 사이트에서 데이터를 캡처하고 데이터를 실시간으로 쿼리할 수 있는 Amazon Kinesis Data Analytics에 제공합니다. 마지막으로 분석된 피드는 Amazon S3에 데이터를 유지하기 위해 Kinesis Data Firehose로 출력됩니다.,Amazon Kinesis Data Streams를 활용하여 웹 사이트에서 데이터를 캡처하고 Kinesis Data Firehose에 공급하여 Amazon S3에서 데이터를 유지합니다. 마지막으로 Amazon Athena를 사용하여 실시간으로 데이터를 분석합니다.,Amazon Kinesis Data Streams를 활용하여 웹 사이트에서 데이터를 캡처하고 실시간으로 데이터를 쿼리할 수 있는 Amazon QuickSight에 제공합니다. 마지막으로 분석된 피드는 Amazon S3에 데이터를 유지하기 위해 Kinesis Data Firehose로 출력됩니다.,Amazon SQS를 활용하여 웹 사이트에서 데이터를 캡처합니다. Auto Scaling 그룹에서 EC2 인스턴스 플릿을 구성하여 SQS 대기열의 메시지를 처리하고 대기열의 대기 중인 메시지 수에 따라 조정 정책을 트리거합니다. EC2 인스턴스에서 타사 라이브러리를 사용하여 실시간 분석 수행,,,0,,
udemy,CLF-01,198,"The engineering team at an e-commerce company has been tasked with migrating to a serverless architecture. The team wants to focus on the key points of consideration when using Lambda as a backbone for this architecture.As a Solutions Architect, which of the following options would you identify as correct for the given requirement? (Select three)",AEF,AEF,"If you intend to reuse code in more than one Lambda function, you should consider creating a Lambda Layer for the reusable code","The bigger your deployment package, the slower your Lambda function will cold-start. Hence, AWS suggests packaging dependencies as a separate package from the actual Lambda package","Lambda allocates compute power in proportion to the memory you allocate to your function. AWS, thus recommends to over provision your function time out settings for the proper performance of Lambda functions",Serverless architecture and containers complement each other but you cannot package and deploy Lambda functions as container images,"By default, Lambda functions always operate from an AWS-owned VPC and hence have access to any public internet address or public AWS APIs. Once a Lambda function is VPC-enabled, it will need a route through a NAT gateway in a public subnet to access public resources","Since Lambda functions can scale extremely quickly, it's a good idea to deploy a CloudWatch Alarm that notifies your team when function metrics such as ConcurrentExecutions or Invocations exceeds the expected threshold",,전자 상거래 회사의 엔지니어링 팀은 서버리스 아키텍처로 마이그레이션하는 임무를 받았습니다. 팀은 Lambda를 이 아키텍처의 백본으로 사용할 때 고려해야 할 핵심 사항에 집중하고자 합니다.솔루션 아키텍트로서 다음 중 주어진 요구 사항에 맞는 것으로 식별하는 옵션은 무엇입니까? (3개 선택),둘 이상의 Lambda 함수에서 코드를 재사용하려는 경우 재사용 가능한 코드에 대한 Lambda 계층 생성을 고려해야 합니다.,배포 패키지가 클수록 Lambda 함수의 콜드 스타트 ​​속도가 느려집니다. 따라서 AWS는 패키징 종속성을 실제 Lambda 패키지와 별도의 패키지로 제안합니다.,Lambda는 함수에 할당한 메모리에 비례하여 컴퓨팅 성능을 할당합니다. 따라서 AWS는 Lambda 함수의 적절한 성능을 위해 함수 제한 시간 설정을 과도하게 프로비저닝할 것을 권장합니다.,서버리스 아키텍처와 컨테이너는 서로를 보완하지만 Lambda 함수를 컨테이너 이미지로 패키징하고 배포할 수 없습니다.,기본적으로 Lambda 함수는 항상 AWS 소유 VPC에서 작동하므로 모든 퍼블릭 인터넷 주소 또는 퍼블릭 AWS API에 액세스할 수 있습니다. Lambda 함수가 VPC를 지원하면 퍼블릭 리소스에 액세스하려면 퍼블릭 서브넷의 NAT 게이트웨이를 통한 경로가 필요합니다.,,0,,Lambda 함수는 매우 빠르게 확장할 수 있으므로 ConcurrentExecutions 또는 Invocations와 같은 함수 지표가 예상 임계값을 초과할 때 팀에 알리는 CloudWatch 경보를 배포하는 것이 좋습니다.
udemy,CLF-01,199,A company uses Application Load Balancers (ALBs) in multiple AWS Regions. The ALBs receive inconsistent traffic that varies throughout the year. The engineering team at the company needs to allow the IP addresses of the ALBs in the on-premises firewall to enable connectivity.Which of the following represents the MOST scalable solution with minimal configuration changes?,D,D,Migrate all ALBs in different Regions to the Network Load Balancer (NLBs). Configure the on-premises firewall's rule to allow the Elastic IP addresses of all the NLBs,Set up a Network Load Balancer (NLB) in one Region. Register the private IP addresses of the ALBs in different Regions with the NLB. Configure the on-premises firewall's rule to allow the Elastic IP address attached to the NLB,Develop an AWS Lambda script to get the IP addresses of the ALBs in different Regions. Configure the on-premises firewall's rule to allow the IP addresses of the ALBs,Set up AWS Global Accelerator. Register the ALBs in different Regions to the Global Accelerator. Configure the on-premises firewall's rule to allow static IP addresses associated with the Global Accelerator,,,,회사는 여러 AWS 리전에서 Application Load Balancer(ALB)를 사용합니다. ALB는 일년 내내 달라지는 일관되지 않은 트래픽을 수신합니다. 회사의 엔지니어링 팀은 온프레미스 방화벽에서 ALB의 IP 주소를 허용하여 연결을 활성화해야 합니다.다음 중 최소한의 구성 변경으로 가장 확장 가능한 솔루션을 나타내는 것은 무엇입니까?,서로 다른 지역의 모든 ALB를 NLB(Network Load Balancer)로 마이그레이션합니다. 모든 NLB의 탄력적 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 구성합니다.,한 리전에서 NLB(Network Load Balancer)를 설정합니다. 서로 다른 지역에 있는 ALB의 사설 IP 주소를 NLB에 등록합니다. NLB에 연결된 탄력적 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 구성합니다.,서로 다른 지역에 있는 ALB의 IP 주소를 가져오는 AWS Lambda 스크립트를 개발합니다. ALB의 IP 주소를 허용하도록 온프레미스 방화벽의 규칙 구성,AWS Global Accelerator를 설정합니다. 서로 다른 지역의 ALB를 Global Accelerator에 등록합니다. Global Accelerator와 연결된 고정 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 구성합니다.,,,0,,
udemy,CLF-01,200,A development team has configured an Elastic Load Balancer for host-based routing. The idea is to support multiple subdomains and different top-level domains.The rule *.example.com matches which of the following?,A,A,test.example.com,example.com,EXAMPLE.COM,example.test.com,,,,개발 팀이 호스트 기반 라우팅을 위해 Elastic Load Balancer를 구성했습니다. 아이디어는 여러 하위 도메인과 다른 최상위 도메인을 지원하는 것입니다.*.example.com 규칙은 다음 중 어느 것과 일치합니까?,test.example.com,example.com,EXAMPLE.COM,example.test.com,,,0,,
udemy,CLF-01,201,"A company has built a serverless application using API Gateway and AWS Lambda. The backend is leveraging an RDS Aurora MySQL database. The web application was initially launched in the Americas and the company would now like to expand it to Europe, where a read-only version will be available to improve latency. You plan on deploying the API Gateway and AWS Lambda using CloudFormation, but would like to have a read-only copy of your data in Europe as well.As a Solutions Architect, what do you recommend?",A,A,Use Aurora Read Replicas,Use Aurora Multi-AZ,Create a Lambda function to periodically back up and restore the Aurora database in another region,Use a DynamoDB Streams,,,,회사에서 API 게이트웨이와 AWS Lambda를 사용하여 서버리스 애플리케이션을 구축했습니다. 백엔드는 RDS Aurora MySQL 데이터베이스를 활용하고 있습니다. 이 웹 애플리케이션은 처음에 미주에서 출시되었으며 이제 회사는 대기 시간을 개선하기 위해 읽기 전용 버전을 사용할 수 있는 유럽으로 확장하려고 합니다. CloudFormation을 사용하여 API 게이트웨이 및 AWS Lambda를 배포할 계획이지만 유럽에서도 데이터의 읽기 전용 복사본을 갖고 싶습니다.솔루션 아키텍트로서 추천하는 것은 무엇입니까?,Aurora 읽기 복제본 사용,Aurora 다중 AZ 사용,다른 리전에서 Aurora 데이터베이스를 주기적으로 백업 및 복원하는 Lambda 함수 생성,DynamoDB 스트림 사용,,,0,,
udemy,CLF-01,202,"A Big Data processing company has created a distributed data processing framework that performs best if the network performance between the processing machines is high. The application has to be deployed on AWS, and the company is only looking at performance as the key measure.As a Solutions Architect, which deployment do you recommend?",C,C,Use a Spread placement group,Use Spot Instances,Use a Cluster placement group,Optimize the EC2 kernel using EC2 User Data,,,,빅 데이터 처리 회사는 처리 시스템 간의 네트워크 성능이 높을 때 최상의 성능을 발휘하는 분산 데이터 처리 프레임워크를 만들었습니다. 애플리케이션은 AWS에 배포되어야 하며 회사는 성능만을 주요 척도로 보고 있습니다.솔루션 아키텍트로서 어떤 배포를 권장합니까?,스프레드 배치 그룹 사용,스팟 인스턴스 사용,클러스터 배치 그룹 사용,EC2 사용자 데이터를 사용하여 EC2 커널 최적화,,,0,,
udemy,CLF-01,203,"An e-commerce company wants to migrate its on-premises application to AWS. The application consists of application servers and a Microsoft SQL Server database. The solution should result in the maximum possible availability for the database layer while minimizing operational and management overhead.As a solutions architect, which of the following would you recommend to meet the given requirements?",C,C,Migrate the data to EC2 instance hosted SQL Server database. Deploy the EC2 instances in a Multi-AZ configuration,Migrate the data to Amazon RDS for SQL Server database in a cross-region Multi-AZ deployment,Migrate the data to Amazon RDS for SQL Server database in a Multi-AZ deployment,Migrate the data to Amazon RDS for SQL Server database in a cross-region read-replica configuration,,,,전자 상거래 회사는 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 애플리케이션은 애플리케이션 서버와 Microsoft SQL Server 데이터베이스로 구성됩니다. 솔루션은 운영 및 관리 오버헤드를 최소화하면서 데이터베이스 계층에 대한 최대 가용성을 제공해야 합니다.다음 중 솔루션 설계자로서 주어진 요구 사항을 충족하기 위해 권장하는 것은 무엇입니까?,데이터를 EC2 인스턴스 호스팅 SQL Server 데이터베이스로 마이그레이션합니다. 다중 AZ 구성에서 EC2 인스턴스 배포,지역 간 다중 AZ 배포에서 SQL Server 데이터베이스용 Amazon RDS로 데이터 마이그레이션,다중 AZ 배포에서 SQL Server 데이터베이스용 Amazon RDS로 데이터 마이그레이션,지역 간 읽기 복제본 구성에서 SQL Server 데이터베이스용 Amazon RDS로 데이터 마이그레이션,,,0,,
udemy,CLF-01,204,"The development team at a social media company wants to handle some complicated queries such as ""What are the number of likes on the videos that have been posted by friends of a user A?"".As a solutions architect, which of the following AWS database services would you suggest as the BEST fit to handle such use cases?",A,A,Amazon Neptune,Amazon ElasticSearch,Amazon Aurora,Amazon Redshift,,,,"소셜 미디어 회사의 개발 팀은 ""사용자 A의 친구가 올린 동영상의 좋아요 수는 몇 개입니까?""와 같은 복잡한 쿼리를 처리하려고 합니다.솔루션 아키텍트로서 다음 중 이러한 사용 사례를 처리하는 데 가장 적합하다고 제안하는 AWS 데이터베이스 서비스는 무엇입니까?",아마존 해왕성,아마존 엘라스틱서치,Amazon Aurora,아마존 레드시프트,,,0,,
udemy,CLF-01,205,"A music-sharing company uses a Network Load Balancer to direct traffic to 5 EC2 instances managed by an Auto Scaling group. When a very popular song is released, the Auto Scaling Group scales to 100 instances and the company incurs high network and compute fees.The company wants a solution to reduce the costs without changing any of the application code. What do you recommend?",D,D,Leverage AWS Storage Gateway,Move the songs to S3,Move the songs to Glacier,Use a CloudFront distribution,,,,음악 공유 회사는 Network Load Balancer를 사용하여 Auto Scaling 그룹에서 관리하는 5개의 EC2 인스턴스로 트래픽을 보냅니다. 매우 인기 있는 노래가 출시되면 Auto Scaling Group은 인스턴스를 100개로 확장하고 회사는 높은 네트워크 및 컴퓨팅 비용을 발생시킵니다.회사는 애플리케이션 코드를 변경하지 않고 비용을 절감할 수 있는 솔루션을 원합니다. 추천 메뉴가 무엇인가요?,AWS Storage Gateway 활용,노래를 S3로 이동,노래를 Glacier로 이동,CloudFront 배포 사용,,,0,,
udemy,CLF-01,206,"A ride-sharing company wants to improve the ride-tracking system that stores GPS coordinates for all rides. The engineering team at the company is looking for a NoSQL database that has single-digit millisecond latency, can scale horizontally, and is serverless, so that they can perform high-frequency lookups reliably.As a Solutions Architect, which database do you recommend for their requirements?",B,B,Amazon Neptune,Amazon DynamoDB,Amazon ElastiCache,Amazon Relational Database Service (Amazon RDS),,,,차량 공유 회사는 모든 차량에 대한 GPS 좌표를 저장하는 차량 추적 시스템을 개선하려고 합니다. 이 회사의 엔지니어링 팀은 지연 시간이 한 자릿수 밀리초이고 수평 확장이 가능하며 서버리스이므로 높은 빈도의 조회를 안정적으로 수행할 수 있는 NoSQL 데이터베이스를 찾고 있습니다.솔루션 설계자로서 그들의 요구 사항에 대해 어떤 데이터베이스를 권장합니까?,아마존 해왕성,아마존 다이나모DB,아마존 엘라스티캐시,Amazon 관계형 데이터베이스 서비스(Amazon RDS),,,0,,
udemy,CLF-01,207,"An Internet-of-Things (IoT) company would like to have a streaming system that performs real-time analytics on the ingested IoT data. Once the analytics is done, the company would like to send notifications back to the mobile applications of the IoT device owners.As a solutions architect, which of the following AWS technologies would you recommend to send these notifications to the mobile applications?",B,B,Amazon Kinesis with Simple Email Service (Amazon SES),Amazon Kinesis with Amazon Simple Notification Service (SNS),Amazon Kinesis with Simple Queue Service (SQS),Amazon Simple Queue Service (SQS) with Amazon Simple Notification Service (SNS),,,,IoT(Internet-of-Things) 회사는 수집된 IoT 데이터에 대한 실시간 분석을 수행하는 스트리밍 시스템을 원합니다. 분석이 완료되면 회사는 IoT 장치 소유자의 모바일 애플리케이션에 다시 알림을 보내려고 합니다.솔루션 아키텍트로서 이러한 알림을 모바일 애플리케이션에 보내기 위해 다음 AWS 기술 중 어떤 것을 추천하시겠습니까?,간단한 이메일 서비스를 사용하는 Amazon Kinesis(Amazon SES),Amazon Simple Notification Service(SNS)를 사용하는 Amazon Kinesis,SQS(Simple Queue Service)를 사용하는 Amazon Kinesis,Amazon Simple Notification Service(SNS)를 사용하는 Amazon Simple Queue Service(SQS),,,0,,
udemy,CLF-01,208,"A Pharmaceuticals company is looking for a simple solution to connect its VPCs and on-premises networks through a central hub.As a Solutions Architect, which of the following would you suggest as the solution that requires the LEAST operational overhead?",B,B,Partially meshed VPC peering can be used to connect the Amazon VPCs to the on-premises networks,Use AWS Transit Gateway to connect the Amazon VPCs to the on-premises networks,Fully meshed VPC peering can be used to connect the Amazon VPCs to the on-premises networks,Use Transit VPC Solution to connect the Amazon VPCs to the on-premises networks,,,,한 제약 회사는 중앙 허브를 통해 VPC와 온프레미스 네트워크를 연결하는 간단한 솔루션을 찾고 있습니다.솔루션 아키텍트로서 다음 중 최소한의 운영 오버헤드가 필요한 솔루션으로 제안하는 것은 무엇입니까?,부분적으로 메시된 VPC 피어링을 사용하여 Amazon VPC를 온프레미스 네트워크에 연결할 수 있습니다.,AWS Transit Gateway를 사용하여 Amazon VPC를 온프레미스 네트워크에 연결,완전한 메시 VPC 피어링을 사용하여 Amazon VPC를 온프레미스 네트워크에 연결할 수 있습니다.,Transit VPC Solution을 사용하여 Amazon VPC를 온프레미스 네트워크에 연결,,,0,,
udemy,CLF-01,209,"A company wants to adopt a hybrid cloud infrastructure where it uses some AWS services such as S3 alongside its on-premises data center. The company wants a dedicated private connection between the on-premise data center and AWS. In case of failures though, the company needs to guarantee uptime and is willing to use the public internet for an encrypted connection.What do you recommend? (Select two)",CE,CE,Use Site to Site VPN as a primary connection,Use Egress Only Internet Gateway as a backup connection,Use Site to Site VPN as a backup connection,Use Direct Connect as a backup connection,Use Direct Connect as a primary connection,,,회사는 온프레미스 데이터 센터와 함께 S3와 같은 일부 AWS 서비스를 사용하는 하이브리드 클라우드 인프라를 채택하려고 합니다. 회사는 온프레미스 데이터 센터와 AWS 간의 전용 프라이빗 연결을 원합니다. 그러나 실패할 경우 회사는 가동 시간을 보장해야 하며 암호화된 연결을 위해 공용 인터넷을 사용할 의향이 있습니다.추천 메뉴가 무엇인가요? (2개 선택),Site to Site VPN을 기본 연결로 사용,외부 전용 인터넷 게이트웨이를 백업 연결로 사용,Site to Site VPN을 백업 연결로 사용,Direct Connect를 백업 연결로 사용,Direct Connect를 기본 연결로 사용,,0,,
udemy,CLF-01,210,"For security purposes, a development team has decided to deploy the EC2 instances in a private subnet. The team plans to use VPC endpoints so that the instances can access some AWS services securely. The members of the team would like to know about the two AWS services that support Gateway Endpoints.As a solutions architect, which of the following services would you suggest for this requirement? (Select two)",AE,AE,Amazon S3,Amazon Simple Notification Service (SNS),Amazon Kinesis,Amazon Simple Queue Service (SQS),DynamoDB,,,보안을 위해 개발 팀은 프라이빗 서브넷에 EC2 인스턴스를 배포하기로 결정했습니다. 팀은 인스턴스가 일부 AWS 서비스에 안전하게 액세스할 수 있도록 VPC 엔드포인트를 사용할 계획입니다. 팀 구성원은 게이트웨이 엔드포인트를 지원하는 두 가지 AWS 서비스에 대해 알고 싶어합니다.솔루션 설계자로서 이 요구 사항에 대해 다음 중 어떤 서비스를 제안하시겠습니까? (2개 선택),아마존 S3,Amazon 단순 알림 서비스(SNS),아마존 키네시스,Amazon 단순 대기열 서비스(SQS),DynamoDB,,0,,
udemy,CLF-01,211,A social media company wants the capability to dynamically alter the size of a geographic area from which traffic is routed to a specific server resource.Which feature of Route 53 can help achieve this functionality?,D,D,Latency-based routing,Geolocation routing,Weighted routing,Geoproximity routing,,,,소셜 미디어 회사는 트래픽이 특정 서버 리소스로 라우팅되는 지리적 영역의 크기를 동적으로 변경할 수 있는 기능을 원합니다.이 기능을 달성하는 데 도움이 되는 Route 53의 기능은 무엇입니까?,대기 시간 기반 라우팅,지리적 위치 라우팅,가중 라우팅,지리 근접 라우팅,,,0,,
udemy,CLF-01,212,"You are working for a SaaS (Software as a Service) company as a solutions architect and help design solutions for the company's customers. One of the customers is a bank and has a requirement to whitelist up to two public IPs when the bank is accessing external services across the internet.Which architectural choice do you recommend to maintain high availability, support scaling-up to 10 instances and comply with the bank's requirements?",A,A,Use a Network Load Balancer with an Auto Scaling Group (ASG),Use a Classic Load Balancer with an Auto Scaling Group (ASG),Use an Application Load Balancer with an Auto Scaling Group (ASG),Use an Auto Scaling Group (ASG) with Dynamic Elastic IPs attachment,,,,귀하는 SaaS(Software as a Service) 회사에서 솔루션 아키텍트로 일하고 있으며 회사 고객을 위한 솔루션 설계를 돕고 있습니다. 고객 중 하나는 은행이며 은행이 인터넷을 통해 외부 서비스에 액세스할 때 최대 2개의 공용 IP를 화이트리스트에 추가해야 한다는 요구 사항이 있습니다.고가용성을 유지하고 최대 10개의 인스턴스 확장을 지원하며 은행의 요구 사항을 준수하기 위해 어떤 아키텍처 선택을 권장합니까?,Auto Scaling 그룹(ASG)과 함께 Network Load Balancer 사용,Auto Scaling 그룹(ASG)과 함께 Classic Load Balancer 사용,ASG(Auto Scaling Group)와 함께 Application Load Balancer 사용,동적 탄력적 IP 연결과 함께 ASG(Auto Scaling Group) 사용,,,0,,
udemy,CLF-01,213,"A retail company is using AWS Site-to-Site VPN connections for secure connectivity to its AWS cloud resources from its on-premises data center. Due to a surge in traffic across the VPN connections to the AWS cloud, users are experiencing slower VPN connectivity.Which of the following options will maximize the VPN throughput?",A,A,Create a transit gateway with equal cost multipath routing and add additional VPN tunnels,Use Transfer Acceleration for the VPN connection to maximize the throughput,Create a virtual private gateway with equal cost multipath routing and multiple channels,Use AWS Global Accelerator for the VPN connection to maximize the throughput,,,,소매 회사는 온프레미스 데이터 센터에서 AWS 클라우드 리소스에 대한 보안 연결을 위해 AWS Site-to-Site VPN 연결을 사용하고 있습니다. AWS 클라우드에 대한 VPN 연결을 통한 트래픽 급증으로 인해 사용자는 VPN 연결 속도가 느려지고 있습니다.다음 중 VPN 처리량을 최대화하는 옵션은 무엇입니까?,동일 비용 다중 경로 라우팅으로 전송 게이트웨이 생성 및 추가 VPN 터널 추가,VPN 연결에 Transfer Acceleration을 사용하여 처리량 최대화,동일한 비용의 다중 경로 라우팅 및 다중 채널을 사용하여 가상 프라이빗 게이트웨이 생성,VPN 연결에 AWS Global Accelerator를 사용하여 처리량 극대화,,,0,,
udemy,CLF-01,214,"An Elastic Load Balancer has marked all the EC2 instances in the target group as unhealthy. Surprisingly, when a developer enters the IP address of the EC2 instances in the web browser, he can access the website.What could be the reason the instances are being marked as unhealthy? (Select two)",AD,AD,The security group of the EC2 instance does not allow for traffic from the security group of the Application Load Balancer,Your web-app has a runtime that is not supported by the Application Load Balancer,The EBS volumes have been improperly mounted,The route for the health check is misconfigured,You need to attach Elastic IP to the EC2 instances,,,Elastic Load Balancer가 대상 그룹의 모든 EC2 인스턴스를 비정상으로 표시했습니다. 놀랍게도 개발자가 웹 브라우저에 EC2 인스턴스의 IP 주소를 입력하면 웹 사이트에 접속할 수 있습니다.인스턴스가 비정상으로 표시되는 이유는 무엇입니까? (2개 선택),EC2 인스턴스의 보안 그룹은 Application Load Balancer 보안 그룹의 트래픽을 허용하지 않습니다.,웹 앱에 Application Load Balancer에서 지원하지 않는 런타임이 있습니다.,EBS 볼륨이 부적절하게 마운트되었습니다.,상태 확인 경로가 잘못 구성됨,EC2 인스턴스에 탄력적 IP를 연결해야 합니다.,,0,,
udemy,CLF-01,215,"A CRM web application was written as a monolith in PHP and is facing scaling issues because of performance bottlenecks. The CTO wants to re-engineer towards microservices architecture and expose their application from the same load balancer, linked to different target groups with different URLs: checkout.mycorp.com, www.mycorp.com, yourcorp.com/profile and yourcorp.com/search. The CTO would like to expose all these URLs as HTTPS endpoints for security purposes.As a solutions architect, which of the following would you recommend as a solution that requires MINIMAL configuration effort?",A,A,Use SSL certificates with SNI,Use an HTTP to HTTPS redirect,Use a wildcard SSL certificate,Change the ELB SSL Security Policy,,,,"CRM 웹 애플리케이션은 PHP에서 모놀리식으로 작성되었으며 성능 병목 현상으로 인해 확장 문제에 직면해 있습니다. CTO는 마이크로서비스 아키텍처로 재설계하고 다른 URL(checkout.mycorp.com, www.mycorp.com, yourcorp.com/profile 및 yourcorp.com)을 사용하여 다른 대상 그룹에 연결된 동일한 로드 밸런서에서 애플리케이션을 노출하려고 합니다. /찾다. CTO는 보안을 위해 이러한 모든 URL을 HTTPS 끝점으로 노출하려고 합니다.솔루션 아키텍트로서 다음 중 최소한의 구성 작업이 필요한 솔루션으로 권장하는 솔루션은 무엇입니까?",SNI와 함께 SSL 인증서 사용,HTTP에서 HTTPS로 리디렉션 사용,와일드카드 SSL 인증서 사용,ELB SSL 보안 정책 변경,,,0,,
udemy,CLF-01,216,"As an e-sport tournament hosting company, you have servers that need to scale and be highly available. Therefore you have deployed an Elastic Load Balancer (ELB) with an Auto Scaling group (ASG) across 3 Availability Zones (AZs). When e-sport tournaments are running, the servers need to scale quickly. And when tournaments are done, the servers can be idle. As a general rule, you would like to be highly available, have the capacity to scale and optimize your costs.What do you recommend? (Select two)",CD,CD,Set the minimum capacity to 1,Use Dedicated hosts for the minimum capacity,Use Reserved Instances for the minimum capacity,Set the minimum capacity to 2,Set the minimum capacity to 3,,,e스포츠 토너먼트 호스팅 회사는 확장성과 가용성이 높아야 하는 서버를 보유하고 있습니다. 따라서 3개의 가용 영역(AZ)에 걸쳐 Auto Scaling 그룹(ASG)과 함께 ELB(Elastic Load Balancer)를 배포했습니다. e-스포츠 토너먼트가 실행 중일 때 서버는 빠르게 확장되어야 합니다. 토너먼트가 끝나면 서버가 유휴 상태가 될 수 있습니다. 일반적으로 가용성이 높고 비용을 확장하고 최적화할 수 있는 용량을 원합니다.추천 메뉴가 무엇인가요? (2개 선택),최소 용량을 1로 설정,최소 용량에 전용 호스트 사용,최소 용량에 예약 인스턴스 사용,최소 용량을 2로 설정,최소 용량을 3으로 설정,,0,,
udemy,CLF-01,217,"A company has migrated its application from a monolith architecture to a microservices based architecture. The development team has updated the Route 53 simple record to point ""myapp.mydomain.com"" from the old Load Balancer to the new one.The users are still not redirected to the new Load Balancer. What has gone wrong in the configuration?",D,D,The health checks are failing,The Alias Record is misconfigured,The CNAME Record is misconfigured,The TTL is still in effect,,,,"회사에서 애플리케이션을 모놀리식 아키텍처에서 마이크로서비스 기반 아키텍처로 마이그레이션했습니다. 개발 팀은 이전 로드 밸런서에서 새 로드 밸런서로 ""myapp.mydomain.com""을 가리키도록 Route 53 단순 레코드를 업데이트했습니다.사용자는 여전히 새 로드 밸런서로 리디렉션되지 않습니다. 구성에서 무엇이 잘못되었습니까?",상태 확인이 실패하고 있습니다.,별칭 레코드가 잘못 구성됨,CNAME 레코드가 잘못 구성됨,TTL은 여전히 ​​유효합니다.,,,0,,
udemy,CLF-01,218,"A company has recently created a new department to handle their services workload. An IT team has been asked to create a custom VPC to isolate the resources created in this new department. They have set up the public subnet and internet gateway (IGW). However, they are not able to ping the Amazon EC2 instances with Elastic IP launched in the newly created VPC.As a Solutions Architect, the team has requested your help. How will you troubleshoot this scenario? (Select two)",AE,AE,Check if the security groups allow ping from the source,Create a secondary IGW to attach with public subnet and move the current IGW to private and write route tables,Contact AWS support to map your VPC with subnet,Disable Source / Destination check on the EC2 instance,Check if the route table is configured with IGW,,,회사는 최근에 서비스 워크로드를 처리하기 위해 새로운 부서를 만들었습니다. IT 팀은 이 새로운 부서에서 생성된 리소스를 격리하기 위해 사용자 지정 VPC를 생성하라는 요청을 받았습니다. 퍼블릭 서브넷과 인터넷 게이트웨이(IGW)를 설정했습니다. 그러나 새로 생성된 VPC에서 시작된 탄력적 IP로 Amazon EC2 인스턴스를 ping할 수 없습니다.솔루션 아키텍트로서 팀은 귀하의 도움을 요청했습니다. 이 시나리오의 문제를 어떻게 해결하시겠습니까? (2개 선택),보안 그룹이 소스에서 ping을 허용하는지 확인,퍼블릭 서브넷에 연결할 보조 IGW를 생성하고 현재 IGW를 프라이빗으로 이동하고 경로 테이블 쓰기,VPC를 서브넷과 매핑하려면 AWS 지원에 문의하십시오.,EC2 인스턴스에서 소스/대상 확인 비활성화,경로 테이블이 IGW로 구성되어 있는지 확인,,0,,
udemy,CLF-01,219,"A company has grown from a small startup to an enterprise employing over 1000 people. As the team size has grown, the company has recently observed some strange behavior, with S3 buckets settings being changed regularly.How can you figure out what's happening without restricting the rights of the users?",C,C,Implement an IAM policy to forbid users to change S3 bucket settings,Use S3 access logs to analyze user access using Athena,Use CloudTrail to analyze API calls,Implement a bucket policy requiring MFA for all operations,,,,작은 스타트업에서 1000명이 넘는 직원을 고용하는 기업으로 성장한 회사입니다. 팀 규모가 커짐에 따라 회사는 최근 S3 버킷 설정이 정기적으로 변경되는 몇 가지 이상한 동작을 관찰했습니다.사용자의 권리를 제한하지 않고 무슨 일이 일어나고 있는지 어떻게 알 수 있습니까?,사용자가 S3 버킷 설정을 변경하는 것을 금지하는 IAM 정책 구현,S3 액세스 로그를 사용하여 Athena를 사용하여 사용자 액세스 분석,CloudTrail을 사용하여 API 호출 분석,모든 작업에 MFA를 요구하는 버킷 정책 구현,,,0,,
udemy,CLF-01,220,"As a solutions architect, you have created a solution that utilizes an Application Load Balancer with stickiness and an Auto Scaling Group (ASG). The ASG spawns across 2 Availability Zones (AZ). AZ-A has 3 EC2 instances and AZ-B has 4 EC2 instances. The ASG is about to go into a scale-in event due to the triggering of a CloudWatch alarm.What will happen under the default ASG configuration?",B,B,A random instance will be terminated in AZ-B,The instance with the oldest launch configuration will be terminated in AZ-B,An instance in the AZ-A will be created,A random instance in the AZ-A will be terminated,,,,솔루션 아키텍트로서 귀하는 고정성이 있는 Application Load Balancer와 ASG(Auto Scaling Group)를 활용하는 솔루션을 만들었습니다. ASG는 2개의 가용 영역(AZ)에 걸쳐 생성됩니다. AZ-A에는 3개의 EC2 인스턴스가 있고 AZ-B에는 4개의 EC2 인스턴스가 있습니다. ASG는 CloudWatch 경보 트리거로 인해 축소 이벤트에 들어가려고 합니다.기본 ASG 구성에서는 어떻게 됩니까?,임의 인스턴스는 AZ-B에서 종료됩니다.,가장 오래된 시작 구성이 있는 인스턴스는 AZ-B에서 종료됩니다.,AZ-A의 인스턴스가 생성됩니다.,AZ-A의 임의 인스턴스가 종료됩니다.,,,0,,
udemy,CLF-01,221,"The engineering team at a global e-commerce company is currently reviewing their disaster recovery strategy. The team has outlined that they need to be able to quickly recover their application stack with a Recovery Time Objective (RTO) of 5 minutes, in all of the AWS Regions that the application runs. The application stack currently takes over 45 minutes to install on a Linux system.As a Solutions architect, which of the following options would you recommend as the disaster recovery strategy?",A,A,Create an AMI after installing the software and copy the AMI across all Regions. Use this Region-specific AMI to run the recovery process in the respective Regions,Use Amazon EC2 user data to speed up the installation process,Create an AMI after installing the software and use this AMI to run the recovery process in other Regions,Store the installation files in Amazon S3 for quicker retrieval,,,,글로벌 전자 상거래 회사의 엔지니어링 팀은 현재 재해 복구 전략을 검토하고 있습니다. 팀은 애플리케이션이 실행되는 모든 AWS 리전에서 5분의 RTO(복구 시간 목표)로 애플리케이션 스택을 신속하게 복구할 수 있어야 한다고 설명했습니다. 애플리케이션 스택은 현재 Linux 시스템에 설치하는 데 45분 이상 걸립니다.솔루션 설계자로서 다음 중 재해 복구 전략으로 추천할 옵션은 무엇입니까?,소프트웨어를 설치한 후 AMI를 생성하고 모든 리전에서 AMI를 복사합니다. 이 리전별 AMI를 사용하여 해당 리전에서 복구 프로세스를 실행합니다.,Amazon EC2 사용자 데이터를 사용하여 설치 프로세스 속도 향상,소프트웨어 설치 후 AMI를 생성하고 이 AMI를 사용하여 다른 리전에서 복구 프로세스 실행,빠른 검색을 위해 Amazon S3에 설치 파일 저장,,,0,,
udemy,CLF-01,222,"You are working as an AWS architect for a weather tracking facility. You are asked to set up a Disaster Recovery (DR) mechanism with minimum costs. In case of failure, the facility can only bear data loss of a few minutes without jeopardizing the forecasting models.As a Solutions Architect, which DR method will you suggest?",D,D,Multi-Site,Warm Standby,Backup and Restore,Pilot Light,,,,날씨 추적 시설의 AWS 설계자로 일하고 있습니다. 최소 비용으로 DR(재해 복구) 메커니즘을 설정하라는 메시지가 표시됩니다. 장애가 발생할 경우 시설은 예측 모델을 위태롭게 하지 않고 몇 분 동안만 데이터 손실을 견딜 수 있습니다.솔루션 설계자로서 제안할 DR 방법은 무엇입니까?,다중 사이트,웜 스탠바이,백업 및 복원,파일럿 라이트,,,0,,
udemy,CLF-01,223,"A junior developer has downloaded a sample Amazon S3 bucket policy to make changes to it based on new company-wide access policies. He has requested your help in understanding this bucket policy.As a Solutions Architect, which of the following would you identify as the correct description for the given policy?{ ""Version"": ""2012-10-17"", ""Id"": ""S3PolicyId1"", ""Statement"": [   {     ""Sid"": ""IPAllow"",     ""Effect"": ""Allow"",     ""Principal"": ""*"",     ""Action"": ""s3:*"",     ""Resource"": ""arn:aws:s3:::examplebucket/*"",     ""Condition"": {        ""IpAddress"": {""aws:SourceIp"": ""54.240.143.0/24""},        ""NotIpAddress"": {""aws:SourceIp"": ""54.240.143.188/32""}     }   } ]}",B,B,It authorizes an IP address and a CIDR to access the S3 bucket,It authorizes an entire CIDR except one IP address to access the S3 bucket,"It ensures the S3 bucket is exposing an external IP within the CIDR range specified, except one IP",It ensures EC2 instances that have inherited a security group can access the bucket,,,,"주니어 개발자가 샘플 Amazon S3 버킷 정책을 다운로드하여 회사 전체의 새로운 액세스 정책을 기반으로 변경했습니다. 그는 이 버킷 정책을 이해하는 데 도움을 요청했습니다.솔루션 아키텍트로서 다음 중 주어진 정책에 대한 올바른 설명으로 식별하는 것은 무엇입니까?{ ""Version"": ""2012-10-17"", ""Id"": ""S3PolicyId1"", ""Statement"": [   {     ""Sid"": ""IPAllow"",     ""Effect"": ""Allow"",     ""Principal"": ""*"",     ""Action"": ""s3:*"",     ""Resource"": ""arn:aws:s3:::examplebucket/*"",     ""Condition"": {        ""IpAddress"": {""aws:SourceIp"": ""54.240.143.0/24""},        ""NotIpAddress"": {""aws:SourceIp"": ""54.240.143.188/32""}     }   } ]}",IP 주소와 CIDR이 S3 버킷에 액세스할 수 있는 권한을 부여합니다.,S3 버킷에 액세스하기 위해 하나의 IP 주소를 제외한 전체 CIDR에 권한을 부여합니다.,S3 버킷이 하나의 IP를 제외하고 지정된 CIDR 범위 내에서 외부 IP를 노출하는지 확인합니다.,보안 그룹을 상속한 EC2 인스턴스가 버킷에 액세스할 수 있도록 합니다.,,,0,,
udemy,CLF-01,224,"A company has noticed that its EBS storage volume (io1) accounts for 90% of the cost and the remaining 10% cost can be attributed to the EC2 instance. The CloudWatch metrics report that both the EC2 instance and the EBS volume are under-utilized. The CloudWatch metrics also show that the EBS volume has occasional I/O bursts. The entire infrastructure is managed by AWS CloudFormation.As a Solutions Architect, what do you propose to reduce the costs?",A,A,Convert the Amazon EC2 instance EBS volume to gp2,Change the Amazon EC2 instance type to something much smaller,Don't use a CloudFormation template to create the database as the CloudFormation service incurs greater service charges,Keep the EBS volume to io1 and reduce the IOPS,,,,회사는 EBS 스토리지 볼륨(io1)이 비용의 90%를 차지하고 나머지 10% 비용은 EC2 인스턴스에 기인할 수 있음을 확인했습니다. CloudWatch 지표는 EC2 인스턴스와 EBS 볼륨 모두 활용도가 낮다고 보고합니다. CloudWatch 지표는 또한 EBS 볼륨에 간헐적인 I/O 버스트가 있음을 보여줍니다. 전체 인프라는 AWS CloudFormation에서 관리합니다.솔루션 설계자로서 비용 절감을 위해 제안하는 것은 무엇입니까?,Amazon EC2 인스턴스 EBS 볼륨을 gp2로 변환,Amazon EC2 인스턴스 유형을 훨씬 작은 것으로 변경,CloudFormation 서비스에 더 많은 서비스 요금이 부과되므로 CloudFormation 템플릿을 사용하여 데이터베이스를 생성하지 마십시오.,EBS 볼륨을 io1로 유지하고 IOPS를 줄입니다.,,,0,,
udemy,CLF-01,225,"You are working as a Solutions Architect for a photo processing company that has a proprietary algorithm to compress an image without any loss in quality. Because of the efficiency of the algorithm, your clients are willing to wait for a response that carries their compressed images back. You also want to process these jobs asynchronously and scale quickly, to cater to the high demand. Additionally, you also want the job to be retried in case of failures.Which combination of choices do you recommend to minimize cost and comply with the requirements? (Select two)",CD,CD,Amazon Simple Notification Service (SNS),EC2 Reserved Instances,Amazon Simple Queue Service (SQS),EC2 Spot Instances,EC2 On-Demand Instances,,,귀하는 품질 손실 없이 이미지를 압축하는 독점 알고리즘을 보유한 사진 처리 회사의 솔루션 아키텍트로 일하고 있습니다. 알고리즘의 효율성으로 인해 클라이언트는 압축된 이미지를 다시 전달하는 응답을 기꺼이 기다립니다. 또한 이러한 작업을 비동기식으로 처리하고 신속하게 확장하여 높은 수요를 충족하고자 합니다. 또한 실패 시 작업을 다시 시도하려고 합니다.비용을 최소화하고 요구 사항을 준수하기 위해 권장하는 선택 조합은 무엇입니까? (2개 선택),Amazon 단순 알림 서비스(SNS),EC2 예약 인스턴스,Amazon 단순 대기열 서비스(SQS),EC2 스팟 인스턴스,EC2 온디맨드 인스턴스,,0,,
udemy,CLF-01,226,"A developer in your company has set up a classic 2 tier architecture consisting of an Application Load Balancer and an Auto Scaling group (ASG) managing a fleet of EC2 instances. The ALB is deployed in a subnet of size 10.0.1.0/24 and the ASG is deployed in a subnet of size 10.0.4.0/22.As a solutions architect, you would like to adhere to the security pillar of the well-architected framework. How do you configure the security group of the EC2 instances to only allow traffic coming from the ALB?",C,C,Add a rule to authorize the security group of the ASG,Add a rule to authorize the CIDR 10.0.1.0/24,Add a rule to authorize the security group of the ALB,Add a rule to authorize the CIDR 10.0.4.0/22,,,,회사의 개발자가 Application Load Balancer와 EC2 인스턴스 플릿을 관리하는 Auto Scaling 그룹(ASG)으로 구성된 클래식 2계층 아키텍처를 설정했습니다. ALB는 크기의 서브넷에 배포되고 10.0.1.0/24ASG는 크기의 서브넷에 배포됩니다 10.0.4.0/22.솔루션 설계자는 Well-Architected 프레임워크의 보안 원칙을 고수하고자 합니다. ALB에서 오는 트래픽만 허용하도록 EC2 인스턴스의 보안 그룹을 어떻게 구성합니까?,ASG의 보안 그룹에 권한을 부여하는 규칙 추가,CIDR을 승인하는 규칙 추가10.0.1.0/24,ALB의 보안 그룹에 권한을 부여하는 규칙 추가,CIDR을 승인하는 규칙 추가10.0.4.0/22,,,0,,
udemy,CLF-01,227,A retail company uses AWS Cloud to manage its technology infrastructure. The company has deployed its consumer-focused web application on EC2-based web servers and uses RDS PostgreSQL DB as the data store. The PostgreSQL DB is set up in a private subnet that allows inbound traffic from selected EC2 instances. The DB also uses AWS KMS for encrypting data at rest.Which of the following steps would you recommend to facilitate secure access to the database?,D,D,Create a new Network Access Control List (NACL) that blocks SSH from the entire EC2 subnet into the DB,Use IAM authentication to access the DB instead of the database user's access credentials,Create a new security group that blocks SSH from the selected EC2 instances into the DB,Configure RDS to use SSL for data in transit,,,,소매 회사는 AWS 클라우드를 사용하여 기술 인프라를 관리합니다. 이 회사는 소비자 중심의 웹 애플리케이션을 EC2 기반 웹 서버에 배포했으며 RDS PostgreSQL DB를 데이터 저장소로 사용합니다. PostgreSQL DB는 선택한 EC2 인스턴스의 인바운드 트래픽을 허용하는 프라이빗 서브넷에 설정됩니다. DB는 유휴 데이터 암호화에도 AWS KMS를 사용합니다.다음 중 데이터베이스에 대한 보안 액세스를 용이하게 하기 위해 권장하는 단계는 무엇입니까?,전체 EC2 서브넷에서 DB로의 SSH를 차단하는 새 네트워크 액세스 제어 목록(NACL) 생성,데이터베이스 사용자의 액세스 자격 증명 대신 IAM 인증을 사용하여 DB에 액세스,선택한 EC2 인스턴스에서 DB로의 SSH를 차단하는 새 보안 그룹 생성,전송 중인 데이터에 SSL을 사용하도록 RDS 구성,,,0,,
udemy,CLF-01,228,"A healthcare company is evaluating storage options on Amazon S3 to meet regulatory guidelines. The data should be stored in such a way on S3 that it cannot be deleted until the regulatory time period has expired.As a solutions architect, which of the following would you recommend for the given requirement?",D,D,Activate MFA delete on the S3 bucket,Use S3 Glacier Vault Lock,Use S3 cross-Region Replication,Use S3 Object Lock,,,,의료 회사는 규제 지침을 충족하기 위해 Amazon S3의 스토리지 옵션을 평가하고 있습니다. 데이터는 규제 기간이 만료될 때까지 삭제할 수 없도록 S3에 저장해야 합니다.솔루션 설계자로서 주어진 요구 사항에 대해 다음 중 무엇을 추천하시겠습니까?,S3 버킷에서 MFA 삭제 활성화,S3 Glacier 볼트 잠금 사용,S3 교차 리전 복제 사용,S3 객체 잠금 사용,,,0,,
udemy,CLF-01,229,A company's business logic is built on several microservices that are running in the on-premises data center. They currently communicate using a message broker that supports the MQTT protocol. The company is looking at migrating these applications and the message broker to AWS Cloud without changing the application logic.Which technology allows you to get a managed message broker that supports the MQTT protocol?,C,C,Amazon Simple Queue Service (SQS),Amazon Kinesis Data Streams,Amazon MQ,Amazon Simple Notification Service (SNS),,,,회사의 비즈니스 논리는 온프레미스 데이터 센터에서 실행되는 여러 마이크로 서비스를 기반으로 합니다. 현재 MQTT 프로토콜을 지원하는 메시지 브로커를 사용하여 통신합니다. 이 회사는 애플리케이션 로직을 변경하지 않고 이러한 애플리케이션과 메시지 브로커를 AWS 클라우드로 마이그레이션하는 방법을 찾고 있습니다.MQTT 프로토콜을 지원하는 관리형 메시지 브로커를 얻을 수 있는 기술은 무엇입니까?,Amazon 단순 대기열 서비스(SQS),Amazon Kinesis 데이터 스트림,아마존 MQ,Amazon 단순 알림 서비스(SNS),,,0,,
udemy,CLF-01,230,"Your company is deploying a website running on Elastic Beanstalk. The website takes over 45 minutes for the installation and contains both static as well as dynamic files that must be generated during the installation process.As a Solutions Architect, you would like to bring the time to create a new instance in your Elastic Beanstalk deployment to be less than 2 minutes. Which of the following options should be combined to build a solution for this requirement? (Select two)",AB,AB,Use EC2 user data to customize the dynamic installation parts at boot time,Create a Golden AMI with the static installation components already setup,Store the installation files in S3 so they can be quickly retrieved,Use Elastic Beanstalk deployment caching feature,Use EC2 user data to install the application at boot time,,,귀사는 Elastic Beanstalk에서 실행되는 웹사이트를 배포하고 있습니다. 웹 사이트는 설치에 45분 이상이 소요되며 설치 프로세스 중에 생성되어야 하는 정적 파일과 동적 파일이 모두 포함되어 있습니다.솔루션 설계자는 Elastic Beanstalk 배포에서 새 인스턴스를 생성하는 데 걸리는 시간을 2분 미만으로 만들고 싶습니다. 이 요구 사항에 대한 솔루션을 구축하려면 다음 중 어떤 옵션을 결합해야 합니까? (2개 선택),EC2 사용자 데이터를 사용하여 부팅 시 동적 설치 부분을 사용자 지정,정적 설치 구성 요소가 이미 설정된 Golden AMI 생성,설치 파일을 빠르게 검색할 수 있도록 S3에 저장,Elastic Beanstalk 배포 캐싱 기능 사용,EC2 사용자 데이터를 사용하여 부팅 시 애플리케이션 설치,,0,,
udemy,CLF-01,231,An IT company runs a high-performance computing (HPC) workload on AWS. The workload requires high network throughput and low-latency network performance along with tightly coupled node-to-node communications. The EC2 instances are properly sized for compute and storage capacity and are launched using default options.Which of the following solutions can be used to improve the performance of the workload?,C,C,Select an Elastic Inference accelerator while launching EC2 instances,Select the appropriate capacity reservation while launching EC2 instances,Select a cluster placement group while launching EC2 instances,Select dedicated instance tenancy while launching EC2 instances,,,,IT 회사는 AWS에서 고성능 컴퓨팅(HPC) 워크로드를 실행합니다. 워크로드에는 긴밀하게 결합된 노드 간 통신과 함께 높은 네트워크 처리량과 짧은 지연 시간의 네트워크 성능이 필요합니다. EC2 인스턴스는 컴퓨팅 및 스토리지 용량에 맞게 적절한 크기로 지정되며 기본 옵션을 사용하여 시작됩니다.다음 중 워크로드의 성능을 개선하는 데 사용할 수 있는 솔루션은 무엇입니까?,EC2 인스턴스를 시작하는 동안 Elastic Inference 액셀러레이터 선택,EC2 인스턴스를 시작하는 동안 적절한 용량 예약 선택,EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹 선택,EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시 선택,,,0,,
udemy,CLF-01,232,A ride-sharing company wants to use an Amazon DynamoDB table for data storage. The table will not be used during the night hours whereas the read and write traffic will often be unpredictable during day hours. When traffic spikes occur they will happen very quickly.Which of the following will you recommend as the best-fit solution?,C,C,Set up a DynamoDB global table in the provisioned capacity mode,Set up a DynamoDB table in the provisioned capacity mode with auto-scaling enabled,Set up a DynamoDB table in the on-demand capacity mode,Set up a DynamoDB table with a global secondary index,,,,차량 공유 회사는 데이터 스토리지에 Amazon DynamoDB 테이블을 사용하려고 합니다. 야간에는 테이블이 사용되지 않는 반면 주간에는 읽기 및 쓰기 트래픽을 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다.다음 중 가장 적합한 솔루션으로 추천할 항목은 무엇입니까?,프로비저닝된 용량 모드에서 DynamoDB 글로벌 테이블 설정,Auto Scaling이 활성화된 프로비저닝된 용량 모드에서 DynamoDB 테이블 설정,온디맨드 용량 모드에서 DynamoDB 테이블 설정,글로벌 보조 인덱스로 DynamoDB 테이블 설정,,,0,,
udemy,CLF-01,233,"You started a new job as a solutions architect at a company that has both AWS experts and people learning AWS. Recently, a developer misconfigured a newly created RDS database which resulted in a production outage.How can you ensure that RDS specific best practices are incorporated into a reusable infrastructure template to be used by all your AWS users?",B,B,Store your recommendations in a custom Trusted Advisor rule,Use CloudFormation to manage RDS databases,Create a Lambda function which sends emails when it finds misconfigured RDS databases,Attach an IAM policy to interns preventing them from creating an RDS database,,,,AWS 전문가와 AWS를 배우는 사람들이 있는 회사에서 솔루션 설계자로 새로운 일을 시작했습니다. 최근에 한 개발자가 새로 만든 RDS 데이터베이스를 잘못 구성하여 생산 중단이 발생했습니다.RDS 관련 모범 사례가 모든 AWS 사용자가 사용할 재사용 가능한 인프라 템플릿에 통합되도록 하려면 어떻게 해야 합니까?,맞춤형 Trusted Advisor 규칙에 권장 사항 저장,CloudFormation을 사용하여 RDS 데이터베이스 관리,잘못 구성된 RDS 데이터베이스를 찾으면 이메일을 보내는 Lambda 함수 생성,인턴이 RDS 데이터베이스를 생성하지 못하도록 하는 IAM 정책을 인턴에게 연결,,,0,,
udemy,CLF-01,234,"A Big Data analytics company writes data and log files in Amazon S3 buckets. The company now wants to stream the existing data files as well as any ongoing file updates from Amazon S3 to Amazon Kinesis Data Streams.As a Solutions Architect, which of the following would you suggest as the fastest possible way of building a solution for this requirement?",B,B,Amazon S3 bucket actions can be directly configured to write data into Amazon Simple Notification Service (SNS). SNS can then be used to send the updates to Amazon Kinesis Data Streams,Leverage AWS Database Migration Service (AWS DMS) as a bridge between Amazon S3 and Amazon Kinesis Data Streams,Configure EventBridge events for the bucket actions on Amazon S3. An AWS Lambda function can then be triggered from the EventBridge event that will send the necessary data to Amazon Kinesis Data Streams,Leverage S3 event notification to trigger a Lambda function for the file create event. The Lambda function will then send the necessary data to Amazon Kinesis Data Streams,,,,빅 데이터 분석 회사는 Amazon S3 버킷에 데이터 및 로그 파일을 기록합니다. 이제 회사는 기존 데이터 파일과 Amazon S3에서 Amazon Kinesis Data Streams로 진행 중인 파일 업데이트를 스트리밍하려고 합니다.솔루션 설계자로서 다음 중 이 요구 사항에 대한 솔루션을 구축하는 가장 빠른 방법으로 제안하는 것은 무엇입니까?,Amazon S3 버킷 작업은 Amazon Simple Notification Service(SNS)에 데이터를 쓰도록 직접 구성할 수 있습니다. 그런 다음 SNS를 사용하여 업데이트를 Amazon Kinesis Data Streams로 보낼 수 있습니다.,AWS Database Migration Service(AWS DMS)를 Amazon S3와 Amazon Kinesis Data Streams 간의 브리지로 활용,Amazon S3에서 버킷 작업에 대한 EventBridge 이벤트를 구성합니다. 그런 다음 필요한 데이터를 Amazon Kinesis Data Streams로 보내는 EventBridge 이벤트에서 AWS Lambda 함수를 트리거할 수 있습니다.,S3 이벤트 알림을 활용하여 파일 생성 이벤트에 대한 Lambda 함수를 트리거합니다. 그러면 Lambda 함수가 필요한 데이터를 Amazon Kinesis Data Streams로 보냅니다.,,,0,,
udemy,CLF-01,235,"An IT company has a large number of clients opting to build their APIs by using Docker containers. To facilitate the hosting of these containers, the company is looking at various orchestration services available with AWS.As a Solutions Architect, which of the following solutions will you suggest? (Select two)",CD,CD,Use Amazon ECS with Amazon EC2 for serverless orchestration of the containerized services,Use Amazon SageMaker for serverless orchestration of the containerized services,Use Amazon ECS with AWS Fargate for serverless orchestration of the containerized services,Use Amazon EKS with AWS Fargate for serverless orchestration of the containerized services,Use Amazon EMR for serverless orchestration of the containerized services,,,IT 회사에는 Docker 컨테이너를 사용하여 API를 구축하기로 선택한 많은 고객이 있습니다. 이러한 컨테이너의 호스팅을 용이하게 하기 위해 회사는 AWS에서 사용할 수 있는 다양한 오케스트레이션 서비스를 찾고 있습니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 제안하시겠습니까? (2개 선택),컨테이너화된 서비스의 서버리스 오케스트레이션을 위해 Amazon EC2와 함께 Amazon ECS 사용,컨테이너화된 서비스의 서버리스 오케스트레이션에 Amazon SageMaker 사용,컨테이너화된 서비스의 서버리스 오케스트레이션을 위해 AWS Fargate와 함께 Amazon ECS 사용,컨테이너화된 서비스의 서버리스 오케스트레이션을 위해 AWS Fargate와 함께 Amazon EKS 사용,컨테이너화된 서비스의 서버리스 오케스트레이션에 Amazon EMR 사용,,0,,
udemy,CLF-01,236,"A digital media company needs to manage uploads of around 1TB each from an application being used by a partner company.As a Solutions Architect, how will you handle the upload of these files to Amazon S3?",D,D,Use Amazon S3 Versioning,Use AWS Snowball,Use Direct Connect to provide extra bandwidth,Use multi-part upload feature of Amazon S3,,,,디지털 미디어 회사는 파트너 회사에서 사용 중인 애플리케이션에서 각각 약 1TB의 업로드를 관리해야 합니다.솔루션 아키텍트로서 이러한 파일을 Amazon S3에 업로드하는 작업을 어떻게 처리하시겠습니까?,Amazon S3 버전 관리 사용,AWS Snowball 사용,Direct Connect를 사용하여 추가 대역폭 제공,Amazon S3의 멀티파트 업로드 기능 사용,,,0,,
udemy,CLF-01,237,"A leading e-commerce company runs its IT infrastructure on AWS Cloud. The company has a batch job running at 7 am daily on an RDS database. It processes shipping orders for the past day, and usually gets around 2000 records that need to be processed sequentially in a batch job via a shell script. The processing of each record takes about 3 seconds.What platform do you recommend to run this batch job?",B,B,Amazon Kinesis Data Streams,Amazon EC2,AWS Lambda,AWS Glue,,,,선도적인 전자 상거래 회사는 AWS 클라우드에서 IT 인프라를 실행합니다. 이 회사는 RDS 데이터베이스에서 매일 오전 7시에 실행되는 배치 작업을 가지고 있습니다. 지난 하루 동안의 배송 주문을 처리하고 일반적으로 쉘 스크립트를 통해 배치 작업에서 순차적으로 처리해야 하는 약 2000개의 레코드를 가져옵니다. 각 레코드 처리에는 약 3초가 걸립니다.이 배치 작업을 실행하기 위해 어떤 플랫폼을 권장합니까?,Amazon Kinesis 데이터 스트림,아마존 EC2,AWS 람다,AWS 글루,,,0,,
udemy,CLF-01,238,"A company runs a popular dating website on the AWS Cloud. As a Solutions Architect, you've designed the architecture of the website to follow a serverless pattern on the AWS Cloud using API Gateway and AWS Lambda. The backend uses an RDS PostgreSQL database. Currently, the application uses a username and password combination to connect the Lambda function to the RDS database.You would like to improve the security at the authentication level by leveraging short-lived credentials. What will you choose? (Select two)",CE,CE,Deploy AWS Lambda in a VPC,"Embed a credential rotation logic in the AWS Lambda, retrieving them from SSM",Use IAM authentication from Lambda to RDS PostgreSQL,Restrict the RDS database security group to the Lambda's security group,Attach an AWS Identity and Access Management (IAM) role to AWS Lambda,,,한 회사가 AWS 클라우드에서 인기 있는 데이트 웹사이트를 운영하고 있습니다. 솔루션 아키텍트로서 귀하는 API Gateway 및 AWS Lambda를 사용하여 AWS 클라우드에서 서버리스 패턴을 따르도록 웹 사이트의 아키텍처를 설계했습니다. 백엔드는 RDS PostgreSQL 데이터베이스를 사용합니다. 현재 애플리케이션은 사용자 이름과 암호 조합을 사용하여 Lambda 함수를 RDS 데이터베이스에 연결합니다.단기 자격 증명을 활용하여 인증 수준에서 보안을 개선하려고 합니다. 무엇을 선택하시겠습니까? (2개 선택),VPC에 AWS Lambda 배포,자격 증명 교체 논리를 AWS Lambda에 포함하여 SSM에서 검색,Lambda에서 RDS PostgreSQL로 IAM 인증 사용,RDS 데이터베이스 보안 그룹을 Lambda의 보안 그룹으로 제한,AWS Identity and Access Management(IAM) 역할을 AWS Lambda에 연결,,0,,
udemy,CLF-01,239,"A systems administrator is creating IAM policies and attaching them to IAM identities. After creating the necessary identity-based policies, the administrator is now creating resource-based policies.Which is the only resource-based policy that the IAM service supports?",B,B,Access control list (ACL),Trust policy,AWS Organizations Service Control Policies (SCP),Permissions boundary,,,,시스템 관리자가 IAM 정책을 생성하고 이를 IAM 자격 증명에 연결하고 있습니다. 필요한 자격 증명 기반 정책을 만든 후 관리자는 이제 리소스 기반 정책을 만듭니다.IAM 서비스가 지원하는 유일한 리소스 기반 정책은 무엇입니까?,액세스 제어 목록(ACL),신뢰 정책,AWS Organizations 서비스 제어 정책(SCP),권한 경계,,,0,,
udemy,CLF-01,240,"A mobile gaming company is experiencing heavy read traffic to its Amazon Relational Database Service (RDS) database that retrieves player’s scores and stats. The company is using an RDS database instance type that is not cost-effective for their budget. The company would like to implement a strategy to deal with the high volume of read traffic, reduce latency, and also downsize the instance size to cut costs.Which of the following solutions do you recommend?",B,B,Setup RDS Read Replicas,Setup ElastiCache in front of RDS,Switch application code to AWS Lambda for better performance,Move to Amazon Redshift,,,,모바일 게임 회사는 플레이어의 점수와 통계를 검색하는 Amazon Relational Database Service(RDS) 데이터베이스에 대한 읽기 트래픽이 과중합니다. 회사는 예산에 비해 비용 효율적이지 않은 RDS 데이터베이스 인스턴스 유형을 사용하고 있습니다. 회사는 많은 양의 읽기 트래픽을 처리하고 대기 시간을 줄이며 인스턴스 크기를 축소하여 비용을 절감하는 전략을 구현하고자 합니다.다음 중 어떤 솔루션을 권장하십니까?,RDS 읽기 복제본 설정,RDS 앞에 ElastiCache 설정,성능 향상을 위해 애플리케이션 코드를 AWS Lambda로 전환,아마존 레드시프트로 이동,,,0,,
udemy,CLF-01,241,"Your company runs a web portal to match developers to clients who need their help. As a solutions architect, you've designed the architecture of the website to be fully serverless with API Gateway & AWS Lambda. The backend uses a DynamoDB table. You would like to automatically congratulate your developers on important milestones, such as - their first paid contract. All the contracts are stored in DynamoDB.Which DynamoDB feature can you use to implement this functionality such that there is LEAST delay in sending automatic notifications?",A,A,DynamoDB Streams + Lambda,EventBridge events + Lambda,Amazon SQS + Lambda,DynamoDB DAX + API Gateway,,,,귀사는 웹 포털을 운영하여 도움이 필요한 클라이언트와 개발자를 연결합니다. 솔루션 아키텍트로서 귀하는 API Gateway 및 AWS Lambda를 사용하여 웹 사이트의 아키텍처를 완전히 서버리스로 설계했습니다. 백엔드는 DynamoDB 테이블을 사용합니다. 첫 번째 유료 계약과 같은 중요한 이정표에서 개발자를 자동으로 축하하고 싶습니다. 모든 계약은 DynamoDB에 저장됩니다.자동 알림을 보내는 데 최소 지연이 있도록 이 기능을 구현하는 데 사용할 수 있는 DynamoDB 기능은 무엇입니까?,DynamoDB 스트림 + Lambda,EventBridge 이벤트 + Lambda,아마존 SQS + 람다,DynamoDB DAX + API 게이트웨이,,,0,,
udemy,CLF-01,242,"As part of the on-premises data center migration to AWS Cloud, a company is looking at using multiple AWS Snow Family devices to move their on-premises data.Which Snow Family service offers the feature of storage clustering?",A,A,AWS Snowball Edge Compute Optimized,AWS Snowmobile,AWS Snowmobile Storage Compute,AWS Snowcone,,,,온프레미스 데이터 센터를 AWS 클라우드로 마이그레이션하는 과정의 일환으로 한 회사에서 여러 AWS Snow Family 장치를 사용하여 온프레미스 데이터를 이동하려고 합니다.스토리지 클러스터링 기능을 제공하는 Snow Family 서비스는 무엇입니까?,AWS Snowball Edge 컴퓨팅 최적화,AWS 스노우모빌,AWS Snowmobile 스토리지 컴퓨팅,AWS 스노우콘,,,0,,
udemy,CLF-01,243,"A financial services firm has traditionally operated with an on-premise data center and would like to create a disaster recovery strategy leveraging the AWS Cloud.As a Solutions Architect, you would like to ensure that a scaled-down version of a fully functional environment is always running in the AWS cloud, and in case of a disaster, the recovery time is kept to a minimum. Which disaster recovery strategy is that?",D,D,Pilot Light,Backup and Restore,Multi Site,Warm Standby,,,,금융 서비스 회사는 전통적으로 온프레미스 데이터 센터에서 운영해 왔으며 AWS 클라우드를 활용하는 재해 복구 전략을 만들고자 합니다.솔루션 아키텍트로서 완벽하게 작동하는 환경의 축소된 버전이 항상 AWS 클라우드에서 실행되고 재해 발생 시 복구 시간이 최소로 유지되는지 확인하고자 합니다. 어떤 재해 복구 전략입니까?,파일럿 라이트,백업 및 복원,다중 사이트,웜 스탠바이,,,0,,
udemy,CLF-01,244,"You have an S3 bucket that contains files in two different folders - s3://my-bucket/images and s3://my-bucket/thumbnails. When an image is first uploaded and new, it is viewed several times. But after 45 days, analytics prove that image files are on average rarely requested, but the thumbnails still are. After 180 days, you would like to archive the image files and the thumbnails. Overall you would like the solution to remain highly available to prevent disasters happening against a whole AZ.How can you implement an efficient cost strategy for your S3 bucket? (Select two)",BE,BE,Create a Lifecycle Policy to transition objects to Glacier using a prefix after 180 days,Create a Lifecycle Policy to transition objects to S3 Standard IA using a prefix after 45 days,Create a Lifecycle Policy to transition all objects to S3 Standard IA after 45 days,Create a Lifecycle Policy to transition objects to S3 One Zone IA using a prefix after 45 days,Create a Lifecycle Policy to transition all objects to Glacier after 180 days,,,s3://my-bucket/images두 개의 서로 다른 폴더( 및 ) 에 파일을 포함하는 S3 버킷이 있습니다 s3://my-bucket/thumbnails. 이미지가 처음 업로드되고 새로 업로드되면 여러 번 표시됩니다. 그러나 45일 후 분석에 따르면 이미지 파일은 평균적으로 거의 요청되지 않지만 썸네일은 여전히 ​​요청됩니다. 180일 후 이미지 파일과 썸네일을 보관하려고 합니다. 전반적으로 전체 AZ에 대해 발생하는 재해를 방지하기 위해 솔루션의 가용성을 높게 유지하기를 원합니다.S3 버킷에 대한 효율적인 비용 전략을 어떻게 구현할 수 있습니까? (2개 선택),180일 후에 접두사를 사용하여 개체를 Glacier로 전환하는 수명 주기 정책 생성,45일 후에 접두사를 사용하여 객체를 S3 Standard IA로 전환하는 수명 주기 정책 생성,45일 후에 모든 객체를 S3 Standard IA로 전환하는 수명 주기 정책 생성,45일 후에 접두사를 사용하여 객체를 S3 One Zone IA로 전환하는 수명 주기 정책 생성,180일 후에 모든 객체를 Glacier로 전환하는 수명 주기 정책 생성,,0,,
udemy,CLF-01,245,"A company has developed a popular photo-sharing website using a serverless pattern on the AWS Cloud using API Gateway and AWS Lambda. The backend uses an RDS PostgreSQL database. The website is experiencing high read traffic and the Lambda functions are putting an increased read load on the RDS database.The architecture team is planning to increase the read throughput of the database, without changing the application's core logic. As a Solutions Architect, what do you recommend?",A,A,Use Amazon RDS Read Replicas,Use Amazon ElastiCache,Use Amazon DynamoDB,Use Amazon RDS Multi-AZ feature,,,,한 회사가 API Gateway와 AWS Lambda를 사용하여 AWS 클라우드에서 서버리스 패턴을 사용하여 인기있는 사진 공유 웹 사이트를 개발했습니다. 백엔드는 RDS PostgreSQL 데이터베이스를 사용합니다. 웹 사이트에서 읽기 트래픽이 많고 Lambda 함수가 RDS 데이터베이스에 대한 읽기 로드를 증가시키고 있습니다.아키텍처 팀은 애플리케이션의 핵심 논리를 변경하지 않고 데이터베이스의 읽기 처리량을 늘릴 계획입니다. 솔루션 아키텍트로서 추천하는 것은 무엇입니까?,Amazon RDS 읽기 전용 복제본 사용,Amazon ElastiCache 사용,Amazon DynamoDB 사용,Amazon RDS 다중 AZ 기능 사용,,,0,,
udemy,CLF-01,246,"An e-commerce company has copied 1 PB of data from its on-premises data center to an Amazon S3 bucket in the us-west-1 Region using an AWS Direct Connect link. The company now wants to set up a one-time copy of the data to another S3 bucket in the us-east-1 Region. The on-premises data center does not allow the use of AWS Snowball.As a Solutions Architect, which of the following options can be used to accomplish this goal? (Select two)",AC,AC,Copy data from the source bucket to the destination bucket using the aws S3 sync command,Set up S3 Transfer Acceleration to copy objects across S3 buckets in different Regions using S3 console,Set up S3 batch replication to copy objects across S3 buckets in another Region using S3 console and then delete the replication configuration,Use Snowball Edge device to copy the data from one Region to another Region,Copy data from the source S3 bucket to a target S3 bucket using the S3 console,,,한 전자상거래 회사가 AWS Direct Connect 링크를 사용하여 온프레미스 데이터 센터에서 us-west-1 리전의 Amazon S3 버킷으로 1PB의 데이터를 복사했습니다. 이제 회사는 us-east-1 리전의 다른 S3 버킷에 데이터의 일회성 사본을 설정하려고 합니다. 온프레미스 데이터 센터는 AWS Snowball 사용을 허용하지 않습니다.솔루션 설계자로서 이 목표를 달성하기 위해 다음 중 어떤 옵션을 사용할 수 있습니까? (2개 선택),aws S3 sync 명령을 사용하여 원본 버킷에서 대상 버킷으로 데이터 복사,S3 콘솔을 사용하여 다른 리전의 S3 버킷 간에 객체를 복사하도록 S3 Transfer Acceleration 설정,S3 콘솔을 사용하여 다른 리전의 S3 버킷 간에 객체를 복사하도록 S3 일괄 복제를 설정한 다음 복제 구성을 삭제합니다.,Snowball Edge 디바이스를 사용하여 한 리전에서 다른 리전으로 데이터 복사,S3 콘솔을 사용하여 원본 S3 버킷에서 대상 S3 버킷으로 데이터 복사,,0,,
udemy,CLF-01,247,"A photo hosting service publishes a collection of beautiful mountain images, every month, that aggregate over 50 GB in size and downloaded all around the world. The content is currently hosted on EFS and distributed by Elastic Load Balancing (ELB) and Amazon EC2 instances. The website is experiencing high load each month and very high network costs.As a Solutions Architect, what can you recommend that won't force an application refactor and reduce network costs and EC2 load drastically?",D,D,Upgrade the Amazon EC2 instances,Host the master pack onto Amazon S3 for faster access,Enable ELB caching,Create a CloudFront distribution,,,,사진 호스팅 서비스는 매월 총 50GB가 넘는 아름다운 산 이미지 모음을 게시하고 전 세계에서 다운로드합니다. 콘텐츠는 현재 EFS에서 호스팅되고 Elastic Load Balancing(ELB) 및 Amazon EC2 인스턴스에 의해 배포됩니다. 웹 사이트는 매달 높은 부하와 매우 높은 네트워크 비용을 경험하고 있습니다.솔루션 아키텍트로서 애플리케이션 리팩터링을 강제하지 않고 네트워크 비용과 EC2 로드를 크게 줄이지 않는 것을 권장할 수 있습니까?,Amazon EC2 인스턴스 업그레이드,빠른 액세스를 위해 마스터 팩을 Amazon S3에 호스팅,ELB 캐싱 활성화,CloudFront 배포 생성,,,0,,
udemy,CLF-01,248,A media company uses Amazon ElastiCache Redis to enhance the performance of its RDS database layer. The company wants a robust disaster recovery strategy for its caching layer that guarantees minimal downtime as well as minimal data loss while ensuring good application performance.Which of the following solutions will you recommend to address the given use-case?,C,C,Add read-replicas across multiple availability zones to reduce the risk of potential data loss because of failure,Schedule daily automatic backups at a time when you expect low resource utilization for your cluster,Opt for Multi-AZ configuration with automatic failover functionality to help mitigate failure,Schedule manual backups using Redis append-only file (AOF),,,,미디어 회사는 Amazon ElastiCache Redis를 사용하여 RDS 데이터베이스 계층의 성능을 향상시킵니다. 이 회사는 우수한 애플리케이션 성능을 보장하면서 최소한의 가동 중지 시간과 최소한의 데이터 손실을 보장하는 캐싱 계층에 대한 강력한 재해 복구 전략을 원합니다.다음 중 주어진 사용 사례를 해결하기 위해 권장하는 솔루션은 무엇입니까?,장애로 인한 잠재적인 데이터 손실 위험을 줄이기 위해 여러 가용 영역에 걸쳐 읽기 복제본을 추가합니다.,클러스터의 리소스 사용률이 낮을 것으로 예상되는 시간에 매일 자동 백업을 예약합니다.,장애를 완화하는 데 도움이 되는 자동 장애 조치 기능이 있는 다중 AZ 구성을 선택하십시오.,Redis AOF(추가 전용 파일)를 사용하여 수동 백업 예약,,,0,,
udemy,CLF-01,249,"You have developed a new REST API leveraging the API Gateway, AWS Lambda and Aurora database services. Most of the workload on the website is read-heavy. The data rarely changes and it is acceptable to serve users outdated data for about 24 hours. Recently, the website has been experiencing high load and the costs incurred on the Aurora database have been very high.How can you easily reduce the costs while improving performance, with minimal changes?",A,A,Enable API Gateway Caching,Add Aurora Read Replicas,Enable AWS Lambda In Memory Caching,Switch to using an Application Load Balancer,,,,"API 게이트웨이, AWS Lambda 및 Aurora 데이터베이스 서비스를 활용하는 새로운 REST API를 개발했습니다. 웹 사이트의 작업량 대부분은 읽기 작업이 많습니다. 데이터는 거의 변경되지 않으며 약 24시간 동안 사용자에게 오래된 데이터를 제공하는 것이 허용됩니다. 최근 웹 사이트에 높은 부하가 발생하고 있으며 Aurora 데이터베이스에서 발생하는 비용이 매우 높습니다.최소한의 변경으로 어떻게 성능을 향상시키면서 비용을 쉽게 줄일 수 있습니까?",API 게이트웨이 캐싱 활성화,Aurora 읽기 복제본 추가,메모리 캐싱에서 AWS Lambda 활성화,Application Load Balancer 사용으로 전환,,,0,,
udemy,CLF-01,250,"A niche social media application allows users to connect with sports athletes. As a solutions architect, you've designed the architecture of the application to be fully serverless using API Gateway & AWS Lambda. The backend uses a DynamoDB table. Some of the star athletes using the application are highly popular, and therefore DynamoDB has increased the RCUs. Still, the application is experiencing a hot partition problem.What can you do to improve the performance of DynamoDB and eliminate the hot partition problem without a lot of application refactoring?",D,D,Use DynamoDB Global Tables,Use DynamoDB Streams,Use Amazon ElastiCache,Use DynamoDB DAX,,,,틈새 소셜 미디어 애플리케이션을 통해 사용자는 스포츠 선수와 연결할 수 있습니다. 솔루션 설계자로서 API Gateway 및 AWS Lambda를 사용하여 애플리케이션의 아키텍처를 완전히 서버리스로 설계했습니다. 백엔드는 DynamoDB 테이블을 사용합니다. 이 애플리케이션을 사용하는 스타 선수 중 일부는 인기가 높기 때문에 DynamoDB는 RCU를 늘렸습니다. 여전히 응용 프로그램에 핫 파티션 문제가 있습니다.많은 애플리케이션 리팩토링 없이 DynamoDB의 성능을 개선하고 핫 파티션 문제를 제거하기 위해 무엇을 할 수 있습니까?,DynamoDB 전역 테이블 사용,DynamoDB 스트림 사용,Amazon ElastiCache 사용,DynamoDB DAX 사용,,,0,,
udemy,CLF-01,251,"A small rental company had 5 employees, all working under the same AWS cloud account. These employees deployed their applications built for various functions- including billing, operations, finance, etc. Each of these employees has been operating in their own VPC. Now, there is a need to connect these VPCs so that the applications can communicate with each other.Which of the following is the MOST cost-effective solution for this use-case?",C,C,Use a Direct Connect,Use a NAT Gateway,Use VPC Peering,Use an Internet Gateway,,,,"소규모 임대 회사에는 5명의 직원이 있었고 모두 동일한 AWS 클라우드 계정으로 작업했습니다. 이 직원들은 청구, 운영, 재무 등 다양한 기능을 위해 구축된 애플리케이션을 배포했습니다. 이 직원들은 각자 자신의 VPC에서 운영해 왔습니다. 이제 애플리케이션이 서로 통신할 수 있도록 이러한 VPC를 연결해야 합니다.다음 중 이 사용 사례에 대한 가장 비용 효율적인 솔루션은 무엇입니까?",직접 연결 사용,NAT 게이트웨이 사용,VPC 피어링 사용,인터넷 게이트웨이 사용,,,0,,
udemy,CLF-01,252,"An enterprise has decided to move its secondary workloads such as backups and archives to AWS cloud. The CTO wishes to move the data stored on physical tapes to Cloud, without changing their current tape backup workflows. The company holds petabytes of data on tapes and needs a cost-optimized solution to move this data to cloud.What is an optimal solution that meets these requirements while keeping the costs to a minimum?",B,B,"Use AWS Direct Connect, a cloud service solution that makes it easy to establish a dedicated network connection from on-premises to AWS to transfer data. Once this is done, Amazon S3 can be used to store data at lesser costs","Use Tape Gateway, which can be used to move on-premises tape data onto AWS Cloud. Then, Amazon S3 archiving storage classes can be used to store data cost-effectively for years","Use AWS DataSync, which makes it simple and fast to move large amounts of data online between on-premises storage and AWS Cloud. Data moved to Cloud can then be stored cost-effectively in Amazon S3 archiving storage classes","Use AWS VPN connection between the on-premises datacenter and your Amazon VPC. Once this is established, you can use Amazon Elastic File System (Amazon EFS) to get a scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources",,,,한 기업이 백업 및 아카이브와 같은 보조 워크로드를 AWS 클라우드로 이동하기로 결정했습니다. CTO는 현재 테이프 백업 워크플로우를 변경하지 않고 물리적 테이프에 저장된 데이터를 클라우드로 이동하기를 원합니다. 이 회사는 페타바이트 규모의 데이터를 테이프에 보관하고 있으며 이 데이터를 클라우드로 이동하려면 비용 최적화된 솔루션이 필요합니다.비용을 최소화하면서 이러한 요구 사항을 충족하는 최적의 솔루션은 무엇입니까?,온프레미스에서 AWS로 전용 네트워크 연결을 쉽게 설정하여 데이터를 전송할 수 있는 클라우드 서비스 솔루션인 AWS Direct Connect를 사용하십시오. 이 작업이 완료되면 Amazon S3를 사용하여 더 적은 비용으로 데이터를 저장할 수 있습니다.,온프레미스 테이프 데이터를 AWS 클라우드로 이동하는 데 사용할 수 있는 테이프 게이트웨이를 사용합니다. 그런 다음 Amazon S3 아카이빙 스토리지 클래스를 사용하여 수년간 비용 효율적으로 데이터를 저장할 수 있습니다.,온프레미스 스토리지와 AWS 클라우드 간에 대량의 데이터를 온라인으로 쉽고 빠르게 이동할 수 있는 AWS DataSync를 사용하십시오. 그런 다음 클라우드로 이동한 데이터를 Amazon S3 아카이빙 스토리지 클래스에 비용 효율적으로 저장할 수 있습니다.,온프레미스 데이터 센터와 Amazon VPC 간에 AWS VPN 연결을 사용합니다. 이것이 설정되면 Amazon Elastic File System(Amazon EFS)을 사용하여 AWS 클라우드 서비스 및 온프레미스 리소스와 함께 사용할 확장 가능하고 완벽하게 관리되는 탄력적 NFS 파일 시스템을 얻을 수 있습니다.,,,0,,
udemy,CLF-01,253,"A CRM company has a SaaS (Software as a Service) application that feeds updates to other in-house and third-party applications. The SaaS application and the in-house applications are being migrated to use AWS services for this inter-application communication.As a Solutions Architect, which of the following would you suggest to asynchronously decouple the architecture?",B,B,Use Amazon Simple Notification Service (SNS) to communicate between systems and decouple the architecture,Use Amazon EventBridge to decouple the system architecture,Use Amazon Simple Queue Service (SQS) to decouple the architecture,Use Elastic Load Balancing for effective decoupling of system architecture,,,,CRM 회사에는 다른 사내 및 타사 응용 프로그램에 대한 업데이트를 제공하는 SaaS(Software as a Service) 응용 프로그램이 있습니다. SaaS 애플리케이션과 사내 애플리케이션은 이 애플리케이션 간 통신을 위해 AWS 서비스를 사용하도록 마이그레이션되고 있습니다.솔루션 설계자로서 다음 중 아키텍처를 비동기식으로 분리하기 위해 제안하는 것은 무엇입니까?,Amazon Simple Notification Service(SNS)를 사용하여 시스템 간 통신 및 아키텍처 분리,Amazon EventBridge를 사용하여 시스템 아키텍처 분리,Amazon Simple Queue Service(SQS)를 사용하여 아키텍처 분리,시스템 아키텍처의 효과적인 분리를 위해 Elastic Load Balancing 사용,,,0,,
udemy,CLF-01,254,Amazon Route 53 is configured to route traffic to two Network Load Balancer (NLB) nodes belonging to two Availability Zones (AZs): AZ-A and AZ-B. Cross-zone load balancing is disabled. AZ-A has four targets and AZ-B has six targets.Which of the below statements is true about traffic distribution to the target instances from Route 53?,C,C,Each of the four targets in AZ-A receives 8% of the traffic,Each of the four targets in AZ-A receives 10% of the traffic,Each of the four targets in AZ-A receives 12.5% of the traffic,Each of the six targets in AZ-B receives 10% of the traffic,,,,Amazon Route 53은 2개의 가용 영역(AZ)인 AZ-A 및 AZ-B에 속하는 2개의 NLB(Network Load Balancer) 노드로 트래픽을 라우팅하도록 구성됩니다. 교차 영역 로드 밸런싱이 비활성화됩니다. AZ-A에는 4개의 표적이 있고 AZ-B에는 6개의 표적이 있습니다.다음 중 Route 53에서 대상 인스턴스로의 트래픽 분산에 대한 설명으로 옳은 것은 무엇입니까?,AZ-A의 4개 대상은 각각 트래픽의 8%를 수신합니다.,AZ-A의 4개 대상은 각각 트래픽의 10%를 수신합니다.,AZ-A의 4개 대상은 각각 트래픽의 12.5%를 수신합니다.,AZ-B의 6개 대상은 각각 트래픽의 10%를 수신합니다.,,,0,,
udemy,CLF-01,255,"The engineering team at a social media company has recently migrated to AWS Cloud from its on-premises data center. The team is evaluating CloudFront to be used as a CDN for its flagship application. The team has hired you as an AWS Certified Solutions Architect Associate to advise on CloudFront capabilities on routing, security, and high availability.Which of the following would you identify as correct regarding CloudFront? (Select three)",AEF,AEF,Use field level encryption in CloudFront to protect sensitive data for specific content,Use geo restriction to configure CloudFront for high-availability and failover,CloudFront can route to multiple origins based on the price class,Use KMS encryption in CloudFront to protect sensitive data for specific content,CloudFront can route to multiple origins based on the content type,Use an origin group with primary and secondary origins to configure CloudFront for high-availability and failover,,"소셜 미디어 회사의 엔지니어링 팀은 최근 온프레미스 데이터 센터에서 AWS 클라우드로 마이그레이션했습니다. 팀은 주력 애플리케이션의 CDN으로 사용할 CloudFront를 평가하고 있습니다. 팀은 라우팅, 보안 및 고가용성에 대한 CloudFront 기능에 대해 조언하기 위해 귀하를 AWS 공인 솔루션 아키텍트 어소시에이트로 고용했습니다.다음 중 CloudFront와 관련하여 올바른 것은 무엇입니까? (3개 선택)",CloudFront에서 필드 수준 암호화를 사용하여 특정 콘텐츠의 민감한 데이터 보호,지리적 제한을 사용하여 고가용성 및 장애 조치를 위한 CloudFront 구성,CloudFront는 가격 등급에 따라 여러 오리진으로 라우팅할 수 있습니다.,CloudFront에서 KMS 암호화를 사용하여 특정 콘텐츠의 민감한 데이터 보호,CloudFront는 콘텐츠 유형에 따라 여러 오리진으로 라우팅할 수 있습니다.,,0,,기본 및 보조 오리진이 있는 오리진 그룹을 사용하여 고가용성 및 장애 조치를 위한 CloudFront 구성
udemy,CLF-01,256,What does this CloudFormation snippet do? (Select three)SecurityGroupIngress:     - IpProtocol: tcp       FromPort: 80       ToPort: 80       CidrIp: 0.0.0.0/0     - IpProtocol: tcp       FromPort: 22       ToPort: 22       CidrIp: 192.168.1.1/32,BCD,BCD,It configures a security group's outbound rules,It allows any IP to pass through on the HTTP port,It configures a security group's inbound rules,It lets traffic flow from one IP on port 22,It only allows the IP 0.0.0.0 to reach HTTP,It configures an NACL's inbound rules,It prevents traffic from reaching on HTTP unless from the IP 192.168.1.1,이 CloudFormation 조각은 무엇을 합니까? (3개 선택)SecurityGroupIngress:     - IpProtocol: tcp       FromPort: 80       ToPort: 80       CidrIp: 0.0.0.0/0     - IpProtocol: tcp       FromPort: 22       ToPort: 22       CidrIp: 192.168.1.1/32,보안 그룹의 아웃바운드 규칙을 구성합니다.,모든 IP가 HTTP 포트를 통과하도록 허용합니다.,보안 그룹의 인바운드 규칙을 구성합니다.,포트 22의 한 IP에서 트래픽 흐름을 허용합니다.,IP가 0.0.0.0HTTP에 도달하는 것만 허용합니다.,IP에서 오는 경우가 아니면 트래픽이 HTTP에 도달하는 것을 방지합니다.192.168.1.1,0,,NACL의 인바운드 규칙을 구성합니다.
udemy,CLF-01,257,"The engineering team at a leading e-commerce company is anticipating a surge in the traffic because of a flash sale planned for the weekend. You have estimated the web traffic to be 10x. The content of your website is highly dynamic and changes very often.As a Solutions Architect, which of the following options would you recommend to make sure your infrastructure scales for that day?",A,A,Use an Auto Scaling Group,Use a Route53 Multi Value record,Use a CloudFront distribution in front of your website,Deploy the website on S3,,,,선도적인 전자 상거래 회사의 엔지니어링 팀은 주말에 계획된 플래시 세일로 인해 트래픽이 급증할 것으로 예상하고 있습니다. 웹 트래픽을 10배로 추정했습니다. 웹사이트의 콘텐츠는 매우 역동적이며 매우 자주 변경됩니다.솔루션 아키텍트로서 그날의 인프라 확장을 위해 다음 중 어떤 옵션을 추천하시겠습니까?,Auto Scaling 그룹 사용,Route53 다중 값 레코드 사용,웹 사이트 앞에서 CloudFront 배포 사용,S3에 웹 사이트 배포,,,0,,
udemy,CLF-01,258,"The engineering team at a company is running batch workloads on AWS Cloud. The team has embedded RDS database connection strings within each web server hosting the flagship application. After failing a security audit, the team is looking at a different approach to store the database secrets securely and automatically rotate the database credentials.Which of the following solutions would you recommend to meet this requirement?",A,A,Secrets Manager,SSM Parameter Store,Systems Manager,KMS,,,,회사의 엔지니어링 팀은 AWS 클라우드에서 배치 워크로드를 실행하고 있습니다. 이 팀은 플래그십 애플리케이션을 호스팅하는 각 웹 서버 내에 RDS 데이터베이스 연결 문자열을 내장했습니다. 보안 감사에 실패한 후 팀은 데이터베이스 비밀을 안전하게 저장하고 데이터베이스 자격 증명을 자동으로 교체하는 다른 접근 방식을 찾고 있습니다.다음 중 이 요구 사항을 충족하기 위해 권장하는 솔루션은 무엇입니까?,비밀 관리자,SSM 매개변수 저장소,시스템 관리자,KMS,,,0,,
udemy,CLF-01,259,A company wants to grant access to an S3 bucket to users in its own AWS account as well as to users in another AWS account. Which of the following options can be used to meet this requirement?,A,A,Use a bucket policy to grant permission to users in its account as well as to users in another account,Use a user policy to grant permission to users in its account as well as to users in another account,Use either a bucket policy or a user policy to grant permission to users in its account as well as to users in another account,Use permissions boundary to grant permission to users in its account as well as to users in another account,,,,회사에서 자체 AWS 계정의 사용자와 다른 AWS 계정의 사용자에게 S3 버킷에 대한 액세스 권한을 부여하려고 합니다. 다음 중 이 요구 사항을 충족하는 데 사용할 수 있는 옵션은 무엇입니까?,버킷 정책을 사용하여 해당 계정의 사용자와 다른 계정의 사용자에게 권한 부여,사용자 정책을 사용하여 해당 계정의 사용자와 다른 계정의 사용자에게 권한을 부여합니다.,버킷 정책 또는 사용자 정책을 사용하여 해당 계정의 사용자와 다른 계정의 사용자에게 권한을 부여합니다.,권한 경계를 사용하여 해당 계정의 사용자와 다른 계정의 사용자에게 권한을 부여합니다.,,,0,,
udemy,CLF-01,260,"As a Solutions Architect, you are tasked to design a distributed application that will run on various EC2 instances. This application needs to have the highest performance local disk to cache data. Also, data is copied through an EC2 to EC2 replication mechanism. It is acceptable if the instance loses its data when stopped or terminated.Which storage solution do you recommend?",C,C,Amazon Simple Storage Service (Amazon S3),Amazon Elastic Block Store (EBS),Instance Store,Amazon Elastic File System (Amazon EFS),,,,솔루션 설계자는 다양한 EC2 인스턴스에서 실행될 분산 애플리케이션을 설계해야 합니다. 이 응용 프로그램은 데이터를 캐시하기 위해 최고 성능의 로컬 디스크가 필요합니다. 또한 데이터는 EC2에서 EC2로 복제 메커니즘을 통해 복사됩니다. 인스턴스가 중지되거나 종료될 때 데이터가 손실되는 경우 허용됩니다.어떤 스토리지 솔루션을 권장합니까?,Amazon Simple Storage Service(Amazon S3),아마존 엘라스틱 블록 스토어(EBS),인스턴스 스토어,Amazon 탄력적 파일 시스템(Amazon EFS),,,0,,
udemy,CLF-01,261,You have just terminated an instance in the us-west-1a availability zone. The attached EBS volume is now available for attachment to other instances. An intern launches a new Linux EC2 instance in the us-west-1b availability zone and is attempting to attach the EBS volume. The intern informs you that it is not possible and needs your help.Which of the following explanations would you provide to them?,A,A,EBS volumes are AZ locked,The required IAM permissions are missing,EBS volumes are region locked,The EBS volume is encrypted,,,,us-west-1a 가용 영역에서 방금 인스턴스를 종료했습니다. 이제 연결된 EBS 볼륨을 다른 인스턴스에 연결할 수 있습니다. 인턴이 us-west-1b 가용 영역에서 새 Linux EC2 인스턴스를 시작하고 EBS 볼륨 연결을 시도하고 있습니다. 인턴은 불가능하며 귀하의 도움이 필요하다고 알려줍니다.다음 중 어떤 설명을 그들에게 제공하시겠습니까?,EBS 볼륨은 AZ로 잠겨 있습니다.,필요한 IAM 권한이 없습니다.,EBS 볼륨은 지역 잠금,EBS 볼륨이 암호화됨,,,0,,
udemy,CLF-01,262,"A company's cloud architect has set up a solution that uses Route 53 to configure the DNS records for the primary website with the domain pointing to the Application Load Balancer (ALB). The company wants a solution where users will be directed to a static error page, configured as a backup, in case of unavailability of the primary website.Which configuration will meet the company's requirements, while keeping the changes to a bare minimum?",A,A,"Set up a Route 53 active-passive type of failover routing policy. If Route 53 health check determines the ALB endpoint as unhealthy, the traffic will be diverted to a static error page, hosted on Amazon S3 bucket","Use Route 53 Weighted routing to give minimum weight to Amazon S3 bucket that holds the error page to be displayed. In case of primary failure, the requests get routed to the error page","Set up a Route 53 active-active type of failover routing policy. If Route 53 health check determines the ALB endpoint as unhealthy, the traffic will be diverted to a static error page, hosted on Amazon S3 bucket",Use Route 53 Latency-based routing. Create a latency record to point to the Amazon S3 bucket that holds the error page to be displayed,,,,회사의 클라우드 설계자는 Route 53을 사용하여 ALB(Application Load Balancer)를 가리키는 도메인이 있는 기본 웹 사이트에 대한 DNS 레코드를 구성하는 솔루션을 설정했습니다. 회사는 기본 웹 사이트를 사용할 수 없는 경우 백업으로 구성된 정적 오류 페이지로 사용자를 안내하는 솔루션을 원합니다.변경 사항을 최소한으로 유지하면서 회사의 요구 사항을 충족하는 구성은 무엇입니까?,장애 조치 라우팅 정책의 Route 53 활성-수동 유형을 설정합니다. Route 53 상태 확인에서 ALB 엔드포인트가 비정상이라고 판단하면 트래픽이 Amazon S3 버킷에서 호스팅되는 정적 오류 페이지로 전환됩니다.,표시할 오류 페이지가 있는 Amazon S3 버킷에 최소 가중치를 부여하려면 Route 53 가중 라우팅을 사용하십시오. 기본 실패의 경우 요청이 오류 페이지로 라우팅됩니다.,장애 조치 라우팅 정책의 Route 53 활성-활성 유형을 설정합니다. Route 53 상태 확인에서 ALB 엔드포인트가 비정상이라고 판단하면 트래픽이 Amazon S3 버킷에서 호스팅되는 정적 오류 페이지로 전환됩니다.,Route 53 지연 시간 기반 라우팅을 사용합니다. 표시할 오류 페이지가 있는 Amazon S3 버킷을 가리키는 지연 시간 레코드 생성,,,0,,
udemy,CLF-01,263,"As a Solutions Architect, you have been hired to work with the engineering team at a company to create a REST API using the serverless architecture.Which of the following solutions will you recommend to move the company to the serverless architecture?",A,A,API Gateway exposing Lambda Functionality,Public-facing Application Load Balancer with ECS on Amazon EC2,Route 53 with EC2 as backend,Fargate with Lambda at the front,,,,솔루션 아키텍트는 회사의 엔지니어링 팀과 협력하여 서버리스 아키텍처를 사용하여 REST API를 생성하도록 고용되었습니다.다음 중 회사를 서버리스 아키텍처로 전환하기 위해 권장하는 솔루션은 무엇입니까?,Lambda 기능을 노출하는 API Gateway,Amazon EC2에서 ECS를 사용하는 공용 애플리케이션 로드 밸런서,EC2를 백엔드로 사용하는 Route 53,전면에 Lambda가 있는 Fargate,,,0,,
udemy,CLF-01,264,"Computer vision researchers at a university are trying to optimize the I/O bound processes for a proprietary algorithm running on EC2 instances. The ideal storage would facilitate high-performance IOPS when doing file processing in a temporary storage space before uploading the results back into Amazon S3.As a solutions architect, which of the following AWS storage options would you recommend as the MOST performant as well as cost-optimal?",C,C,Use EC2 instances with EBS Provisioned IOPS SSD (io1) as the storage option,Use EC2 instances with EBS General Purpose SSD (gp2) as the storage option,Use EC2 instances with Instance Store as the storage option,Use EC2 instances with EBS Throughput Optimized HDD (st1) as the storage option,,,,대학의 컴퓨터 비전 연구원은 EC2 인스턴스에서 실행되는 독점 알고리즘에 대한 I/O 바운드 프로세스를 최적화하려고 합니다. 이상적인 스토리지는 결과를 Amazon S3에 다시 업로드하기 전에 임시 스토리지 공간에서 파일 처리를 수행할 때 고성능 IOPS를 용이하게 합니다.솔루션 아키텍트로서 다음 AWS 스토리지 옵션 중 가장 성능이 뛰어나고 비용이 최적인 것으로 추천하는 것은 무엇입니까?,스토리지 옵션으로 EBS 프로비저닝된 IOPS SSD(io1)와 함께 EC2 인스턴스 사용,스토리지 옵션으로 EBS 범용 SSD(gp2)와 함께 EC2 인스턴스 사용,스토리지 옵션으로 인스턴스 스토어와 함께 EC2 인스턴스 사용,스토리지 옵션으로 EBS 처리량 최적화 HDD(st1)와 함께 EC2 인스턴스 사용,,,0,,
udemy,CLF-01,265,"A company has noticed that its application performance has deteriorated after a new Auto Scaling group was deployed a few days back. Upon investigation, the team found out that the Launch Configuration selected for the Auto Scaling group is using the incorrect instance type that is not optimized to handle the application workflow.As a solutions architect, what would you recommend to provide a long term resolution for this issue?",D,D,No need to modify the launch configuration. Just modify the Auto Scaling group to use the correct instance type,Modify the launch configuration to use the correct instance type and continue to use the existing Auto Scaling group,No need to modify the launch configuration. Just modify the Auto Scaling group to use more number of existing instance types. More instances may offset the loss of performance,Create a new launch configuration to use the correct instance type. Modify the Auto Scaling group to use this new launch configuration. Delete the old launch configuration as it is no longer needed,,,,며칠 전 새로운 Auto Scaling 그룹을 배포한 후 한 회사에서 애플리케이션 성능이 저하되었음을 알아차렸습니다. 조사 결과 팀은 Auto Scaling 그룹에 대해 선택한 시작 구성이 애플리케이션 워크플로를 처리하도록 최적화되지 않은 잘못된 인스턴스 유형을 사용하고 있음을 발견했습니다.솔루션 아키텍트로서 이 문제에 대한 장기적인 해결책을 제공하기 위해 무엇을 추천하시겠습니까?,시작 구성을 수정할 필요가 없습니다. 올바른 인스턴스 유형을 사용하도록 Auto Scaling 그룹을 수정하기만 하면 됩니다.,올바른 인스턴스 유형을 사용하고 기존 Auto Scaling 그룹을 계속 사용하도록 시작 구성을 수정합니다.,시작 구성을 수정할 필요가 없습니다. 기존 인스턴스 유형을 더 많이 사용하도록 Auto Scaling 그룹을 수정하기만 하면 됩니다. 더 많은 인스턴스가 성능 손실을 상쇄할 수 있습니다.,올바른 인스턴스 유형을 사용하려면 새 시작 구성을 생성하십시오. 이 새로운 시작 구성을 사용하도록 Auto Scaling 그룹을 수정합니다. 더 이상 필요하지 않은 이전 시작 구성을 삭제합니다.,,,0,,
udemy,CLF-01,266,"An IT company has built a custom data warehousing solution for a retail organization by using Amazon Redshift. As part of the cost optimizations, the company wants to move any historical data (any data older than a year) into S3, as the daily analytical reports consume data for just the last one year. However the analysts want to retain the ability to cross-reference this historical data along with the daily reports.The company wants to develop a solution with the LEAST amount of effort and MINIMUM cost. As a solutions architect, which option would you recommend to facilitate this use-case?",B,B,"Use Glue ETL job to load the S3 based historical data into Redshift. Once the ad-hoc queries are run for the historic data, it can be removed from Redshift",Use Redshift Spectrum to create Redshift cluster tables pointing to the underlying historical data in S3. The analytics team can then query this historical data to cross-reference with the daily reports from Redshift,"Setup access to the historical data via Athena. The analytics team can run historical data queries on Athena and continue the daily reporting on Redshift. In case the reports need to be cross-referenced, the analytics team need to export these in flat files and then do further analysis","Use the Redshift COPY command to load the S3 based historical data into Redshift. Once the ad-hoc queries are run for the historic data, it can be removed from Redshift",,,,IT 회사는 Amazon Redshift를 사용하여 소매 조직을 위한 맞춤형 데이터 웨어하우징 솔루션을 구축했습니다. 비용 최적화의 일환으로 회사는 과거 데이터(1년 이상 된 모든 데이터)를 S3로 옮기려고 합니다. 일일 분석 보고서는 지난 1년 동안의 데이터만 사용하기 때문입니다. 그러나 분석가는 일일 보고서와 함께 이 과거 데이터를 상호 참조할 수 있는 기능을 유지하기를 원합니다.회사는 최소한의 노력과 최소한의 비용으로 솔루션을 개발하기를 원합니다. 솔루션 설계자로서 이 사용 사례를 용이하게 하기 위해 어떤 옵션을 권장하시겠습니까?,Glue ETL 작업을 사용하여 S3 기반 기록 데이터를 Redshift로 로드합니다. 기록 데이터에 대해 임시 쿼리가 실행되면 Redshift에서 제거할 수 있습니다.,Redshift Spectrum을 사용하여 S3의 기본 기록 데이터를 가리키는 Redshift 클러스터 테이블을 생성합니다. 그런 다음 분석 팀은 이 과거 데이터를 쿼리하여 Redshift의 일일 보고서와 상호 참조할 수 있습니다.,Athena를 통해 기록 데이터에 대한 액세스를 설정합니다. 분석 팀은 Athena에서 기록 데이터 쿼리를 실행하고 Redshift에서 일일 보고를 계속할 수 있습니다. 보고서를 상호 참조해야 하는 경우 분석 팀은 보고서를 플랫 파일로 내보낸 다음 추가 분석을 수행해야 합니다.,Redshift COPY 명령을 사용하여 S3 기반 기록 데이터를 Redshift로 로드합니다. 기록 데이터에 대해 임시 쿼리가 실행되면 Redshift에서 제거할 수 있습니다.,,,0,,
udemy,CLF-01,267,A company wants to publish an event into an SQS queue whenever a new object is uploaded on S3.Which of the following statements are true regarding this functionality?,B,B,Both Standard SQS queue and FIFO SQS queue are allowed as an Amazon S3 event notification destination,"Only Standard SQS queue is allowed as an Amazon S3 event notification destination, whereas FIFO SQS queue is not allowed",Neither Standard SQS queue nor FIFO SQS queue are allowed as an Amazon S3 event notification destination,"Only FIFO SQS queue is allowed as an Amazon S3 event notification destination, whereas Standard SQS queue is not allowed",,,,회사에서 S3에 새 객체가 업로드될 때마다 SQS 대기열에 이벤트를 게시하려고 합니다.다음 중 이 기능에 대한 설명으로 옳은 것은 무엇입니까?,표준 SQS 대기열과 FIFO SQS 대기열 모두 Amazon S3 이벤트 알림 대상으로 허용됩니다.,표준 SQS 대기열만 Amazon S3 이벤트 알림 대상으로 허용되는 반면 FIFO SQS 대기열은 허용되지 않습니다.,표준 SQS 대기열과 FIFO SQS 대기열 모두 Amazon S3 이벤트 알림 대상으로 허용되지 않습니다.,FIFO SQS 대기열만 Amazon S3 이벤트 알림 대상으로 허용되는 반면 표준 SQS 대기열은 허용되지 않습니다.,,,0,,
udemy,CLF-01,268,"A leading video streaming provider is migrating to AWS Cloud infrastructure for delivering its content to users across the world. The company wants to make sure that the solution supports at least a million requests per second for its EC2 server farm.As a solutions architect, which type of Elastic Load Balancer would you recommend as part of the solution stack?",C,C,Infrastructure Load Balancer,Application Load Balancer,Network Load Balancer,Classic Load Balancer,,,,선도적인 비디오 스트리밍 공급자는 전 세계 사용자에게 콘텐츠를 제공하기 위해 AWS 클라우드 인프라로 마이그레이션하고 있습니다. 이 회사는 솔루션이 EC2 서버 팜에 대해 초당 최소 백만 건의 요청을 지원하는지 확인하려고 합니다.솔루션 설계자로서 솔루션 스택의 일부로 어떤 유형의 Elastic Load Balancer를 추천하시겠습니까?,인프라 로드 밸런서,애플리케이션 로드 밸런서,네트워크 로드 밸런서,클래식 로드 밸런서,,,0,,
udemy,CLF-01,269,A financial services company is moving its IT infrastructure to AWS Cloud and wants to enforce adequate data protection mechanisms on Amazon S3 to meet compliance guidelines. The engineering team has hired you as a solutions architect to build a solution for this requirement.Can you help the team identify the INCORRECT option from the choices below?,D,D,S3 can encrypt data in transit using HTTPS (TLS),S3 can protect data at rest using Client-Side Encryption,S3 can protect data at rest using Server-Side Encryption,S3 can encrypt object metadata by using Server-Side Encryption,,,,금융 서비스 회사는 IT 인프라를 AWS 클라우드로 이전하고 있으며 규정 준수 지침을 충족하기 위해 Amazon S3에서 적절한 데이터 보호 메커니즘을 시행하려고 합니다. 엔지니어링 팀은 이 요구 사항에 대한 솔루션을 구축하기 위해 귀하를 솔루션 설계자로 고용했습니다.팀이 아래 선택 항목에서 잘못된 옵션을 식별하도록 도울 수 있습니까?,S3는 HTTPS(TLS)를 사용하여 전송 중인 데이터를 암호화할 수 있습니다.,S3는 클라이언트 측 암호화를 사용하여 미사용 데이터를 보호할 수 있습니다.,S3는 서버 측 암호화를 사용하여 미사용 데이터를 보호할 수 있습니다.,S3는 서버 측 암호화를 사용하여 객체 메타데이터를 암호화할 수 있습니다.,,,0,,
udemy,CLF-01,270,"A silicon valley based healthcare startup uses AWS Cloud for its IT infrastructure. The startup stores patient health records on Amazon S3. The engineering team needs to implement an archival solution based on Amazon S3 Glacier to enforce regulatory and compliance controls on data access.As a solutions architect, which of the following solutions would you recommend?",A,A,Use S3 Glacier vault to store the sensitive archived data and then use a vault lock policy to enforce compliance controls,Use S3 Glacier vault to store the sensitive archived data and then use an S3 Access Control List to enforce compliance controls,Use S3 Glacier to store the sensitive archived data and then use an S3 Access Control List to enforce compliance controls,Use S3 Glacier to store the sensitive archived data and then use an S3 lifecycle policy to enforce compliance controls,,,,실리콘 밸리 기반의 의료 스타트업은 IT 인프라에 AWS Cloud를 사용합니다. 이 스타트업은 Amazon S3에 환자 건강 기록을 저장합니다. 엔지니어링 팀은 Amazon S3 Glacier를 기반으로 하는 아카이브 솔루션을 구현하여 데이터 액세스에 대한 규제 및 규정 준수 제어를 시행해야 합니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 추천하시겠습니까?,S3 Glacier 볼트를 사용하여 민감한 아카이브 데이터를 저장한 다음 볼트 잠금 정책을 사용하여 규정 준수 제어를 시행합니다.,S3 Glacier 볼트를 사용하여 중요한 보관 데이터를 저장한 다음 S3 액세스 제어 목록을 사용하여 규정 준수 제어를 시행합니다.,S3 Glacier를 사용하여 민감한 아카이브 데이터를 저장한 다음 S3 액세스 제어 목록을 사용하여 규정 준수 제어를 시행합니다.,S3 Glacier를 사용하여 민감한 아카이브 데이터를 저장한 다음 S3 수명 주기 정책을 사용하여 규정 준수 제어를 시행합니다.,,,0,,
udemy,CLF-01,271,"A startup has created a cost-effective backup solution in another AWS Region. The application is running in warm standby mode and has Application Load Balancer (ALB) to support it from the front. The current failover process is manual and requires updating the DNS alias record to point to the secondary ALB in another Region in case of failure of the primary ALB.As a Solutions Architect, what will you recommend to automate the failover process?",B,B,Enable an ALB health check,Enable an Amazon Route 53 health check,Configure Trusted Advisor to check on unhealthy instances,Enable an EC2 instance health check,,,,한 스타트업이 다른 AWS 리전에서 비용 효율적인 백업 솔루션을 만들었습니다. 애플리케이션은 웜 대기 모드에서 실행 중이며 ALB(Application Load Balancer)가 전면에서 이를 지원합니다. 현재 장애 조치 프로세스는 수동이며 기본 ALB에 장애가 발생할 경우 다른 지역의 보조 ALB를 가리키도록 DNS 별칭 레코드를 업데이트해야 합니다.솔루션 설계자로서 장애 조치 프로세스를 자동화하기 위해 무엇을 권장하시겠습니까?,ALB 상태 확인 활성화,Amazon Route 53 상태 확인 활성화,비정상 인스턴스를 확인하도록 Trusted Advisor 구성,EC2 인스턴스 상태 확인 활성화,,,0,,
udemy,CLF-01,272,"An e-commerce company uses Amazon SQS queues to decouple their application architecture. The engineering team has observed message processing failures for some customer orders.As a solutions architect, which of the following solutions would you recommend for handling such message failures?",A,A,Use a dead-letter queue to handle message processing failures,Use short polling to handle message processing failures,Use long polling to handle message processing failures,Use a temporary queue to handle message processing failures,,,,전자상거래 회사는 Amazon SQS 대기열을 사용하여 애플리케이션 아키텍처를 분리합니다. 엔지니어링 팀은 일부 고객 주문에 대한 메시지 처리 실패를 관찰했습니다.솔루션 설계자로서 이러한 메시지 오류를 처리하기 위해 다음 중 어떤 솔루션을 권장하시겠습니까?,배달 못한 편지 대기열을 사용하여 메시지 처리 실패 처리,짧은 폴링을 사용하여 메시지 처리 실패 처리,긴 폴링을 사용하여 메시지 처리 실패 처리,임시 대기열을 사용하여 메시지 처리 실패 처리,,,0,,
udemy,CLF-01,273,"An e-commerce company uses a two-tier architecture with application servers in the public subnet and an RDS MySQL DB in a private subnet. The development team can use a bastion host in the public subnet to access the MySQL DB and run queries from the bastion host. However, end-users are reporting application errors. Upon inspecting application logs, the team notices several ""could not connect to server: connection timed out"" error messages.Which of the following options represent the root cause for this issue?",B,B,The security group configuration for the application servers does not have the correct rules to allow inbound connections from the DB instance,The security group configuration for the DB instance does not have the correct rules to allow inbound connections from the application servers,The database user credentials (username and password) configured for the application are incorrect,The database user credentials (username and password) configured for the application do not have the required privilege for the given database,,,,"전자 상거래 회사는 퍼블릭 서브넷에 애플리케이션 서버가 있고 프라이빗 서브넷에 RDS MySQL DB가 있는 2계층 아키텍처를 사용합니다. 개발 팀은 퍼블릭 서브넷의 배스천 호스트를 사용하여 MySQL DB에 액세스하고 배스천 호스트에서 쿼리를 실행할 수 있습니다. 그러나 최종 사용자는 애플리케이션 오류를 보고하고 있습니다. 애플리케이션 로그를 검사한 팀은 여러 ""서버에 연결할 수 없음: 연결 시간 초과"" 오류 메시지를 발견했습니다.다음 중 이 문제의 근본 원인을 나타내는 옵션은 무엇입니까?",애플리케이션 서버의 보안 그룹 구성에 DB 인스턴스로부터의 인바운드 연결을 허용하는 올바른 규칙이 없습니다.,DB 인스턴스의 보안 그룹 구성에 애플리케이션 서버로부터의 인바운드 연결을 허용하는 올바른 규칙이 없습니다.,응용 프로그램에 대해 구성된 데이터베이스 사용자 자격 증명(사용자 이름 및 암호)이 올바르지 않습니다.,응용 프로그램에 대해 구성된 데이터베이스 사용자 자격 증명(사용자 이름 및 암호)에 지정된 데이터베이스에 필요한 권한이 없습니다.,,,0,,
udemy,CLF-01,274,"An online gaming company wants to block access to its application from specific countries; however, the company wants to allow its remote development team (from one of the blocked countries) to have access to the application. The application is deployed on EC2 instances running under an Application Load Balancer (ALB) with AWS WAF.As a solutions architect, which of the following solutions can be combined to address the given use-case? (Select two)",BD,BD,Use ALB IP set statement that specifies the IP addresses that you want to allow through,Use WAF IP set statement that specifies the IP addresses that you want to allow through,Use ALB geo match statement listing the countries that you want to block,Use WAF geo match statement listing the countries that you want to block,Create a deny rule for the blocked countries in the NACL associated with each of the EC2 instances,,,온라인 게임 회사는 특정 국가에서 애플리케이션에 대한 액세스를 차단하려고 합니다. 그러나 회사는 원격 개발 팀(차단된 국가 중 하나에서 온)이 애플리케이션에 액세스할 수 있도록 허용하려고 합니다. 애플리케이션은 AWS WAF와 함께 ALB(Application Load Balancer)에서 실행되는 EC2 인스턴스에 배포됩니다.솔루션 아키텍트로서 다음 중 주어진 사용 사례를 해결하기 위해 결합할 수 있는 솔루션은 무엇입니까? (2개 선택),허용할 IP 주소를 지정하는 ALB IP set 문을 사용합니다.,허용할 IP 주소를 지정하는 WAF IP 집합 문을 사용합니다.,차단하려는 국가를 나열하는 ALB 지역 일치 문을 사용합니다.,차단하려는 국가를 나열하는 WAF 지역 일치 문을 사용하세요.,각 EC2 인스턴스와 연결된 NACL에서 차단된 국가에 대한 거부 규칙 생성,,0,,
udemy,CLF-01,275,"An Internet-of-Things (IoT) company is planning on distributing a master sensor in people's homes to measure the key metrics from its smart devices. In order to provide adjustment commands for these devices, the company would like to have a streaming system that supports ordered data based on the sensor's key, and also sustains high throughput messages (thousands of messages per second).As a solutions architect, which of the following AWS services would you recommend for this use-case?",C,C,Amazon Simple Notification Service (SNS),Amazon Simple Queue Service (SQS),Amazon Kinesis Data Streams (KDS),AWS Lambda,,,,IoT(Internet-of-Things) 회사는 스마트 장치의 주요 메트릭을 측정하기 위해 사람들의 가정에 마스터 센서를 배포할 계획입니다. 이러한 장치에 대한 조정 명령을 제공하기 위해 회사는 센서의 키를 기반으로 정렬된 데이터를 지원하고 높은 처리량 메시지(초당 수천 개의 메시지)를 유지하는 스트리밍 시스템을 갖기를 원합니다.솔루션 아키텍트로서 이 사용 사례에 대해 다음 AWS 서비스 중 어떤 것을 추천하시겠습니까?,Amazon 단순 알림 서비스(SNS),Amazon 단순 대기열 서비스(SQS),Amazon Kinesis 데이터 스트림(KDS),AWS 람다,,,0,,
udemy,CLF-01,276,A DevOps engineer at an organization is debugging issues related to an Amazon EC2 instance. The engineer has SSH'ed into the instance and he needs to retrieve the instance public IP from within a shell script running on the instance command line.Can you identify the correct URL path to get the instance public IP?,D,D,http://254.169.254.169/latest/meta-data/public-ipv4,http://169.254.169.254/latest/user-data/public-ipv4,http://254.169.254.169/latest/user-data/public-ipv4,http://169.254.169.254/latest/meta-data/public-ipv4,,,,조직의 DevOps 엔지니어가 Amazon EC2 인스턴스와 관련된 문제를 디버깅하고 있습니다. 엔지니어는 인스턴스에 SSH로 연결했으며 인스턴스 명령줄에서 실행되는 셸 스크립트 내에서 인스턴스 퍼블릭 IP를 검색해야 합니다.인스턴스 퍼블릭 IP를 얻기 위한 올바른 URL 경로를 식별할 수 있습니까?,http://254.169.254.169/latest/meta-data/public-ipv4,http://169.254.169.254/latest/user-data/public-ipv4,http://254.169.254.169/latest/user-data/public-ipv4,http://169.254.169.254/latest/meta-data/public-ipv4,,,0,,
udemy,CLF-01,277,"The infrastructure team at a company maintains 5 different VPCs (let's call these VPCs A, B, C, D, E) for resource isolation. Due to the changed organizational structure, the team wants to interconnect all VPCs together. To facilitate this, the team has set up VPC peering connections between VPC A and all other VPCs in a hub and spoke model with VPC A at the center. However, the team has still failed to establish connectivity between all VPCs.As a solutions architect, which of the following would you recommend as the MOST resource-efficient and scalable solution?",C,C,Use an internet gateway to interconnect the VPCs,Establish VPC peering connections between all VPCs,Use a transit gateway to interconnect the VPCs,Use a VPC endpoint to interconnect the VPCs,,,,"회사의 인프라 팀은 리소스 격리를 위해 5개의 서로 다른 VPC(이 VPC를 A, B, C, D, E라고 함)를 유지 관리합니다. 변경된 조직 구조로 인해 팀은 모든 VPC를 함께 상호 연결하려고 합니다. 이를 용이하게 하기 위해 팀은 VPC A가 중심에 있는 허브 및 스포크 모델에서 VPC A와 다른 모든 VPC 간에 VPC 피어링 연결을 설정했습니다. 그러나 팀은 여전히 ​​모든 VPC 간에 연결을 설정하지 못했습니다.솔루션 아키텍트로서 다음 중 가장 리소스 효율적이고 확장 가능한 솔루션으로 추천하는 솔루션은 무엇입니까?",인터넷 게이트웨이를 사용하여 VPC 상호 연결,모든 VPC 간에 VPC 피어링 연결 설정,전송 게이트웨이를 사용하여 VPC 상호 연결,VPC 종단점을 사용하여 VPC 상호 연결,,,0,,
udemy,CLF-01,278,"A solutions architect has been tasked to design a low-latency solution for a static, single-page application, accessed by users through a custom domain name. The solution must be serverless, provide in-transit data encryption and needs to be cost-effective.Which AWS services can be combined to build the simplest possible solution for the company's requirement?",A,A,Use Amazon S3 to host the static website and Amazon CloudFront to distribute the content for low latency access,Host the application on Amazon EC2 instance with instance store volume for high performance and low latency access to users,Host the application on AWS Fargate and front it with an Elastic Load Balancer for an improved performance,Configure Amazon S3 to store the static data and use AWS Fargate for hosting the application,,,,솔루션 설계자는 사용자 지정 도메인 이름을 통해 사용자가 액세스하는 정적 단일 페이지 애플리케이션을 위한 대기 시간이 짧은 솔루션을 설계하는 임무를 받았습니다. 솔루션은 서버리스여야 하며 전송 중 데이터 암호화를 제공하고 비용 효율적이어야 합니다.회사의 요구 사항에 가장 간단한 솔루션을 구축하기 위해 결합할 수 있는 AWS 서비스는 무엇입니까?,Amazon S3를 사용하여 정적 웹 사이트를 호스팅하고 Amazon CloudFront를 사용하여 지연 시간이 짧은 액세스를 위해 콘텐츠를 배포합니다.,고성능 및 사용자에 대한 짧은 대기 시간 액세스를 위해 인스턴스 스토어 볼륨이 있는 Amazon EC2 인스턴스에서 애플리케이션 호스팅,성능 향상을 위해 AWS Fargate에서 애플리케이션을 호스팅하고 Elastic Load Balancer로 전면에 배치,정적 데이터를 저장하고 애플리케이션 호스팅에 AWS Fargate를 사용하도록 Amazon S3를 구성합니다.,,,0,,
udemy,CLF-01,279,"A mobile chat application uses DynamoDB as its database service to provide low latency chat updates. A new developer has joined the team and is reviewing the configuration settings for DynamoDB which have been tweaked for certain technical requirements. CloudTrail service has been enabled on all the resources used for the project. Yet, DynamoDB encryption details are nowhere to be found.Which of the following options can explain the root cause for the given issue?",B,B,"By default, all DynamoDB tables are encrypted using Data keys, which do not write to CloudTrail logs","By default, all DynamoDB tables are encrypted under an AWS owned customer master key (CMK), which do not write to CloudTrail logs","By default, all DynamoDB tables are encrypted under Customer managed CMKs, which do not write to CloudTrail logs","By default, all DynamoDB tables are encrypted under AWS managed CMKs, which do not write to CloudTrail logs",,,,모바일 채팅 애플리케이션은 DynamoDB를 데이터베이스 서비스로 사용하여 지연 시간이 짧은 채팅 업데이트를 제공합니다. 새로운 개발자가 팀에 합류하여 특정 기술 요구 사항에 맞게 조정된 DynamoDB의 구성 설정을 검토하고 있습니다. 프로젝트에 사용된 모든 리소스에서 CloudTrail 서비스가 활성화되었습니다. 그러나 DynamoDB 암호화 세부 정보는 어디에도 없습니다.다음 옵션 중 주어진 문제의 근본 원인을 설명할 수 있는 것은 무엇입니까?,기본적으로 모든 DynamoDB 테이블은 CloudTrail 로그에 쓰지 않는 데이터 키를 사용하여 암호화됩니다.,기본적으로 모든 DynamoDB 테이블은 CloudTrail 로그에 쓰지 않는 AWS 소유 고객 마스터 키(CMK)로 암호화됩니다.,기본적으로 모든 DynamoDB 테이블은 CloudTrail 로그에 쓰지 않는 고객 관리형 CMK로 암호화됩니다.,기본적으로 모든 DynamoDB 테이블은 CloudTrail 로그에 쓰지 않는 AWS 관리형 CMK로 암호화됩니다.,,,0,,
udemy,CLF-01,280,"A company hires experienced specialists to analyze the customer service calls attended by its call center representatives. Now, the company wants to move to AWS Cloud and is looking at an automated solution to analyze customer service calls for sentiment analysis via ad-hoc SQL queries.As a Solutions Architect, which of the following solutions would you recommend?",D,D,Use Kinesis Data Streams to read the audio files and Amazon Alexa to convert them into text. Kinesis Data Analytics can be used to analyze these files and Amazon Quicksight can be used to visualize and display the output,Use Amazon Transcribe to convert audio files to text and Amazon Quicksight to run analysis on these text files to understand the underlying patterns. Visualize and display them onto user Dashboards for human analysis,Use Kinesis Data Streams to read the audio files and machine learning (ML) algorithms to convert the audio files into text and run customer sentiment analysis,Use Amazon Transcribe to convert audio files to text and Amazon Athena to understand the underlying customer sentiments,,,,회사는 경험이 풍부한 전문가를 고용하여 콜센터 담당자가 참석한 고객 서비스 통화를 분석합니다. 이제 이 회사는 AWS 클라우드로 이동하기를 원하며 애드혹 SQL 쿼리를 통해 감정 분석을 위한 고객 서비스 호출을 분석하는 자동화된 솔루션을 찾고 있습니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 추천하시겠습니까?,Kinesis Data Streams를 사용하여 오디오 파일을 읽고 Amazon Alexa를 사용하여 텍스트로 변환합니다. Kinesis Data Analytics를 사용하여 이러한 파일을 분석하고 Amazon Quicksight를 사용하여 출력을 시각화하고 표시할 수 있습니다.,Amazon Transcribe를 사용하여 오디오 파일을 텍스트로 변환하고 Amazon Quicksight를 사용하여 이러한 텍스트 파일에 대한 분석을 실행하여 기본 패턴을 이해합니다. 인적 분석을 위해 사용자 대시보드에 시각화 및 표시,Kinesis Data Streams를 사용하여 오디오 파일을 읽고 기계 학습(ML) 알고리즘을 사용하여 오디오 파일을 텍스트로 변환하고 고객 감정 분석을 실행합니다.,Amazon Transcribe를 사용하여 오디오 파일을 텍스트로 변환하고 Amazon Athena를 사용하여 근본적인 고객 감정 이해,,,0,,
udemy,CLF-01,281,"A financial services company runs its flagship web application on AWS. The application serves thousands of users during peak hours. The company needs a scalable near-real-time solution to share hundreds of thousands of financial transactions with multiple internal applications. The solution should also remove sensitive details from the transactions before storing the cleansed transactions in a document database for low-latency retrieval.As an AWS Certified Solutions Architect Associate, which of the following would you recommend?",A,A,Feed the streaming transactions into Amazon Kinesis Data Streams. Leverage Amazon Lambda integration to remove sensitive data from every transaction and then store the cleansed transactions in DynamoDB. The internal applications can consume the raw transactions off the Kinesis Data Stream,Persist the raw transactions into Amazon DynamoDB. Configure a rule in DynamoDB to update the transaction by removing sensitive data whenever any new raw transaction is written. Leverage DynamoDB Streams to share the transactions data with the internal applications,Batch process the raw transactions data into Amazon S3 flat files. Use S3 events to trigger an Amazon Lambda function to remove sensitive data from the raw transactions in the flat file and then store the cleansed transactions in DynamoDB. Leverage DynamoDB Streams to share the transactions data with the internal applications,Feed the streaming transactions into Amazon Kinesis Data Firehose. Leverage Amazon Lambda integration to remove sensitive data from every transaction and then store the cleansed transactions in DynamoDB. The internal applications can consume the raw transactions off the Kinesis Data Firehose,,,,금융 서비스 회사는 AWS에서 주력 웹 애플리케이션을 실행합니다. 이 응용 프로그램은 피크 시간 동안 수천 명의 사용자에게 서비스를 제공합니다. 이 회사는 수십만 건의 금융 거래를 여러 내부 애플리케이션과 공유하기 위해 확장 가능한 실시간에 가까운 솔루션이 필요합니다. 솔루션은 짧은 대기 시간 검색을 위해 정리된 트랜잭션을 문서 데이터베이스에 저장하기 전에 트랜잭션에서 중요한 세부 정보도 제거해야 합니다.AWS 공인 솔루션스 아키텍트 어소시에이트로서 다음 중 무엇을 추천하시겠습니까?,스트리밍 트랜잭션을 Amazon Kinesis Data Streams에 피드합니다. Amazon Lambda 통합을 활용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 정리된 트랜잭션을 DynamoDB에 저장합니다. 내부 애플리케이션은 Kinesis Data Stream에서 원시 트랜잭션을 사용할 수 있습니다.,원시 트랜잭션을 Amazon DynamoDB에 유지합니다. 새로운 원시 트랜잭션이 기록될 때마다 중요한 데이터를 제거하여 트랜잭션을 업데이트하도록 DynamoDB에서 규칙을 구성합니다. DynamoDB Streams를 활용하여 내부 애플리케이션과 트랜잭션 데이터 공유,원시 트랜잭션 데이터를 Amazon S3 플랫 파일로 일괄 처리합니다. S3 이벤트를 사용하여 Amazon Lambda 함수를 트리거하여 플랫 파일의 원시 트랜잭션에서 민감한 데이터를 제거한 다음 정리된 트랜잭션을 DynamoDB에 저장합니다. DynamoDB Streams를 활용하여 내부 애플리케이션과 트랜잭션 데이터 공유,스트리밍 트랜잭션을 Amazon Kinesis Data Firehose에 피드합니다. Amazon Lambda 통합을 활용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 정리된 트랜잭션을 DynamoDB에 저장합니다. 내부 애플리케이션은 Kinesis Data Firehose에서 원시 트랜잭션을 사용할 수 있습니다.,,,0,,
udemy,CLF-01,282,A retail company maintains a Direct Connect connection to AWS and has recently migrated its data warehouse to AWS. The data analysts at the company query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 60 MB and the query responses returned by the data warehouse are not cached in the visualization tool. Each webpage returned by the visualization tool is approximately 600 KB.Which of the following options offers the LOWEST data transfer egress cost for the company?,A,A,Deploy the visualization tool in the same AWS region as the data warehouse. Access the visualization tool over a Direct Connect connection at a location in the same region,Deploy the visualization tool on-premises. Query the data warehouse over the internet at a location in the same AWS region,Deploy the visualization tool on-premises. Query the data warehouse directly over a Direct Connect connection at a location in the same AWS region,Deploy the visualization tool in the same AWS region as the data warehouse. Access the visualization tool over the internet at a location in the same region,,,,소매 회사는 AWS에 대한 Direct Connect 연결을 유지하고 있으며 최근 데이터 웨어하우스를 AWS로 마이그레이션했습니다. 회사의 데이터 분석가는 시각화 도구를 사용하여 데이터 웨어하우스를 쿼리합니다. 데이터 웨어하우스에서 반환된 쿼리의 평균 크기는 60MB이며 데이터 웨어하우스에서 반환된 쿼리 응답은 시각화 도구에 캐시되지 않습니다. 시각화 도구에서 반환되는 각 웹 페이지는 약 600KB입니다.다음 중 회사에 가장 낮은 데이터 전송 송신 비용을 제공하는 옵션은 무엇입니까?,데이터 웨어하우스와 동일한 AWS 지역에 시각화 도구를 배포합니다. 동일한 지역의 위치에서 Direct Connect 연결을 통해 시각화 도구에 액세스,온프레미스에 시각화 도구를 배포합니다. 동일한 AWS 지역의 위치에서 인터넷을 통해 데이터 웨어하우스 쿼리,온프레미스에 시각화 도구를 배포합니다. 동일한 AWS 지역의 위치에서 Direct Connect 연결을 통해 직접 데이터 웨어하우스 쿼리,데이터 웨어하우스와 동일한 AWS 지역에 시각화 도구를 배포합니다. 동일한 지역의 위치에서 인터넷을 통해 시각화 도구에 액세스,,,0,,
udemy,CLF-01,283,"A health-care company manages its web application on Amazon EC2 instances running behind Auto Scaling group (ASG). The company provides ambulances for critical patients and needs the application to be reliable. The workload of the company can be managed on 2 EC2 instances and can peak up to 6 instances when traffic increases.As a Solutions Architect, which of the following configurations would you select as the best fit for these requirements?",B,B,"The ASG should be configured with the minimum capacity set to 4, with 2 instances each in two different AWS Regions. The maximum capacity of the ASG should be set to 6","The ASG should be configured with the minimum capacity set to 4, with 2 instances each in two different Availability Zones. The maximum capacity of the ASG should be set to 6",The ASG should be configured with the minimum capacity set to 2 and the maximum capacity set to 6 in a single Availability Zone,"The ASG should be configured with the minimum capacity set to 2, with 1 instance each in two different Availability Zones. The maximum capacity of the ASG should be set to 6",,,,의료 회사는 ASG(Auto Scaling 그룹) 뒤에서 실행되는 Amazon EC2 인스턴스에서 웹 애플리케이션을 관리합니다. 이 회사는 중환자에게 구급차를 제공하며 신뢰할 수 있는 애플리케이션이 필요합니다. 회사의 작업량은 2개의 EC2 인스턴스에서 관리할 수 있으며 트래픽이 증가하면 최대 6개의 인스턴스까지 피크가 될 수 있습니다.솔루션 아키텍트로서 다음 중 이러한 요구 사항에 가장 적합한 구성은 무엇입니까?,ASG는 서로 다른 두 AWS 리전에 각각 2개의 인스턴스가 있는 최소 용량을 4로 설정하여 구성해야 합니다. ASG의 최대 용량은 6으로 설정해야 합니다.,ASG는 서로 다른 2개의 가용 영역에 각각 2개의 인스턴스가 있는 최소 용량을 4로 설정하여 구성해야 합니다. ASG의 최대 용량은 6으로 설정해야 합니다.,ASG는 단일 가용 영역에서 최소 용량을 2로 설정하고 최대 용량을 6으로 설정하여 구성해야 합니다.,ASG는 서로 다른 2개의 가용 영역에 각각 1개의 인스턴스가 있는 최소 용량을 2로 설정하여 구성해야 합니다. ASG의 최대 용량은 6으로 설정해야 합니다.,,,0,,
udemy,CLF-01,284,"Reporters at a news agency upload/download video files (about 500MB each) to/from an S3 bucket as part of their daily work. As the agency has started offices in remote locations, it has resulted in poor latency for uploading and accessing data to/from the given S3 bucket. The agency wants to continue using a serverless storage solution such as S3 but wants to improve the performance.As a solutions architect, which of the following solutions do you propose to address this issue? (Select two)",AE,AE,Enable Amazon S3 Transfer Acceleration for the S3 bucket. This would speed up uploads as well as downloads for the video files,"Create new S3 buckets in every region where the agency has a remote office, so that each office can maintain its storage for the media assets","Move S3 data into EFS file system created in a US region, connect to EFS file system from EC2 instances in other AWS regions using an inter-region VPC peering connection",Spin up EC2 instances in each region where the agency has a remote office. Create a daily job to transfer S3 data into EBS volumes attached to the EC2 instances,Use Amazon CloudFront distribution with origin as the S3 bucket. This would speed up uploads as well as downloads for the video files,,,뉴스 에이전시의 기자들은 일상 업무의 일부로 비디오 파일(각각 약 500MB)을 S3 버킷에 업로드/다운로드합니다. 기관이 원격 위치에서 사무실을 시작했기 때문에 지정된 S3 버킷에서 데이터를 업로드하고 데이터에 액세스하는 데 지연 시간이 짧아졌습니다. 에이전시는 S3와 같은 서버리스 스토리지 솔루션을 계속 사용하고 싶지만 성능을 개선하고자 합니다.솔루션 설계자로서 다음 중 이 문제를 해결하기 위해 제안하는 솔루션은 무엇입니까? (2개 선택),S3 버킷에 대해 Amazon S3 Transfer Acceleration을 활성화합니다. 이렇게 하면 비디오 파일의 업로드 및 다운로드 속도가 빨라집니다.,에이전시에 원격 사무실이 있는 모든 지역에 새 S3 버킷을 생성하여 각 사무실이 미디어 자산에 대한 스토리지를 유지할 수 있도록 합니다.,"미국 리전에서 생성된 EFS 파일 시스템으로 S3 데이터 이동, 리전 간 VPC 피어링 연결을 사용하여 다른 AWS 리전의 EC2 인스턴스에서 EFS 파일 시스템에 연결",에이전시에 원격 사무실이 있는 각 지역에서 EC2 인스턴스를 가동합니다. S3 데이터를 EC2 인스턴스에 연결된 EBS 볼륨으로 전송하는 일일 작업 생성,원본과 함께 Amazon CloudFront 배포를 S3 버킷으로 사용합니다. 이렇게 하면 비디오 파일의 업로드 및 다운로드 속도가 빨라집니다.,,0,,
udemy,CLF-01,285,An application hosted on Amazon EC2 contains sensitive personal information about all its customers and needs to be protected from all types of cyber-attacks. The company is considering using the AWS Web Application Firewall (WAF) to handle this requirement.Can you identify the correct solution leveraging the capabilities of WAF?,D,D,AWS WAF can be directly configured on Amazon EC2 instances for ensuring the security of the underlying application data,Configure an ALB to balance the workload for all the EC2 instances. Configure CloudFront to distribute from an ALB since WAF cannot be directly configured on ALBs. This configuration not only provides necessary safety but is scalable too,AWS WAF can be directly configured only on an ALB or an Amazon API Gateway. One of these two services can then be configured with Amazon EC2 to build the needed secure architecture,Create a CloudFront distribution for the application on Amazon EC2 instances. Deploy AWS WAF on Amazon CloudFront to provide the necessary safety measures,,,,Amazon EC2에서 호스팅되는 애플리케이션에는 모든 고객에 대한 민감한 개인 정보가 포함되어 있으며 모든 유형의 사이버 공격으로부터 보호되어야 합니다. 이 회사는 이 요구 사항을 처리하기 위해 AWS 웹 애플리케이션 방화벽(WAF)을 사용하는 것을 고려하고 있습니다.WAF의 기능을 활용하는 올바른 솔루션을 식별할 수 있습니까?,AWS WAF는 기본 애플리케이션 데이터의 보안을 보장하기 위해 Amazon EC2 인스턴스에서 직접 구성할 수 있습니다.,모든 EC2 인스턴스에 대한 워크로드의 균형을 맞추도록 ALB를 구성합니다. WAF는 ALB에서 직접 구성할 수 없으므로 ALB에서 배포하도록 CloudFront를 구성합니다. 이 구성은 필요한 안전을 제공할 뿐만 아니라 확장 가능합니다.,AWS WAF는 ALB 또는 Amazon API Gateway에서만 직접 구성할 수 있습니다. 그런 다음 이 두 서비스 중 하나를 Amazon EC2로 구성하여 필요한 보안 아키텍처를 구축할 수 있습니다.,Amazon EC2 인스턴스에서 애플리케이션용 CloudFront 배포를 생성합니다. Amazon CloudFront에 AWS WAF를 배포하여 필요한 안전 조치 제공,,,0,,
udemy,CLF-01,286,A DevOps engineer at an IT company was recently added to the admin group of the company's AWS account. The AdministratorAccess managed policy is attached to this group.Can you identify the AWS tasks that the DevOps engineer CANNOT perform even though he has full Administrator privileges (Select two)?,AD,AD,Configure an Amazon S3 bucket to enable MFA (Multi Factor Authentication) delete,Delete the IAM user for his manager,Delete an S3 bucket from the production environment,Close the company's AWS account,Change the password for his own IAM user account,,,IT 회사의 DevOps 엔지니어가 최근 회사 AWS 계정의 관리자 그룹에 추가되었습니다. 관리 AdministratorAccess형 정책이 이 그룹에 연결됩니다.전체 관리자 권한(2개 선택)이 있어도 DevOps 엔지니어가 수행할 수 없는 AWS 작업을 식별할 수 있습니까?,MFA(Multi Factor Authentication) 삭제를 활성화하도록 Amazon S3 버킷 구성,관리자의 IAM 사용자 삭제,프로덕션 환경에서 S3 버킷 삭제,회사의 AWS 계정 폐쇄,자신의 IAM 사용자 계정에 대한 비밀번호 변경,,0,,
udemy,CLF-01,287,"The engineering team at a retail company manages 3 Amazon EC2 instances that make read-heavy database requests to the Amazon RDS for the PostgreSQL DB instance. As an AWS Certified Solutions Architect Associate, you have been tasked to make the database instance resilient from a disaster recovery perspective.Which of the following features will help you in disaster recovery of the database? (Select two)",AE,AE,Enable the automated backup feature of Amazon RDS in a multi-AZ deployment that creates backups across multiple Regions,Enable the automated backup feature of Amazon RDS in a multi-AZ deployment that creates backups in a single AWS Region,Use the database cloning feature of the RDS DB cluster,Use RDS Provisioned IOPS (SSD) Storage in place of General Purpose (SSD) Storage,Use cross-Region Read Replicas,,,소매 회사의 엔지니어링 팀은 PostgreSQL DB 인스턴스용 Amazon RDS에 대한 읽기 작업이 많은 데이터베이스 요청을 만드는 3개의 Amazon EC2 인스턴스를 관리합니다. AWS 공인 솔루션스 아키텍트 어소시에이트로서 귀하는 재해 복구 관점에서 데이터베이스 인스턴스를 탄력적으로 만드는 임무를 받았습니다.다음 중 데이터베이스 재해 복구에 도움이 되는 기능은 무엇입니까? (2개 선택),여러 지역에 걸쳐 백업을 생성하는 다중 AZ 배포에서 Amazon RDS의 자동 백업 기능 활성화,단일 AWS 리전에서 백업을 생성하는 다중 AZ 배포에서 Amazon RDS의 자동 백업 기능 활성화,RDS DB 클러스터의 데이터베이스 복제 기능 사용,범용(SSD) 스토리지 대신 RDS 프로비저닝된 IOPS(SSD) 스토리지 사용,리전 간 읽기 전용 복제본 사용,,0,,
udemy,CLF-01,288,Which of the following is true regarding cross-zone load balancing as seen in Application Load Balancer versus Network Load Balancer?,C,C,"By default, cross-zone load balancing is disabled for Application Load Balancer and enabled for Network Load Balancer","By default, cross-zone load balancing is disabled for both Application Load Balancer and Network Load Balancer","By default, cross-zone load balancing is enabled for Application Load Balancer and disabled for Network Load Balancer","By default, cross-zone load balancing is enabled for both Application Load Balancer and Network Load Balancer",,,,Application Load Balancer와 Network Load Balancer에서 볼 수 있는 교차 영역 로드 밸런싱과 관련하여 다음 중 참인 것은 무엇입니까?,기본적으로 교차 영역 로드 밸런싱은 Application Load Balancer에 대해 비활성화되고 Network Load Balancer에 대해 활성화됩니다.,기본적으로 교차 영역 로드 밸런싱은 Application Load Balancer와 Network Load Balancer 모두에 대해 비활성화되어 있습니다.,기본적으로 교차 영역 로드 밸런싱은 Application Load Balancer에 대해 활성화되고 Network Load Balancer에 대해 비활성화됩니다.,기본적으로 교차 영역 로드 밸런싱은 Application Load Balancer와 Network Load Balancer 모두에 대해 활성화됩니다.,,,0,,
udemy,CLF-01,289,A cyber security company is running a mission critical application using a single Spread placement group of EC2 instances. The company needs 15 Amazon EC2 instances for optimal performance.How many Availability Zones (AZs) will the company need to deploy these EC2 instances per the given use-case?,D,D,15,7,14,3,,,,사이버 보안 회사는 EC2 인스턴스의 단일 Spread 배치 그룹을 사용하여 미션 크리티컬 애플리케이션을 실행하고 있습니다. 회사는 최적의 성능을 위해 15개의 Amazon EC2 인스턴스가 필요합니다.회사는 주어진 사용 사례별로 이러한 EC2 인스턴스를 배포하는 데 몇 개의 가용 영역(AZ)이 필요합니까?,15,7,14,삼,,,0,,
udemy,CLF-01,290,"A company needs a massive PostgreSQL database and the engineering team would like to retain control over managing the patches, version upgrades for the database, and consistent performance with high IOPS. The team wants to install the database on an EC2 instance with the optimal storage type on the attached EBS volume.As a solutions architect, which of the following configurations would you suggest to the engineering team?",A,A,Amazon EC2 with EBS volume of Provisioned IOPS SSD (io1) type,Amazon EC2 with EBS volume of Throughput Optimized HDD (st1) type,Amazon EC2 with EBS volume of cold HDD (sc1) type,Amazon EC2 with EBS volume of General Purpose SSD (gp2) type,,,,"회사는 대규모 PostgreSQL 데이터베이스가 필요하고 엔지니어링 팀은 패치 관리, 데이터베이스 버전 업그레이드 및 높은 IOPS로 일관된 성능을 제어하기를 원합니다. 팀은 연결된 EBS 볼륨에 최적의 스토리지 유형으로 EC2 인스턴스에 데이터베이스를 설치하려고 합니다.솔루션 설계자로서 다음 중 엔지니어링 팀에 제안할 구성은 무엇입니까?",프로비저닝된 IOPS SSD(io1) 유형의 EBS 볼륨이 있는 Amazon EC2,처리량 최적화 HDD(st1) 유형의 EBS 볼륨이 포함된 Amazon EC2,콜드 HDD(sc1) 유형의 EBS 볼륨이 포함된 Amazon EC2,범용 SSD(gp2) 유형의 EBS 볼륨이 포함된 Amazon EC2,,,0,,
udemy,CLF-01,291,"Your firm has implemented a multi-tiered networking structure within the VPC - with two public and two private subnets. The public subnets are used to deploy the Application Load Balancers, while the two private subnets are used to deploy the application on Amazon EC2 instances. The development team wants the EC2 instances to have access to the internet. The solution has to be fully managed by AWS and needs to work over IPv4.What will you recommend?",C,C,Internet Gateways deployed in your private subnet,Egress-Only Internet Gateways deployed in your private subnet,NAT Gateways deployed in your public subnet,NAT Instances deployed in your public subnet,,,,귀하의 회사는 VPC 내에 2개의 퍼블릭 서브넷과 2개의 프라이빗 서브넷이 있는 다중 계층 네트워킹 구조를 구현했습니다. 퍼블릭 서브넷은 Application Load Balancer를 배포하는 데 사용되는 반면 두 개의 프라이빗 서브넷은 Amazon EC2 인스턴스에 애플리케이션을 배포하는 데 사용됩니다. 개발 팀은 EC2 인스턴스가 인터넷에 액세스할 수 있기를 원합니다. 솔루션은 AWS에서 완전히 관리해야 하며 IPv4를 통해 작동해야 합니다.무엇을 추천하시겠습니까?,프라이빗 서브넷에 배포된 인터넷 게이트웨이,프라이빗 서브넷에 배포된 외부 전용 인터넷 게이트웨이,퍼블릭 서브넷에 배포된 NAT 게이트웨이,퍼블릭 서브넷에 배포된 NAT 인스턴스,,,0,,
udemy,CLF-01,292,"A company wants to store business-critical data on EBS volumes which provide persistent storage independent of EC2 instances. During a test run, the development team found that on terminating an EC2 instance, the attached EBS volume was also lost, which was contrary to their assumptions.As a solutions architect, could you explain this issue?",D,D,"The EBS volumes were not backed up on EFS file system storage, resulting in the loss of volume","On termination of an EC2 instance, all the attached EBS volumes are always terminated","The EBS volumes were not backed up on Amazon S3 storage, resulting in the loss of volume","The EBS volume was configured as the root volume of Amazon EC2 instance. On termination of the instance, the default behavior is to also terminate the attached root volume",,,,"회사는 EC2 인스턴스와 독립적인 영구 스토리지를 제공하는 EBS 볼륨에 비즈니스 크리티컬 데이터를 저장하려고 합니다. 테스트 실행 중에 개발 팀은 EC2 인스턴스를 종료할 때 연결된 EBS 볼륨도 손실된다는 사실을 발견했는데, 이는 그들의 가정과 상반됩니다.솔루션 아키텍트로서 이 문제를 설명해 주시겠습니까?",EBS 볼륨이 EFS 파일 시스템 스토리지에 백업되지 않아 볼륨이 손실됨,EC2 인스턴스가 종료되면 연결된 모든 EBS 볼륨이 항상 종료됩니다.,EBS 볼륨이 Amazon S3 스토리지에 백업되지 않아 볼륨 손실이 발생했습니다.,EBS 볼륨은 Amazon EC2 인스턴스의 루트 볼륨으로 구성되었습니다. 인스턴스 종료 시 기본 동작은 연결된 루트 볼륨도 종료하는 것입니다.,,,0,,
udemy,CLF-01,293,"A medium-sized business has a taxi dispatch application deployed on an EC2 instance. Because of an unknown bug, the application causes the instance to freeze regularly. Then, the instance has to be manually restarted via the AWS management console.Which of the following is the MOST cost-optimal and resource-efficient way to implement an automated solution until a permanent fix is delivered by the development team?",D,D,Use EventBridge events to trigger a Lambda function to reboot the instance status every 5 minutes,"Setup a CloudWatch alarm to monitor the health status of the instance. In case of an Instance Health Check failure, CloudWatch Alarm can publish to an SNS event which can then trigger a lambda function. The lambda function can use AWS EC2 API to reboot the instance","Use EventBridge events to trigger a Lambda function to check the instance status every 5 minutes. In the case of Instance Health Check failure, the lambda function can use AWS EC2 API to reboot the instance","Setup a CloudWatch alarm to monitor the health status of the instance. In case of an Instance Health Check failure, an EC2 Reboot CloudWatch Alarm Action can be used to reboot the instance",,,,중간 규모의 비즈니스에는 EC2 인스턴스에 배포된 택시 배차 애플리케이션이 있습니다. 알 수 없는 버그로 인해 애플리케이션으로 인해 인스턴스가 정기적으로 중지됩니다. 그런 다음 AWS 관리 콘솔을 통해 인스턴스를 수동으로 다시 시작해야 합니다.다음 중 개발 팀에서 영구적인 수정 사항을 제공할 때까지 자동화된 솔루션을 구현하는 가장 비용 최적화되고 리소스 효율적인 방법은 무엇입니까?,EventBridge 이벤트를 사용하여 5분마다 인스턴스 상태를 재부팅하는 Lambda 함수 트리거,인스턴스의 상태를 모니터링하도록 CloudWatch 경보를 설정합니다. 인스턴스 상태 확인에 실패하는 경우 CloudWatch 경보는 람다 기능을 트리거할 수 있는 SNS 이벤트에 게시할 수 있습니다. Lambda 함수는 AWS EC2 API를 사용하여 인스턴스를 재부팅할 수 있습니다.,EventBridge 이벤트를 사용하여 5분마다 인스턴스 상태를 확인하는 Lambda 함수를 트리거합니다. 인스턴스 상태 확인에 실패한 경우 Lambda 함수는 AWS EC2 API를 사용하여 인스턴스를 재부팅할 수 있습니다.,인스턴스의 상태를 모니터링하도록 CloudWatch 경보를 설정합니다. 인스턴스 상태 확인에 실패한 경우 EC2 재부팅 CloudWatch 경보 작업을 사용하여 인스턴스를 재부팅할 수 있습니다.,,,0,,
udemy,CLF-01,294,An application with global users across AWS Regions had suffered an issue when the Elastic Load Balancer (ELB) in a Region malfunctioned thereby taking down the traffic with it. The manual intervention cost the company significant time and resulted in major revenue loss.What should a solutions architect recommend to reduce internet latency and add automatic failover across AWS Regions?,B,B,Set up AWS Direct Connect as the backbone for each of the AWS Regions where the application is deployed,Set up AWS Global Accelerator and add endpoints to cater to users in different geographic locations,Create S3 buckets in different AWS Regions and configure CloudFront to pick the nearest edge location to the user,Set up an Amazon Route 53 geoproximity routing policy to route traffic,,,,AWS 리전 전체에 걸쳐 글로벌 사용자가 있는 애플리케이션에서 리전의 Elastic Load Balancer(ELB)가 오작동하여 트래픽이 중단되는 문제가 발생했습니다. 수동 개입으로 인해 회사는 상당한 시간이 소요되었고 막대한 수익 손실이 발생했습니다.인터넷 지연 시간을 줄이고 AWS 리전 전체에 자동 장애 조치를 추가하려면 솔루션 설계자가 무엇을 권장해야 합니까?,애플리케이션이 배포되는 각 AWS 리전의 백본으로 AWS Direct Connect 설정,AWS Global Accelerator를 설정하고 엔드포인트를 추가하여 서로 다른 지리적 위치에 있는 사용자를 수용합니다.,서로 다른 AWS 리전에서 S3 버킷을 생성하고 사용자에게 가장 가까운 엣지 로케이션을 선택하도록 CloudFront를 구성합니다.,Amazon Route 53 지리 근접 라우팅 정책을 설정하여 트래픽 라우팅,,,0,,
udemy,CLF-01,295,"Your company is evolving towards a microservice approach for their website. The company plans to expose the website from the same load balancer, linked to different target groups with different URLs, that are similar to these - checkout.mycorp.com, www.mycorp.com, mycorp.com/profile, and mycorp.com/search.As a Solutions Architect, which Load Balancer type do you recommend to achieve this routing feature with MINIMUM configuration and development effort?",D,D,Create a Classic Load Balancer,Create an NGINX based load balancer on an EC2 instance to have advanced routing capabilities,Create a Network Load Balancer,Create an Application Load Balancer,,,,"귀하의 회사는 웹 사이트에 대한 마이크로 서비스 접근 방식으로 발전하고 있습니다. 회사는 checkout.mycorp.com, www.mycorp.com, mycorp.com/profile 및 mycorp.com과 유사한 URL이 다른 여러 대상 그룹에 연결된 동일한 로드 밸런서에서 웹 사이트를 노출할 계획입니다. /찾다.솔루션 아키텍트로서 최소한의 구성 및 개발 노력으로 이 라우팅 기능을 달성하기 위해 권장하는 로드 밸런서 유형은 무엇입니까?",클래식 로드 밸런서 생성,고급 라우팅 기능을 사용하려면 EC2 인스턴스에 NGINX 기반 로드 밸런서를 생성하십시오.,네트워크 로드 밸런서 생성,애플리케이션 로드 밸런서 생성,,,0,,
udemy,CLF-01,296,"A company is looking for a technology that allows its mobile app users to connect through a Google login and have the capability to turn on MFA (Multi-Factor Authentication) to have maximum security. Ideally, the solution should be fully managed by AWS.Which technology do you recommend for managing the users' accounts?",B,B,Enable the AWS Google Login Service,Amazon Cognito,Write a Lambda function with Auth0 3rd party integration,AWS Identity and Access Management (IAM),,,,회사는 모바일 앱 사용자가 Google 로그인을 통해 연결할 수 있고 최대 보안을 위해 MFA(Multi-Factor Authentication)를 켤 수 있는 기술을 찾고 있습니다. 이상적으로는 솔루션이 AWS에서 완전히 관리되어야 합니다.사용자 계정 관리를 위해 어떤 기술을 권장합니까?,AWS Google 로그인 서비스 활성화,아마존 코그니토,Auth0 타사 통합으로 Lambda 함수 작성,AWS 자격 증명 및 액세스 관리(IAM),,,0,,
udemy,CLF-01,297,"An Internet-of-Things (IoT) company is looking for a database solution on AWS Cloud that has Auto Scaling capabilities and is highly available. The database should be able to handle any changes in data attributes over time, in case the company updates the data feed from its IoT devices. The database must provide the capability to output a continuous stream with details of any changes to the underlying data.As a Solutions Architect, which database will you recommend?",C,C,Amazon Relational Database Service (Amazon RDS),Amazon Aurora,Amazon DynamoDB,Amazon Redshift,,,,사물 인터넷(IoT) 회사는 Auto Scaling 기능이 있고 가용성이 높은 AWS 클라우드의 데이터베이스 솔루션을 찾고 있습니다. 데이터베이스는 회사가 IoT 장치에서 데이터 피드를 업데이트하는 경우 시간이 지남에 따라 데이터 속성의 모든 변경 사항을 처리할 수 있어야 합니다. 데이터베이스는 기본 데이터에 대한 변경 사항에 대한 세부 정보가 포함된 연속 스트림을 출력하는 기능을 제공해야 합니다.솔루션 설계자로서 어떤 데이터베이스를 추천하시겠습니까?,Amazon 관계형 데이터베이스 서비스(Amazon RDS),Amazon Aurora,아마존 다이나모DB,아마존 레드시프트,,,0,,
udemy,CLF-01,298,"A developer in your team has set up a classic 3 tier architecture composed of an Application Load Balancer, an Auto Scaling group managing a fleet of EC2 instances, and an Aurora database. As a Solutions Architect, you would like to adhere to the security pillar of the well-architected framework.How do you configure the security group of the Aurora database to only allow traffic coming from the EC2 instances?",C,C,Add a rule authorizing the ELB security group,Add a rule authorizing the Aurora security group,Add a rule authorizing the EC2 security group,Add a rule authorizing the ASG's subnets CIDR,,,,"팀의 개발자가 Application Load Balancer, EC2 인스턴스 플릿을 관리하는 Auto Scaling 그룹 및 Aurora 데이터베이스로 구성된 클래식 3계층 아키텍처를 설정했습니다. 솔루션 아키텍트로서 귀하는 Well-Architected 프레임워크의 보안 기반을 고수하고자 합니다.EC2 인스턴스에서 들어오는 트래픽만 허용하도록 Aurora 데이터베이스의 보안 그룹을 어떻게 구성합니까?",ELB 보안 그룹을 승인하는 규칙 추가,Aurora 보안 그룹을 승인하는 규칙 추가,EC2 보안 그룹을 승인하는 규칙 추가,ASG의 서브넷 CIDR을 승인하는 규칙 추가,,,0,,
udemy,CLF-01,299,A gaming company is doing pre-launch testing for its new product. The company runs its production database on an Aurora MySQL DB cluster and the performance testing team wants access to multiple test databases that must be re-created from production data. The company has hired you as an AWS Certified Solutions Architect Associate to deploy a solution to create these test databases quickly with the LEAST required effort.What would you suggest to address this use case?,D,D,"Take a backup of the Aurora MySQL DB instance using the mysqldump utility, create multiple new test DB instances and restore each test DB from the backup",Create additional Read Replicas of the Aurora MySQL production DB and use the Read Replicas for testing by promoting each Replica to be its own independent standalone instance,Enable database Backtracking on the production DB and let the testing team use the production DB,Use database cloning to create multiple clones of the production DB and use each clone as a test DB,,,,한 게임 회사에서 신제품의 출시 전 테스트를 진행하고 있습니다. 이 회사는 Aurora MySQL DB 클러스터에서 프로덕션 데이터베이스를 실행하고 성능 테스트 팀은 프로덕션 데이터에서 다시 생성해야 하는 여러 테스트 데이터베이스에 대한 액세스를 원합니다. 이 회사는 최소한의 노력으로 이러한 테스트 데이터베이스를 신속하게 생성하는 솔루션을 배포하기 위해 귀하를 AWS 공인 솔루션 아키텍트 어소시에이트로 고용했습니다.이 사용 사례를 해결하기 위해 무엇을 제안하시겠습니까?,"mysqldump 유틸리티를 사용하여 Aurora MySQL DB 인스턴스를 백업하고, 새 테스트 DB 인스턴스를 여러 개 생성하고, 백업에서 각 테스트 DB를 복원합니다.",Aurora MySQL 프로덕션 DB의 추가 읽기 전용 복제본을 생성하고 각 복제본을 독립적인 독립 실행형 인스턴스로 승격하여 읽기 전용 복제본을 테스트용으로 사용,프로덕션 DB에서 데이터베이스 역추적을 활성화하고 테스트 팀이 프로덕션 DB를 사용하도록 합니다.,데이터베이스 복제를 사용하여 프로덕션 DB의 여러 클론을 생성하고 각 클론을 테스트 DB로 사용,,,0,,
udemy,CLF-01,300,"A media company wants to get out of the business of owning and maintaining its own IT infrastructure. As part of this digital transformation, the media company wants to archive about 5PB of data in its on-premises data center to durable long term storage.As a solutions architect, what is your recommendation to migrate this data in the MOST cost-optimal way?",D,D,Transfer the on-premises data into multiple Snowball Edge Storage Optimized devices. Copy the Snowball Edge data into AWS Glacier,Setup Site-to-Site VPN connection between the on-premises data center and AWS Cloud. Use this connection to transfer the data into AWS Glacier,Setup AWS direct connect between the on-premises data center and AWS Cloud. Use this connection to transfer the data into AWS Glacier,Transfer the on-premises data into multiple Snowball Edge Storage Optimized devices. Copy the Snowball Edge data into Amazon S3 and create a lifecycle policy to transition the data into AWS Glacier,,,,미디어 회사는 자체 IT 인프라를 소유하고 유지하는 사업에서 벗어나고 싶어합니다. 이 디지털 혁신의 일환으로 이 미디어 회사는 온프레미스 데이터 센터에 있는 약 5PB의 데이터를 내구성 있는 장기 스토리지에 보관하려고 합니다.솔루션 설계자로서 가장 비용 최적화된 방식으로 이 데이터를 마이그레이션하기 위한 권장 사항은 무엇입니까?,온프레미스 데이터를 여러 Snowball Edge Storage Optimized 디바이스로 전송합니다. Snowball Edge 데이터를 AWS Glacier에 복사,온프레미스 데이터 센터와 AWS 클라우드 간에 Site-to-Site VPN 연결을 설정합니다. 이 연결을 사용하여 데이터를 AWS Glacier로 전송,온프레미스 데이터 센터와 AWS 클라우드 간에 AWS Direct Connect를 설정합니다. 이 연결을 사용하여 데이터를 AWS Glacier로 전송,온프레미스 데이터를 여러 Snowball Edge Storage Optimized 디바이스로 전송합니다. Snowball Edge 데이터를 Amazon S3에 복사하고 수명 주기 정책을 생성하여 데이터를 AWS Glacier로 전환,,,0,,
udemy,CLF-01,301,The engineering team at an e-commerce company uses a Lambda function to write the order data into a single DB instance Aurora cluster. The team has noticed that many order- writes to its Aurora cluster are getting missed during peak load times. The diagnostics data has revealed that the DB is experiencing high CPU and memory consumption during traffic spikes. The team also wants to enhance the availability of the Aurora DB.Which of the following steps would you combine to address the given scenario? (Select two),AB,AB,Create a replica Aurora instance in another Availability Zone to improve the availability as the replica can serve as a failover target,Handle all read operations for your application by connecting to the reader endpoint of the Aurora cluster so that Aurora can spread the load for read-only connections across the Aurora replica,Create a standby Aurora instance in another Availability Zone to improve the availability as the standby can serve as a failover target,Use EC2 instances behind an Application Load Balancer to write the order data into the Aurora cluster,Increase the concurrency of the Lambda function so that the order-writes do not get missed during traffic spikes,,,전자상거래 회사의 엔지니어링 팀은 Lambda 함수를 사용하여 주문 데이터를 단일 DB 인스턴스 Aurora 클러스터에 기록합니다. 팀은 피크 로드 시간 동안 Aurora 클러스터에 대한 많은 주문-쓰기가 누락되는 것을 발견했습니다. 진단 데이터에 따르면 DB는 트래픽 급증 시 높은 CPU 및 메모리 소비를 경험하고 있습니다. 팀은 또한 Aurora DB의 가용성을 향상시키고자 합니다.주어진 시나리오를 해결하기 위해 다음 중 어떤 단계를 결합하시겠습니까? (2개 선택),복제본이 장애 조치 대상 역할을 할 수 있으므로 가용성을 개선하려면 다른 가용 영역에 복제본 Aurora 인스턴스를 생성하십시오.,Aurora가 Aurora 복제본 전체에서 읽기 전용 연결에 대한 로드를 분산할 수 있도록 Aurora 클러스터의 리더 엔드포인트에 연결하여 애플리케이션에 대한 모든 읽기 작업을 처리합니다.,대기가 장애 조치 대상 역할을 할 수 있으므로 가용성을 개선하려면 다른 가용 영역에 대기 Aurora 인스턴스를 생성하십시오.,Application Load Balancer 뒤의 EC2 인스턴스를 사용하여 Aurora 클러스터에 주문 데이터 쓰기,트래픽 급증 시 주문 쓰기가 누락되지 않도록 Lambda 함수의 동시성을 높입니다.,,0,,
udemy,CLF-01,302,"A junior developer is learning to build websites using HTML, CSS, and JavaScript. He has created a static website and then deployed it on Amazon S3. Now he can't seem to figure out the endpoint for his super cool website.As a solutions architect, can you help him figure out the allowed formats for the Amazon S3 website endpoints? (Select two)",BE,BE,http://s3-website.Region.bucket-name.amazonaws.com,http://bucket-name.s3-website-Region.amazonaws.com,http://s3-website-Region.bucket-name.amazonaws.com,http://bucket-name.Region.s3-website.amazonaws.com,http://bucket-name.s3-website.Region.amazonaws.com,,,"주니어 개발자가 HTML, CSS 및 JavaScript를 사용하여 웹 사이트를 구축하는 방법을 배우고 있습니다. 그는 정적 웹 사이트를 만든 다음 Amazon S3에 배포했습니다. 이제 그는 자신의 매우 멋진 웹사이트의 끝점을 파악할 수 없는 것 같습니다.솔루션 설계자로서 그가 Amazon S3 웹 사이트 엔드포인트에 허용되는 형식을 파악하도록 도울 수 있습니까? (2개 선택)",http://s3-website.Region.bucket-name.amazonaws.com,http://bucket-name.s3-website-Region.amazonaws.com,http://s3-website-Region.bucket-name.amazonaws.com,http://bucket-name.Region.s3-website.amazonaws.com,http://bucket-name.s3-website.Region.amazonaws.com,,0,,
udemy,CLF-01,303,"A company wants to ensure high availability for its RDS database. The development team wants to opt for Multi-AZ deployment and they would like to understand what happens when the primary instance of the Multi-AZ configuration goes down.As a Solutions Architect, which of the following will you identify as the outcome of the scenario?",D,D,The URL to access the database will change to the standby DB,An email will be sent to the System Administrator asking for manual intervention,The application will be down until the primary database has recovered itself,The CNAME record will be updated to point to the standby DB,,,,회사에서 RDS 데이터베이스의 고가용성을 보장하려고 합니다. 개발 팀은 다중 AZ 배포를 선택하고 다중 AZ 구성의 기본 인스턴스가 다운될 때 어떤 일이 발생하는지 이해하고 싶어합니다.솔루션 설계자로서 다음 중 시나리오의 결과로 식별할 항목은 무엇입니까?,데이터베이스에 접근하기 위한 URL이 대기 DB로 변경됩니다.,수동 개입을 요청하는 이메일이 시스템 관리자에게 전송됩니다.,애플리케이션은 기본 데이터베이스가 자체적으로 복구될 때까지 다운됩니다.,CNAME 레코드는 대기 DB를 가리키도록 업데이트됩니다.,,,0,,
udemy,CLF-01,304,"The content division at a digital media agency has an application that generates a large number of files on Amazon S3, each approximately 10 MB in size. The agency mandates that the files be stored for 5 years before they can be deleted. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days. The files contain critical business data that is not easy to reproduce, therefore, immediate accessibility is always required.Which solution is the MOST cost-effective for the given use case?",C,C,Set up an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier Flexible Retrieval 30 days after object creation. Delete the files 5 years after object creation,Set up an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-IA 30 days after object creation. Delete the files 5 years after object creation,Set up an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-IA 30 days after object creation. Delete the files 5 years after object creation,Set up an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-IA 30 days after object creation. Archive the files to S3 Glacier Deep Archive 5 years after object creation,,,,디지털 미디어 에이전시의 콘텐츠 부서에는 Amazon S3에서 각각 크기가 약 10MB인 많은 수의 파일을 생성하는 애플리케이션이 있습니다. 기관은 파일을 삭제하기 전에 5년 동안 저장하도록 지시합니다. 파일은 개체 생성 후 처음 30일 동안 자주 액세스되지만 처음 30일 이후에는 거의 액세스되지 않습니다. 파일에는 재현하기 쉽지 않은 중요한 비즈니스 데이터가 포함되어 있으므로 항상 즉각적인 액세스가 필요합니다.주어진 사용 사례에 대해 가장 비용 효율적인 솔루션은 무엇입니까?,객체 생성 후 30일이 지나면 S3 Standard에서 S3 Glacier Flexible Retrieval로 파일을 이동하도록 S3 버킷 수명 주기 정책을 설정합니다. 개체 생성 후 5년이 지난 파일 삭제,객체 생성 30일 후 S3 Standard에서 S3 One Zone-IA로 파일을 이동하도록 S3 버킷 수명 주기 정책을 설정합니다. 개체 생성 후 5년이 지난 파일 삭제,객체 생성 후 30일이 지나면 S3 Standard에서 S3 Standard-IA로 파일을 이동하도록 S3 버킷 수명 주기 정책을 설정합니다. 개체 생성 후 5년이 지난 파일 삭제,객체 생성 후 30일이 지나면 S3 Standard에서 S3 Standard-IA로 파일을 이동하도록 S3 버킷 수명 주기 정책을 설정합니다. 객체 생성 후 5년 동안 S3 Glacier Deep Archive에 파일 보관,,,0,,
udemy,CLF-01,305,"The engineering team at an online fashion retailer uses AWS Cloud to manage its technology infrastructure. The EC2 server fleet is behind an Application Load Balancer and the fleet strength is managed by an Auto Scaling group. Based on the historical data, the team is anticipating a huge traffic spike during the upcoming Thanksgiving sale.As an AWS solutions architect, what feature of the Auto Scaling group would you leverage so that the potential surge in traffic can be preemptively addressed?",A,A,Auto Scaling group scheduled action,Auto Scaling group lifecycle hook,Auto Scaling group target tracking scaling policy,Auto Scaling group step scaling policy,,,,온라인 패션 소매업체의 엔지니어링 팀은 AWS Cloud를 사용하여 기술 인프라를 관리합니다. EC2 서버 플릿은 Application Load Balancer 뒤에 있으며 플릿 강도는 Auto Scaling 그룹에서 관리합니다. 이전 데이터를 기반으로 팀은 다가오는 추수 감사절 세일 기간 동안 엄청난 트래픽 급증을 예상하고 있습니다.AWS 솔루션 아키텍트로서 잠재적인 트래픽 급증을 선제적으로 해결하기 위해 Auto Scaling 그룹의 어떤 기능을 활용하시겠습니까?,Auto Scaling 그룹 예약 작업,Auto Scaling 그룹 수명 주기 후크,Auto Scaling 그룹 대상 추적 조정 정책,Auto Scaling 그룹 단계 조정 정책,,,0,,
udemy,CLF-01,306,"A leading media company wants to do an accelerated online migration of hundreds of terabytes of files from their on-premises data center to Amazon S3 and then establish a mechanism to access the migrated data for ongoing updates from the on-premises applications.As a solutions architect, which of the following would you select as the MOST performant solution for the given use-case?",C,C,Use File Gateway configuration of AWS Storage Gateway to migrate data to Amazon S3 and then use S3 Transfer Acceleration for ongoing updates from the on-premises applications,Use S3 Transfer Acceleration to migrate existing data to Amazon S3 and then use DataSync for ongoing updates from the on-premises applications,Use AWS DataSync to migrate existing data to Amazon S3 and then use File Gateway to retain access to the migrated data for ongoing updates from the on-premises applications,Use AWS DataSync to migrate existing data to Amazon S3 as well as access the S3 data for ongoing updates,,,,선도적인 미디어 회사는 수백 테라바이트의 파일을 온프레미스 데이터 센터에서 Amazon S3로 빠르게 온라인 마이그레이션한 다음 온프레미스 애플리케이션에서 지속적인 업데이트를 위해 마이그레이션된 데이터에 액세스하는 메커니즘을 구축하려고 합니다.솔루션 설계자로서 주어진 사용 사례에 대해 다음 중 가장 성능이 뛰어난 솔루션으로 선택하는 것은 무엇입니까?,AWS Storage Gateway의 파일 게이트웨이 구성을 사용하여 데이터를 Amazon S3로 마이그레이션한 다음 S3 Transfer Acceleration을 사용하여 온프레미스 애플리케이션의 지속적인 업데이트,S3 Transfer Acceleration을 사용하여 기존 데이터를 Amazon S3로 마이그레이션한 다음 DataSync를 사용하여 온프레미스 애플리케이션의 지속적인 업데이트,AWS DataSync를 사용하여 기존 데이터를 Amazon S3로 마이그레이션한 다음 파일 게이트웨이를 사용하여 온프레미스 애플리케이션의 지속적인 업데이트를 위해 마이그레이션된 데이터에 대한 액세스를 유지합니다.,AWS DataSync를 사용하여 기존 데이터를 Amazon S3로 마이그레이션하고 지속적인 업데이트를 위해 S3 데이터에 액세스,,,0,,
udemy,CLF-01,307,"A big data analytics company is using Kinesis Data Streams (KDS) to process IoT data from the field devices of an agricultural sciences company. Multiple consumer applications are using the incoming data streams and the engineers have noticed a performance lag for the data delivery speed between producers and consumers of the data streams.As a solutions architect, which of the following would you recommend for improving the performance for the given use-case?",D,D,Swap out Kinesis Data Streams with Kinesis Data Firehose,Swap out Kinesis Data Streams with SQS FIFO queues,Swap out Kinesis Data Streams with SQS Standard queues,Use Enhanced Fanout feature of Kinesis Data Streams,,,,빅 데이터 분석 회사는 Kinesis Data Streams(KDS)를 사용하여 농업 과학 회사의 현장 장치에서 IoT 데이터를 처리하고 있습니다. 여러 소비자 응용 프로그램이 들어오는 데이터 스트림을 사용하고 있으며 엔지니어는 데이터 스트림의 생산자와 소비자 간의 데이터 전송 속도에 대한 성능 지연을 발견했습니다.솔루션 설계자로서 주어진 사용 사례의 성능을 개선하기 위해 다음 중 어떤 것을 추천하시겠습니까?,Kinesis Data Streams를 Kinesis Data Firehose로 교체,Kinesis Data Streams를 SQS FIFO 대기열로 교체,Kinesis Data Streams를 SQS 표준 대기열로 교체,Kinesis Data Streams의 향상된 팬아웃 기능 사용,,,0,,
udemy,CLF-01,308,"A global media company uses a fleet of EC2 instances (behind an Application Load Balancer) to power its video streaming application. To improve the performance of the application, the engineering team has also created a CloudFront distribution with the Application Load Balancer as the custom origin. The security team at the company has noticed a spike in the number and types of SQL injection and cross-site scripting attack vectors on the application.As a solutions architect, which of the following solutions would you recommend as the MOST effective in countering these malicious attacks?",D,D,Use Security Hub with CloudFront distribution,Use AWS Firewall Manager with CloudFront distribution,Use Route 53 with CloudFront distribution,Use Web Application Firewall (WAF) with CloudFront distribution,,,,한 글로벌 미디어 회사는 여러 EC2 인스턴스(Application Load Balancer 뒤)를 사용하여 비디오 스트리밍 애플리케이션을 구동합니다. 애플리케이션의 성능을 개선하기 위해 엔지니어링 팀은 Application Load Balancer를 사용자 지정 오리진으로 사용하여 CloudFront 배포도 생성했습니다. 회사의 보안 팀은 애플리케이션에서 SQL 주입 및 교차 사이트 스크립팅 공격 벡터의 수와 유형이 급증하는 것을 발견했습니다.솔루션 설계자로서 다음 중 이러한 악의적인 공격에 대응하는 데 가장 효과적인 솔루션으로 권장하는 솔루션은 무엇입니까?,CloudFront 배포와 함께 Security Hub 사용,CloudFront 배포와 함께 AWS Firewall Manager 사용,CloudFront 배포와 함께 Route 53 사용,CloudFront 배포와 함께 웹 애플리케이션 방화벽(WAF) 사용,,,0,,
udemy,CLF-01,309,"A retail company wants to establish encrypted network connectivity between its on-premises data center and AWS Cloud. The company wants to get the solution up and running in the fastest possible time and it should also support encryption in transit.As a solutions architect, which of the following solutions would you suggest to the company?",B,B,Use AWS Data Sync to establish encrypted network connectivity between the on-premises data center and AWS Cloud,Use Site-to-Site VPN to establish encrypted network connectivity between the on-premises data center and AWS Cloud,Use AWS Secrets Manager to establish encrypted network connectivity between the on-premises data center and AWS Cloud,Use AWS Direct Connect to establish encrypted network connectivity between the on-premises data center and AWS Cloud,,,,소매 회사는 온프레미스 데이터 센터와 AWS 클라우드 간에 암호화된 네트워크 연결을 설정하려고 합니다. 이 회사는 솔루션을 가능한 가장 빠른 시간 내에 가동하고 실행하기를 원하며 전송 중 암호화도 지원해야 합니다.솔루션 설계자로서 다음 중 회사에 제안할 솔루션은 무엇입니까?,AWS Data Sync를 사용하여 온프레미스 데이터 센터와 AWS 클라우드 간에 암호화된 네트워크 연결 설정,Site-to-Site VPN을 사용하여 온프레미스 데이터 센터와 AWS 클라우드 간에 암호화된 네트워크 연결 설정,AWS Secrets Manager를 사용하여 온프레미스 데이터 센터와 AWS 클라우드 간의 암호화된 네트워크 연결 설정,AWS Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 클라우드 간에 암호화된 네트워크 연결 설정,,,0,,
udemy,CLF-01,310,"A development team has deployed a microservice to the ECS. The application layer is in a Docker container that provides both static and dynamic content through an Application Load Balancer. With increasing load, the ECS cluster is experiencing higher network usage. The development team has looked into the network usage and found that 90% of it is due to distributing static content of the application.As a Solutions Architect, what do you recommend to improve the application's network usage and decrease costs?",A,A,Distribute the static content through Amazon S3,Distribute the dynamic content through Amazon EFS,Distribute the dynamic content through Amazon S3,Distribute the static content through Amazon EFS,,,,개발 팀이 ECS에 마이크로서비스를 배포했습니다. 애플리케이션 계층은 Application Load Balancer를 통해 정적 콘텐츠와 동적 콘텐츠를 모두 제공하는 Docker 컨테이너에 있습니다. 로드가 증가함에 따라 ECS 클러스터의 네트워크 사용량이 증가하고 있습니다. 개발팀은 네트워크 사용량을 조사한 결과 그 중 90%가 애플리케이션의 정적 콘텐츠 배포로 인한 것임을 발견했습니다.솔루션 설계자로서 애플리케이션의 네트워크 사용량을 개선하고 비용을 줄이기 위해 무엇을 권장합니까?,Amazon S3를 통해 정적 콘텐츠 배포,Amazon EFS를 통해 동적 콘텐츠 배포,Amazon S3를 통해 동적 콘텐츠 배포,Amazon EFS를 통해 정적 콘텐츠 배포,,,0,,
udemy,CLF-01,311,"While troubleshooting, a cloud architect realized that the Amazon EC2 instance is unable to connect to the internet using the Internet Gateway.Which conditions should be met for internet connectivity to be established? (Select two)",AB,AB,The network ACLs associated with the subnet must have rules to allow inbound and outbound traffic,The route table in the instance’s subnet should have a route to an Internet Gateway,The instance's subnet is associated with multiple route tables with conflicting configurations,The subnet has been configured to be public and has no access to the internet,The instance's subnet is not associated with any route table,,,문제를 해결하는 동안 클라우드 설계자는 Amazon EC2 인스턴스가 인터넷 게이트웨이를 사용하여 인터넷에 연결할 수 없음을 깨달았습니다.인터넷 연결을 설정하려면 어떤 조건을 충족해야 합니까? (2개 선택),서브넷과 연결된 네트워크 ACL에는 인바운드 및 아웃바운드 트래픽을 허용하는 규칙이 있어야 합니다.,인스턴스 서브넷의 경로 테이블에는 인터넷 게이트웨이에 대한 경로가 있어야 합니다.,인스턴스의 서브넷이 구성이 충돌하는 여러 경로 테이블과 연결되어 있습니다.,서브넷이 공용으로 구성되었으며 인터넷에 액세스할 수 없습니다.,인스턴스의 서브넷이 라우팅 테이블과 연결되어 있지 않습니다.,,0,,
udemy,CLF-01,312,A financial services firm uses a high-frequency trading system and wants to write the log files into Amazon S3. The system will also read these log files in parallel on a near real-time basis. The engineering team wants to address any data discrepancies that might arise when the trading system overwrites an existing log file and then tries to read that specific log file.Which of the following options BEST describes the capabilities of Amazon S3 relevant to this scenario?,C,C,"A process replaces an existing object and immediately tries to read it. Until the change is fully propagated, Amazon S3 does not return any data","A process replaces an existing object and immediately tries to read it. Until the change is fully propagated, Amazon S3 might return the previous data",A process replaces an existing object and immediately tries to read it. Amazon S3 always returns the latest version of the object,"A process replaces an existing object and immediately tries to read it. Until the change is fully propagated, Amazon S3 might return the new data",,,,금융 서비스 회사는 고주파 거래 시스템을 사용하고 로그 파일을 Amazon S3에 기록하려고 합니다. 시스템은 또한 거의 실시간으로 이러한 로그 파일을 병렬로 읽습니다. 엔지니어링 팀은 거래 시스템이 기존 로그 파일을 덮어쓴 다음 특정 로그 파일을 읽으려고 할 때 발생할 수 있는 데이터 불일치를 해결하려고 합니다.다음 옵션 중 이 시나리오와 관련된 Amazon S3의 기능을 가장 잘 설명하는 것은 무엇입니까?,프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3는 어떠한 데이터도 반환하지 않습니다.,프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3는 이전 데이터를 반환할 수 있습니다.,프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. Amazon S3는 항상 객체의 최신 버전을 반환합니다.,프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3는 새 데이터를 반환할 수 있습니다.,,,0,,
udemy,CLF-01,313,"You are a cloud architect at an IT company. The company has multiple enterprise customers that manage their own mobile apps that capture and send data to Amazon Kinesis Data Streams. They have been getting a ProvisionedThroughputExceededException exception. You have been contacted to help and upon analysis, you notice that messages are being sent one by one at a high rate.Which of the following options will help with the exception while keeping costs at a minimum?",D,D,Decrease the Stream retention duration,Increase the number of shards,Use Exponential Backoff,Use batch messages,,,,당신은 IT 회사의 클라우드 설계자입니다. 이 회사에는 데이터를 캡처하여 Amazon Kinesis Data Streams로 보내는 자체 모바일 앱을 관리하는 여러 기업 고객이 있습니다. 그들은 예외를 받고 있습니다 ProvisionedThroughputExceededException. 귀하는 도움을 요청받았고 분석 결과 메시지가 하나씩 빠른 속도로 전송되고 있음을 알게 되었습니다.다음 중 비용을 최소화하면서 예외 상황에 도움이 되는 옵션은 무엇입니까?,스트림 보존 기간 줄이기,샤드 수 늘리기,지수 백오프 사용,배치 메시지 사용,,,0,,
udemy,CLF-01,314,A streaming solutions company is building a video streaming product by using an Application Load Balancer (ALB) that routes the requests to the underlying EC2 instances. The engineering team has noticed a peculiar pattern. The ALB removes an instance from its pool of healthy instances whenever it is detected as unhealthy but the Auto Scaling group fails to kick-in and provision the replacement instance.What could explain this anomaly?,C,C,Both the Auto Scaling group and Application Load Balancer are using ALB based health check,Both the Auto Scaling group and Application Load Balancer are using EC2 based health check,The Auto Scaling group is using EC2 based health check and the Application Load Balancer is using ALB based health check,The Auto Scaling group is using ALB based health check and the Application Load Balancer is using EC2 based health check,,,,스트리밍 솔루션 회사는 요청을 기본 EC2 인스턴스로 라우팅하는 ALB(Application Load Balancer)를 사용하여 비디오 스트리밍 제품을 구축하고 있습니다. 엔지니어링 팀은 특이한 패턴을 발견했습니다. ALB는 비정상으로 감지될 때마다 정상 인스턴스 풀에서 인스턴스를 제거하지만 Auto Scaling 그룹은 교체 인스턴스를 시작하고 프로비저닝하지 못합니다.이 이상 현상을 무엇으로 설명할 수 있습니까?,Auto Scaling 그룹과 Application Load Balancer 모두 ALB 기반 상태 확인을 사용하고 있습니다.,Auto Scaling 그룹과 Application Load Balancer 모두 EC2 기반 상태 확인을 사용하고 있습니다.,Auto Scaling 그룹은 EC2 기반 상태 확인을 사용하고 Application Load Balancer는 ALB 기반 상태 확인을 사용합니다.,Auto Scaling 그룹은 ALB 기반 상태 확인을 사용하고 Application Load Balancer는 EC2 기반 상태 확인을 사용합니다.,,,0,,
udemy,CLF-01,315,"A multi-national company is looking at optimizing their AWS resources across various countries and regions. They want to understand the best practices on cost optimization, performance, and security for their system architecture spanning across multiple business units.Which AWS service is the best fit for their requirements?",C,C,AWS Management Console,AWS Systems Manager,AWS Trusted Advisor,AWS Config,,,,"다국적 기업이 다양한 국가 및 지역에서 AWS 리소스를 최적화하는 방법을 모색하고 있습니다. 그들은 여러 사업부에 걸쳐 있는 시스템 아키텍처의 비용 최적화, 성능 및 보안에 대한 모범 사례를 이해하기를 원합니다.요구 사항에 가장 적합한 AWS 서비스는 무엇입니까?",AWS 관리 콘솔,AWS 시스템 관리자,AWS 신뢰할 수 있는 조언자,AWS 구성,,,0,,
udemy,CLF-01,316,"A silicon valley based startup helps its users legally sign highly confidential contracts. To meet the compliance guidelines, the startup must ensure that the signed contracts are encrypted using the AES-256 algorithm via an encryption key that is generated internally. The startup is now migrating to AWS Cloud and would like the data to be encrypted on AWS. The startup wants to continue using their existing encryption key generation mechanism.What do you recommend?",B,B,SSE-S3,SSE-C,SSE-KMS,Client-Side Encryption,,,,실리콘 밸리에 기반을 둔 스타트업은 사용자가 극비 계약에 합법적으로 서명할 수 있도록 도와줍니다. 규정 준수 지침을 충족하려면 스타트업은 서명된 계약이 내부적으로 생성된 암호화 키를 통해 AES-256 알고리즘을 사용하여 암호화되도록 해야 합니다. 이 스타트업은 현재 AWS 클라우드로 마이그레이션 중이며 AWS에서 데이터를 암호화하려고 합니다. 스타트업은 기존 암호화 키 생성 메커니즘을 계속 사용하려고 합니다.추천 메뉴가 무엇인가요?,SSE-S3,SSE-C,SSE-KMS,클라이언트측 암호화,,,0,,
udemy,CLF-01,317,"A pharma company is working on developing a vaccine for the COVID-19 virus. The researchers at the company want to process the reference healthcare data in a highly available as well as HIPAA compliant in-memory database that supports caching results of SQL queries.As a solutions architect, which of the following AWS services would you recommend for this task?",B,B,DynamoDB Accelerator (DAX),ElastiCache for Redis/Memcached,DocumentDB,DynamoDB,,,,한 제약 회사가 COVID-19 바이러스에 대한 백신을 개발하기 위해 노력하고 있습니다. 이 회사의 연구원들은 SQL 쿼리의 캐싱 결과를 지원하는 고가용성 및 HIPAA 준수 인메모리 데이터베이스에서 참조 의료 데이터를 처리하려고 합니다.솔루션 아키텍트로서 이 작업에 대해 다음 AWS 서비스 중 어떤 것을 추천하시겠습니까?,DynamoDB 액셀러레이터(DAX),Redis/Memcached용 ElastiCache,문서DB,DynamoDB,,,0,,
udemy,CLF-01,318,"A financial services company has to retain the activity logs for each of their customers to meet compliance guidelines. Depending on the business line, the company wants to retain the logs for 5-10 years in highly available and durable storage on AWS. The overall data size is expected to be in PetaBytes. In case of an audit, the data would need to be accessible within a timeframe of up to 48 hours.Which AWS storage option is the MOST cost-effective for the given compliance requirements?",A,A,Amazon S3 Glacier Deep Archive,Amazon S3 Standard storage,Third party tape storage,Amazon S3 Glacier,,,,금융 서비스 회사는 규정 준수 지침을 충족하기 위해 각 고객의 활동 로그를 유지해야 합니다. 비즈니스 라인에 따라 회사는 AWS의 고가용성 및 내구성 스토리지에 5-10년 동안 로그를 유지하려고 합니다. 전체 데이터 크기는 PetaBytes로 예상됩니다. 감사의 경우 최대 48시간 이내에 데이터에 액세스할 수 있어야 합니다.주어진 규정 준수 요구 사항에 대해 가장 비용 효율적인 AWS 스토리지 옵션은 무엇입니까?,Amazon S3 Glacier 딥 아카이브,Amazon S3 표준 스토리지,타사 테이프 스토리지,아마존 S3 빙하,,,0,,
udemy,CLF-01,319,The data engineering team at an e-commerce company has set up a workflow to ingest the clickstream data into the raw zone of the S3 data lake. The team wants to run some SQL based data sanity checks on the raw zone of the data lake.What AWS services would you recommend for this use-case such that the solution is cost-effective and easy to maintain?,C,C,Load the incremental raw zone data into an EMR based Spark Cluster on an hourly basis and use SparkSQL to run the SQL based sanity checks,Load the incremental raw zone data into RDS on an hourly basis and run the SQL based sanity checks,Use Athena to run SQL based analytics against S3 data,Load the incremental raw zone data into Redshift on an hourly basis and run the SQL based sanity checks,,,,전자상거래 회사의 데이터 엔지니어링 팀은 클릭스트림 데이터를 S3 데이터 레이크의 원시 영역으로 수집하는 워크플로를 설정했습니다. 팀은 데이터 레이크의 원시 영역에서 일부 SQL 기반 데이터 온전성 검사를 실행하려고 합니다.이 사용 사례에 솔루션이 비용 효율적이고 유지 관리가 쉬운 AWS 서비스는 무엇입니까?,증분 원시 영역 데이터를 매시간 EMR 기반 Spark 클러스터에 로드하고 SparkSQL을 사용하여 SQL 기반 온전성 검사를 실행합니다.,증분 원시 영역 데이터를 매시간 RDS에 로드하고 SQL 기반 온전성 검사를 실행합니다.,Athena를 사용하여 S3 데이터에 대한 SQL 기반 분석 실행,증분 원시 영역 데이터를 매시간 Redshift로 로드하고 SQL 기반 온전성 검사를 실행합니다.,,,0,,
udemy,CLF-01,320,"You have built an application that is deployed with an Elastic Load Balancer and an Auto Scaling Group. As a Solutions Architect, you have configured aggressive CloudWatch alarms, making your Auto Scaling Group (ASG) scale in and out very quickly, renewing your fleet of Amazon EC2 instances on a daily basis. A production bug appeared two days ago, but the team is unable to SSH into the instance to debug the issue, because the instance has already been terminated by the ASG. The log files are saved on the EC2 instance.How will you resolve the issue and make sure it doesn't happen again?",B,B,Use AWS Lambda to regularly SSH into the EC2 instances and copy the log files to S3,Install a CloudWatch Logs agents on the EC2 instances to send logs to CloudWatch,Make a snapshot of the EC2 instance just before it gets terminated,Disable the Termination from the ASG any time a user reports an issue,,,,Elastic Load Balancer 및 Auto Scaling 그룹과 함께 배포되는 애플리케이션을 구축했습니다. 솔루션 아키텍트로서 귀하는 공격적인 CloudWatch 경보를 구성하여 ASG(Auto Scaling Group)를 매우 빠르게 확장 및 축소하고 Amazon EC2 인스턴스 플릿을 매일 갱신합니다. 프로덕션 버그가 이틀 전에 나타났지만 인스턴스가 이미 ASG에 의해 종료되었기 때문에 팀은 문제를 디버깅하기 위해 인스턴스에 SSH로 연결할 수 없습니다. 로그 파일은 EC2 인스턴스에 저장됩니다.문제를 어떻게 해결하고 다시는 이런 일이 발생하지 않도록 하시겠습니까?,AWS Lambda를 사용하여 정기적으로 EC2 인스턴스에 SSH로 연결하고 로그 파일을 S3에 복사,EC2 인스턴스에 CloudWatch Logs 에이전트를 설치하여 CloudWatch로 로그 전송,종료되기 직전에 EC2 인스턴스의 스냅샷을 만듭니다.,사용자가 문제를 보고할 때마다 ASG에서 종료 비활성화,,,0,,
udemy,CLF-01,321,"A media company is evaluating the possibility of moving its IT infrastructure to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for processing certain files which are mostly large videos. The company also needs close to 450 TB of very durable storage for storing media content and almost double of it, i.e. 900 TB for archival of legacy data.As a Solutions Architect, which set of services will you recommend to meet these requirements?",C,C,"Amazon S3 standard storage for maximum performance, Amazon S3 Intelligent-Tiering for intelligent, durable storage, and Amazon S3 Glacier Deep Archive for archival storage","Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage","Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage","Amazon EC2 instance store for maximum performance, AWS Storage Gateway for on-premises durable data access and Amazon S3 Glacier Deep Archive for archival storage",,,,한 미디어 회사가 IT 인프라를 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 대부분 대용량 비디오인 특정 파일을 처리하기 위해 가능한 최대 I/O 성능을 갖춘 최소 10TB의 스토리지가 필요합니다. 또한 이 회사는 미디어 콘텐츠를 저장하기 위해 거의 450TB의 매우 내구성이 뛰어난 스토리지가 필요하며 거의 두 배인 레거시 데이터 보관을 위해 900TB가 필요합니다.솔루션 설계자로서 이러한 요구 사항을 충족하기 위해 어떤 서비스 세트를 추천하시겠습니까?,"최대 성능을 위한 Amazon S3 표준 스토리지, 지능적이고 내구성 있는 스토리지를 위한 Amazon S3 Intelligent-Tiering 및 아카이브 스토리지를 위한 Amazon S3 Glacier Deep Archive","최대 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier","최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier","최대 성능을 위한 Amazon EC2 인스턴스 스토어, 온프레미스의 내구성 있는 데이터 액세스를 위한 AWS Storage Gateway 및 아카이브 스토리지를 위한 Amazon S3 Glacier Deep Archive",,,0,,
udemy,CLF-01,322,A pharmaceutical company is considering moving to AWS Cloud to accelerate the research and development process. Most of the daily workflows would be centered around running batch jobs on EC2 instances with storage on EBS volumes. The CTO is concerned about meeting HIPAA compliance norms for sensitive data stored on EBS.Which of the following options outline the correct capabilities of an encrypted EBS volume? (Select three),ADE,ADE,Any snapshot created from the volume is encrypted,Data at rest inside the volume is NOT encrypted,Any snapshot created from the volume is NOT encrypted,Data moving between the volume and the instance is encrypted,Data at rest inside the volume is encrypted,Data moving between the volume and the instance is NOT encrypted,,한 제약 회사가 연구 개발 프로세스를 가속화하기 위해 AWS 클라우드로의 이전을 고려하고 있습니다. 대부분의 일일 워크플로는 EBS 볼륨에 스토리지가 있는 EC2 인스턴스에서 배치 작업을 실행하는 데 중점을 둡니다. CTO는 EBS에 저장된 민감한 데이터에 대한 HIPAA 규정 준수 규범을 충족하는 것에 대해 우려하고 있습니다.다음 중 암호화된 EBS 볼륨의 올바른 기능을 설명하는 옵션은 무엇입니까? (3개 선택),볼륨에서 생성된 모든 스냅샷은 암호화됩니다.,볼륨 내부의 미사용 데이터는 암호화되지 않습니다.,볼륨에서 생성된 모든 스냅샷은 암호화되지 않습니다.,볼륨과 인스턴스 간에 이동하는 데이터는 암호화됩니다.,볼륨 내부의 미사용 데이터는 암호화됩니다.,,0,,볼륨과 인스턴스 간에 이동하는 데이터는 암호화되지 않습니다.
udemy,CLF-01,323,"A medical devices company uses S3 buckets to store critical data. Hundreds of buckets are used to keep the data segregated and well organized. Recently, the development team noticed that the lifecycle policies on the S3 buckets have not been applied optimally, resulting in higher costs.As a Solutions Architect, can you recommend a solution to reduce storage costs on S3 while keeping the IT team's involvement to a minimum?",B,B,Use S3 Outposts storage class to reduce the costs on S3 storage by storing the data on-premises,Use S3 Intelligent-Tiering storage class to optimize the S3 storage costs,"Configure Amazon EFS to provide a fast, cost-effective and sharable storage service","Use S3 One Zone-Infrequent Access, to reduce the costs on S3 storage",,,,의료 기기 회사는 S3 버킷을 사용하여 중요한 데이터를 저장합니다. 데이터를 분리하고 체계적으로 유지하기 위해 수백 개의 버킷이 사용됩니다. 최근 개발팀은 S3 버킷의 수명 주기 정책이 최적으로 적용되지 않아 비용이 증가한다는 사실을 발견했습니다.솔루션 설계자로서 IT 팀의 개입을 최소화하면서 S3의 스토리지 비용을 줄이는 솔루션을 추천할 수 있습니까?,S3 Outposts 스토리지 클래스를 사용하여 데이터를 온프레미스에 저장하여 S3 스토리지 비용 절감,S3 Intelligent-Tiering 스토리지 클래스를 사용하여 S3 스토리지 비용 최적화,빠르고 비용 효율적이며 공유 가능한 스토리지 서비스를 제공하도록 Amazon EFS 구성,S3 One Zone-Infrequent Access를 사용하여 S3 스토리지 비용 절감,,,0,,
udemy,CLF-01,324,"The engineering team at a weather tracking company wants to enhance the performance of its relation database and is looking for a caching solution that supports geospatial data.As a solutions architect, which of the following solutions will you suggest?",D,D,Use Amazon DynamoDB Accelerator (DAX),Use Amazon ElastiCache for Memcached,Use AWS Global Accelerator,Use Amazon ElastiCache for Redis,,,,날씨 추적 회사의 엔지니어링 팀은 관계 데이터베이스의 성능을 향상시키고 지리 공간 데이터를 지원하는 캐싱 솔루션을 찾고 있습니다.솔루션 설계자로서 다음 중 어떤 솔루션을 제안하시겠습니까?,Amazon DynamoDB 가속기(DAX) 사용,Memcached용 Amazon ElastiCache 사용,AWS 글로벌 액셀러레이터 사용,Redis용 Amazon ElastiCache 사용,,,0,,
udemy,CLF-01,325,"A CRM application is facing user experience issues with users reporting frequent sign-in requests from the application. The application is currently hosted on multiple EC2 instances behind an Application Load Balancer. The engineering team has identified the root cause as unhealthy servers causing session data to be lost. The team would like to implement a distributed in-memory cache-based session management solution.As a solutions architect, which of the following solutions would you recommend?",B,B,Use Application Load Balancer sticky sessions,Use Elasticache for distributed in-memory cache based session management,Use DynamoDB for distributed in-memory cache based session management,Use RDS for distributed in-memory cache based session management,,,,CRM 애플리케이션은 사용자가 애플리케이션에서 빈번한 로그인 요청을 보고하는 사용자 경험 문제에 직면해 있습니다. 애플리케이션은 현재 Application Load Balancer 뒤에 있는 여러 EC2 인스턴스에서 호스팅됩니다. 엔지니어링 팀은 비정상 서버가 세션 데이터 손실을 일으키는 근본 원인을 확인했습니다. 팀은 분산 메모리 캐시 기반 세션 관리 솔루션을 구현하려고 합니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 추천하시겠습니까?,Application Load Balancer 고정 세션 사용,분산 인 메모리 캐시 기반 세션 관리에 Elasticache 사용,분산 인 메모리 캐시 기반 세션 관리에 DynamoDB 사용,분산 인 메모리 캐시 기반 세션 관리에 RDS 사용,,,0,,
udemy,CLF-01,326,A retail company needs a secure connection between its on-premises data center and AWS Cloud. This connection does not need high bandwidth and will handle a small amount of traffic. The company wants a quick turnaround time to set up the connection.What is the MOST cost-effective way to establish such a connection?,C,C,Set up an Internet Gateway between the on-premises data center and AWS cloud,Set up a bastion host on Amazon EC2,Set up an AWS Site-to-Site VPN connection,Set up AWS Direct Connect,,,,소매 회사는 온프레미스 데이터 센터와 AWS 클라우드 간에 안전한 연결이 필요합니다. 이 연결에는 높은 대역폭이 필요하지 않으며 적은 양의 트래픽을 처리합니다. 회사는 연결을 설정하기 위해 빠른 처리 시간을 원합니다.그러한 연결을 설정하는 가장 비용 효율적인 방법은 무엇입니까?,온프레미스 데이터 센터와 AWS 클라우드 사이에 인터넷 게이트웨이 설정,Amazon EC2에서 배스천 호스트 설정,AWS Site-to-Site VPN 연결 설정,AWS Direct Connect 설정,,,0,,
udemy,CLF-01,327,A financial services company stores confidential data on an Amazon Simple Storage Service (S3) bucket. The compliance guidelines require that files be stored with server-side encryption. The encryption used must be Advanced Encryption Standard (AES-256) and the company does not want to manage the encryption keys.Which of the following options represents the most cost-optimal solution for the given use case?,B,B,SSE-KMS,SSE-S3,SSE-C,Client Side Encryption,,,,금융 서비스 회사는 기밀 데이터를 Amazon Simple Storage Service(S3) 버킷에 저장합니다. 규정 준수 지침에 따르면 파일은 서버 측 암호화로 저장되어야 합니다. 사용된 암호화는 고급 암호화 표준(AES-256)이어야 하며 회사는 암호화 키를 관리하기를 원하지 않습니다.다음 중 주어진 사용 사례에 가장 비용 효율적인 솔루션을 나타내는 옵션은 무엇입니까?,SSE-KMS,SSE-S3,SSE-C,클라이언트 측 암호화,,,0,,
udemy,CLF-01,328,A healthcare company wants to run its applications on single-tenant hardware to meet compliance guidelines.Which of the following is the MOST cost-effective way of isolating the Amazon EC2 instances to a single tenant?,A,A,Dedicated Instances,On-Demand Instances,Dedicated Hosts,Spot Instances,,,,의료 회사는 규정 준수 지침을 충족하기 위해 단일 테넌트 하드웨어에서 애플리케이션을 실행하려고 합니다.다음 중 Amazon EC2 인스턴스를 단일 테넌트로 격리하는 가장 비용 효율적인 방법은 무엇입니까?,전용 인스턴스,온디맨드 인스턴스,전용 호스트,스팟 인스턴스,,,0,,
udemy,CLF-01,329,"Your company has created a data warehouse using Redshift that is used to analyze data from Amazon S3. From the usage pattern, you have detected that after 30 days, the data is rarely queried in Redshift and it's not ""hot data"" anymore. You would like to preserve the SQL querying capability on your data and get the queries started immediately. Also, you want to adopt a pricing model that allows you to save the maximum amount of cost on Redshift.What do you recommend? (Select two)",BC,BC,Create a smaller Redshift Cluster with the cold data,Move the data to S3 Standard IA after 30 days,Analyze the cold data with Athena,Move the data to S3 Glacier after 30 days,Migrate the Redshift underlying storage to S3 IA,,,"귀사는 Amazon S3의 데이터를 분석하는 데 사용되는 Redshift를 사용하여 데이터 웨어하우스를 생성했습니다. 사용 패턴에서 30일 후 데이터가 Redshift에서 거의 쿼리되지 않으며 더 이상 ""핫 데이터""가 아님을 감지했습니다. 데이터에 대한 SQL 쿼리 기능을 유지하고 쿼리를 즉시 시작하려고 합니다. 또한 Redshift에서 최대 비용을 절약할 수 있는 가격 책정 모델을 채택하려고 합니다.추천 메뉴가 무엇인가요? (2개 선택)",콜드 데이터로 더 작은 Redshift 클러스터 생성,30일 후 데이터를 S3 Standard IA로 이동,Athena로 콜드 데이터 분석,30일 후 S3 Glacier로 데이터 이동,Redshift 기본 스토리지를 S3 IA로 마이그레이션,,0,,
udemy,CLF-01,330,"A company maintains its business-critical customer data on an on-premises system in an encrypted format. Over the years, the company has transitioned from using a single encryption key to multiple encryption keys by dividing the data into logical chunks. With the decision to move all the data to an Amazon S3 bucket, the company is now looking for a technique to encrypt each file with a different encryption key to provide maximum security to the migrated on-premises data.How will you implement this requirement without adding the overhead of splitting the data into logical groups?",C,C,Store the logically divided data into different Amazon S3 buckets. Use server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data,Use Multi-Region keys for client-side encryption in the AWS S3 Encryption Client to generate unique keys for each file of data,Configure a single Amazon S3 bucket to hold all data. Use server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data,Configure a single Amazon S3 bucket to hold all data. Use server-side encryption with AWS KMS (SSE-KMS) and use encryption context to generate a different key for each file/object that you store in the S3 bucket,,,,회사는 비즈니스 크리티컬 고객 데이터를 암호화된 형식으로 온프레미스 시스템에 유지 관리합니다. 수년에 걸쳐 회사는 데이터를 논리적 청크로 분할하여 단일 암호화 키 사용에서 다중 암호화 키 사용으로 전환했습니다. 모든 데이터를 Amazon S3 버킷으로 이동하기로 결정한 이 회사는 이제 마이그레이션된 온프레미스 데이터에 최대 보안을 제공하기 위해 서로 다른 암호화 키로 각 ​​파일을 암호화하는 기술을 찾고 있습니다.데이터를 논리 그룹으로 분할하는 오버헤드를 추가하지 않고 이 요구 사항을 어떻게 구현하시겠습니까?,논리적으로 분할된 데이터를 서로 다른 Amazon S3 버킷에 저장합니다. Amazon S3 관리형 키(SSE-S3)로 서버 측 암호화를 사용하여 데이터 암호화,AWS S3 암호화 클라이언트에서 클라이언트 측 암호화에 다중 리전 키를 사용하여 데이터의 각 파일에 대해 고유한 키 생성,모든 데이터를 보관할 단일 Amazon S3 버킷을 구성합니다. Amazon S3 관리형 키(SSE-S3)로 서버 측 암호화를 사용하여 데이터 암호화,모든 데이터를 보관할 단일 Amazon S3 버킷을 구성합니다. AWS KMS(SSE-KMS)와 함께 서버 측 암호화를 사용하고 암호화 컨텍스트를 사용하여 S3 버킷에 저장하는 각 파일/객체에 대해 서로 다른 키를 생성합니다.,,,0,,
udemy,CLF-01,331,"Your application is deployed on EC2 instances fronted by an Application Load Balancer. Recently, your infrastructure has come under attack. Attackers perform over 100 requests per second, while your normal users only make about 5 requests per second.How can you efficiently prevent attackers from overwhelming your application?",A,A,Use a Web Application Firewall and setup a rate-based rule,Configure Sticky Sessions on the Application Load Balancer,Use AWS Shield Advanced and setup a rate-based rule,Define a Network ACL (NACL) on your Application Load Balancer,,,,애플리케이션은 Application Load Balancer가 전면에 있는 EC2 인스턴스에 배포됩니다. 최근 귀하의 인프라가 공격을 받았습니다. 공격자는 초당 100개 이상의 요청을 수행하는 반면 일반 사용자는 초당 약 5개의 요청만 수행합니다.공격자가 애플리케이션을 압도하는 것을 어떻게 효율적으로 방지할 수 있습니까?,웹 애플리케이션 방화벽을 사용하고 속도 기반 규칙 설정,Application Load Balancer에서 고정 세션 구성,AWS Shield Advanced 사용 및 속도 기반 규칙 설정,Application Load Balancer에서 네트워크 ACL(NACL) 정의,,,0,,
udemy,CLF-01,332,A development team is looking for a solution that saves development time and deployment costs for an application that uses a high-throughput request-response message pattern.Which of the following SQS queue types is the best fit to meet this requirement?,D,D,Amazon SQS FIFO queues,Amazon SQS delay queues,Amazon SQS dead-letter queues,Amazon SQS temporary queues,,,,개발 팀은 높은 처리량의 요청-응답 메시지 패턴을 사용하는 애플리케이션의 개발 시간과 배포 비용을 절약할 수 있는 솔루션을 찾고 있습니다.다음 SQS 대기열 유형 중 이 요구 사항을 충족하는 데 가장 적합한 것은 무엇입니까?,Amazon SQS FIFO 대기열,Amazon SQS 지연 대기열,Amazon SQS 데드 레터 대기열,Amazon SQS 임시 대기열,,,0,,
udemy,CLF-01,333,The engineering team at an IT company is deploying an Online Transactional Processing (OLTP) application that needs to support relational queries. The application will have unpredictable spikes of usage that the team does not know in advance.Which database would you recommend using?,B,B,DynamoDB with Provisioned Capacity and Auto Scaling,Aurora Serverless,Amazon ElastiCache,DynamoDB with On-Demand Capacity,,,,IT 회사의 엔지니어링 팀은 관계형 쿼리를 지원해야 하는 OLTP(온라인 트랜잭션 처리) 응용 프로그램을 배포하고 있습니다. 응용 프로그램에는 팀이 미리 알지 못하는 예측할 수 없는 사용량 급증이 있습니다.어떤 데이터베이스를 사용하는 것이 좋습니까?,프로비저닝된 용량 및 Auto Scaling이 포함된 DynamoDB,오로라 서버리스,아마존 엘라스티캐시,온디맨드 용량을 갖춘 DynamoDB,,,0,,
udemy,CLF-01,334,The engineering team at a retail company is planning to migrate to AWS Cloud from the on-premises data center. The team is evaluating Amazon RDS as the database tier for its flagship application. The team has hired you as an AWS Certified Solutions Architect Associate to advise on RDS Multi-AZ capabilities.Which of the following would you identify as correct for RDS Multi-AZ? (Select two),DE,DE,"For automated backups, I/O activity is suspended on your primary DB since backups are not taken from standby DB","To enhance read scalability, a Multi-AZ standby instance can be used to serve read requests",Updates to your DB Instance are asynchronously replicated across the Availability Zone to the standby in order to keep both in sync,"Amazon RDS automatically initiates a failover to the standby, in case primary database fails for any reason","RDS applies OS updates by performing maintenance on the standby, then promoting the standby to primary and finally performing maintenance on the old primary, which becomes the new standby",,,소매 회사의 엔지니어링 팀은 온프레미스 데이터 센터에서 AWS 클라우드로 마이그레이션할 계획입니다. 팀은 주력 애플리케이션의 데이터베이스 계층으로 Amazon RDS를 평가하고 있습니다. 팀은 RDS 다중 AZ 기능에 대한 조언을 제공하기 위해 귀하를 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용했습니다.다음 중 RDS 다중 AZ에 대해 올바른 것으로 식별하는 것은 무엇입니까? (2개 선택),자동 백업의 경우 대기 DB에서 백업을 가져오지 않으므로 기본 DB에서 I/O 활동이 일시 중지됩니다.,읽기 확장성을 향상시키기 위해 다중 AZ 대기 인스턴스를 사용하여 읽기 요청을 처리할 수 있습니다.,DB 인스턴스에 대한 업데이트는 가용 영역에서 대기 인스턴스로 비동기식으로 복제되어 둘 다 동기화 상태로 유지됩니다.,Amazon RDS는 어떤 이유로든 기본 데이터베이스에 장애가 발생할 경우 자동으로 대기로 장애 조치를 시작합니다.,RDS는 대기에서 유지 관리를 수행한 다음 대기를 기본으로 승격하고 마지막으로 새 대기가 되는 이전 기본에서 유지 관리를 수행하여 OS 업데이트를 적용합니다.,,0,,
udemy,CLF-01,335,"You are using AWS Lambda to implement a batch job for a big data analytics workflow. Based on historical trends, a similar job runs for 30 minutes on average. The Lambda function pulls data from Amazon S3, processes it, and then writes the results back to S3. When you deployed your AWS Lambda function, you noticed an issue where the Lambda function abruptly failed after 15 minutes of execution.As a solutions architect, which of the following would you identify as the root cause of the issue?",D,D,The AWS Lambda function chosen runtime is wrong,The AWS Lambda function is running out of memory,The AWS Lambda function is missing IAM permissions,The AWS Lambda function is timing out,,,,AWS Lambda를 사용하여 빅 데이터 분석 워크플로에 대한 배치 작업을 구현하고 있습니다. 기록 추세를 기반으로 유사한 작업이 평균 30분 동안 실행됩니다. Lambda 함수는 Amazon S3에서 데이터를 가져와서 처리한 다음 결과를 다시 S3에 씁니다. AWS Lambda 함수를 배포할 때 실행 15분 후에 Lambda 함수가 갑자기 실패하는 문제를 발견했습니다.솔루션 설계자로서 다음 중 문제의 근본 원인으로 식별할 수 있는 항목은 무엇입니까?,런타임을 선택한 AWS Lambda 함수가 잘못되었습니다.,AWS Lambda 함수의 메모리가 부족합니다.,AWS Lambda 함수에 IAM 권한이 없습니다.,AWS Lambda 함수가 시간 초과되었습니다.,,,0,,
udemy,CLF-01,336,"During a review, a security team has flagged concerns over an Amazon EC2 instance querying IP addresses used for cryptocurrency mining. The EC2 instance does not host any authorized application related to cryptocurrency mining.Which AWS service can be used to protect the EC2 instances from such unauthorized behavior in the future?",A,A,Amazon GuardDuty,AWS Firewall Manager,AWS Web Application Firewall (AWS WAF),AWS Shield Advanced,,,,검토 중에 보안 팀은 암호화폐 채굴에 사용되는 IP 주소를 쿼리하는 Amazon EC2 인스턴스에 대한 우려를 표시했습니다. EC2 인스턴스는 암호화폐 채굴과 관련된 승인된 애플리케이션을 호스팅하지 않습니다.향후 이러한 무단 동작으로부터 EC2 인스턴스를 보호하는 데 사용할 수 있는 AWS 서비스는 무엇입니까?,Amazon GuardDuty,AWS 방화벽 관리자,AWS 웹 애플리케이션 방화벽(AWS WAF),AWS 쉴드 어드밴스드,,,0,,
udemy,CLF-01,337,"As a Solutions Architect, you have set up a database on a single EC2 instance that has an EBS volume of type gp2. You currently have 300GB of space on the gp2 device. The EC2 instance is of type m5.large. The database performance has recently been poor and upon looking at CloudWatch, you realize the IOPS on the EBS volume is maxing out. The disk size of the database must not change because of a licensing issue.How do you troubleshoot this issue?",D,D,Increase the IOPS on the gp2 volume,Convert the EC2 instance to an i3.4xlarge,Stop the CloudWatch agent to improve performance,Convert the gp2 volume to an io1,,,,솔루션 설계자는 gp2 유형의 EBS 볼륨이 있는 단일 EC2 인스턴스에 데이터베이스를 설정했습니다. 현재 gp2 장치에 300GB의 공간이 있습니다. EC2 인스턴스는 m5.large 유형입니다. 최근 데이터베이스 성능이 좋지 않아 CloudWatch를 살펴보니 EBS 볼륨의 IOPS가 최대치에 도달했습니다. 라이선스 문제로 인해 데이터베이스의 디스크 크기를 변경해서는 안 됩니다.이 문제를 어떻게 해결합니까?,gp2 볼륨에서 IOPS를 높입니다.,EC2 인스턴스를 i3.4xlarge로 변환,성능 향상을 위해 CloudWatch 에이전트 중지,gp2 볼륨을 io1로 변환,,,0,,
udemy,CLF-01,338,A photo-sharing company is storing user profile pictures in an S3 bucket and an image analysis application is deployed on four EC2 instances. A solutions architect would like to trigger an image analysis procedure only on one of the four EC2 instances for each photo uploaded.What do you recommend?,A,A,Create an S3 Event Notification that sends a message to an SQS queue. Make the EC2 instances read from the SQS queue,Create an S3 Event Notification that sends a message to an SNS topic. Subscribe the EC2 instances to the SNS topic,Create a EventBridge event that reacts to objects uploads in S3 and invokes one of the EC2 instances,Subscribe the EC2 instances to the S3 Inventory stream,,,,사진 공유 회사는 사용자 프로필 사진을 S3 버킷에 저장하고 이미지 분석 애플리케이션을 4개의 EC2 인스턴스에 배포합니다. 솔루션 설계자는 업로드된 각 사진에 대해 4개의 EC2 인스턴스 중 하나에서만 이미지 분석 절차를 트리거하려고 합니다.추천 메뉴가 무엇인가요?,SQS 대기열에 메시지를 보내는 S3 이벤트 알림을 생성합니다. SQS 대기열에서 EC2 인스턴스를 읽도록 합니다.,SNS 주제에 메시지를 보내는 S3 이벤트 알림을 생성합니다. SNS 주제에 대한 EC2 인스턴스 구독,S3에서 객체 업로드에 반응하고 EC2 인스턴스 중 하나를 호출하는 EventBridge 이벤트 생성,EC2 인스턴스를 S3 Inventory 스트림에 구독,,,0,,
udemy,CLF-01,339,"A company is deploying a web application and it wants to ensure that only the web tier of the application is publicly accessible. To accomplish this, the engineering team has designed the VPC with a public subnet and a private subnet. The application will be hosted on several EC2 instances in an Auto Scaling group. The team also wants TLS termination to be offloaded from the EC2 instances.Which solution should a solutions architect implement to address these requirements?",D,D,Set up a Network Load Balancer in the private subnet. Create an Auto Scaling group in the private subnet and associate it with the Network Load Balancer,Set up a Network Load Balancer in the private subnet. Create an Auto Scaling group in the public subnet and associate it with the Network Load Balancer,Set up a Network Load Balancer in the public subnet. Create an Auto Scaling group in the public subnet and associate it with the Network Load Balancer,Set up a Network Load Balancer in the public subnet. Create an Auto Scaling group in the private subnet and associate it with the Network Load Balancer,,,,회사에서 웹 애플리케이션을 배포하고 애플리케이션의 웹 계층만 공개적으로 액세스할 수 있도록 하려고 합니다. 이를 달성하기 위해 엔지니어링 팀은 퍼블릭 서브넷과 프라이빗 서브넷이 있는 VPC를 설계했습니다. 애플리케이션은 Auto Scaling 그룹의 여러 EC2 인스턴스에서 호스팅됩니다. 팀은 또한 TLS 종료가 EC2 인스턴스에서 오프로드되기를 원합니다.이러한 요구 사항을 해결하기 위해 솔루션 설계자는 어떤 솔루션을 구현해야 합니까?,프라이빗 서브넷에서 Network Load Balancer를 설정합니다. 프라이빗 서브넷에서 Auto Scaling 그룹을 생성하고 이를 Network Load Balancer와 연결합니다.,프라이빗 서브넷에서 Network Load Balancer를 설정합니다. 퍼블릭 서브넷에서 Auto Scaling 그룹을 생성하고 이를 Network Load Balancer와 연결합니다.,퍼블릭 서브넷에서 Network Load Balancer를 설정합니다. 퍼블릭 서브넷에서 Auto Scaling 그룹을 생성하고 이를 Network Load Balancer와 연결합니다.,퍼블릭 서브넷에서 Network Load Balancer를 설정합니다. 프라이빗 서브넷에서 Auto Scaling 그룹을 생성하고 이를 Network Load Balancer와 연결합니다.,,,0,,
udemy,CLF-01,340,"The engineering team at a startup is evaluating the most optimal block storage volume type for the EC2 instances hosting its flagship application. The storage volume should support very low latency but it does not need to persist the data when the instance terminates. As a solutions architect, you have proposed using Instance Store volumes to meet these requirements.Which of the following would you identify as the key characteristics of the Instance Store volumes? (Select two)",AB,AB,You can't detach an instance store volume from one instance and attach it to a different instance,"If you create an AMI from an instance, the data on its instance store volumes isn't preserved",An instance store is a network storage type,You can specify instance store volumes for an instance when you launch or restart it,Instance store is reset when you stop or terminate an instance. Instance store data is preserved during hibernation,,,스타트업의 엔지니어링 팀은 주력 애플리케이션을 호스팅하는 EC2 인스턴스에 가장 적합한 블록 스토리지 볼륨 유형을 평가하고 있습니다. 스토리지 볼륨은 매우 짧은 대기 시간을 지원해야 하지만 인스턴스가 종료될 때 데이터를 유지할 필요는 없습니다. 솔루션 설계자로서 이러한 요구 사항을 충족하기 위해 인스턴스 스토어 볼륨을 사용할 것을 제안했습니다.다음 중 인스턴스 스토어 볼륨의 주요 특성으로 식별할 수 있는 것은 무엇입니까? (2개 선택),한 인스턴스에서 인스턴스 스토어 볼륨을 분리하여 다른 인스턴스에 연결할 수 없습니다.,인스턴스에서 AMI를 생성하면 해당 인스턴스 스토어 볼륨의 데이터가 보존되지 않습니다.,인스턴스 스토어는 네트워크 스토리지 유형입니다.,인스턴스를 시작하거나 다시 시작할 때 인스턴스에 대한 인스턴스 스토어 볼륨을 지정할 수 있습니다.,인스턴스를 중지하거나 종료하면 인스턴스 스토어가 재설정됩니다. 인스턴스 스토어 데이터는 최대 절전 모드 동안 보존됩니다.,,0,,
udemy,CLF-01,341,"The engineering team at a social media company has noticed that while some of the images stored in S3 are frequently accessed, others sit idle for a considerable span of time.As a solutions architect, what is your recommendation to build the MOST cost-effective solution?",A,A,Store the images using the S3 Intelligent-Tiering storage class,Create a data monitoring application on an EC2 instance in the same region as the bucket storing the images. The application is triggered daily via CloudWatch and it changes the storage class of infrequently accessed objects to S3 Standard-IA and the frequently accessed objects are migrated to S3 Standard class,Create a data monitoring application on an EC2 instance in the same region as the bucket storing the images. The application is triggered daily via CloudWatch and it changes the storage class of infrequently accessed objects to S3 One Zone-IA and the frequently accessed objects are migrated to S3 Standard class,Store the images using the S3 Standard-IA storage class,,,,소셜 미디어 회사의 엔지니어링 팀은 S3에 저장된 일부 이미지가 자주 액세스되는 반면 다른 이미지는 상당한 시간 동안 유휴 상태로 있음을 확인했습니다.솔루션 설계자로서 가장 비용 효율적인 솔루션을 구축하기 위한 권장 사항은 무엇입니까?,S3 Intelligent-Tiering 스토리지 클래스를 사용하여 이미지 저장,이미지를 저장하는 버킷과 동일한 리전의 EC2 인스턴스에서 데이터 모니터링 애플리케이션을 생성합니다. 애플리케이션은 CloudWatch를 통해 매일 트리거되며 자주 액세스하지 않는 개체의 스토리지 클래스를 S3 Standard-IA로 변경하고 자주 액세스하는 개체는 S3 Standard 클래스로 마이그레이션합니다.,이미지를 저장하는 버킷과 동일한 리전의 EC2 인스턴스에서 데이터 모니터링 애플리케이션을 생성합니다. 애플리케이션은 CloudWatch를 통해 매일 트리거되며 자주 액세스하지 않는 개체의 스토리지 클래스를 S3 One Zone-IA로 변경하고 자주 액세스하는 개체는 S3 Standard 클래스로 마이그레이션합니다.,S3 Standard-IA 스토리지 클래스를 사용하여 이미지 저장,,,0,,
udemy,CLF-01,342,The CTO of an online home rental marketplace wants to re-engineer the caching layer of the current architecture for its relational database. The CTO wants the caching layer to have replication and archival support built into the architecture.Which of the following AWS service offers the capabilities required for the re-engineering of the caching layer?,B,B,ElastiCache for Memcached,ElastiCache for Redis,DocumentDB,DynamoDB Accelerator (DAX),,,,온라인 주택 임대 시장의 CTO는 관계형 데이터베이스를 위해 현재 아키텍처의 캐싱 계층을 재설계하려고 합니다. CTO는 캐싱 레이어가 아키텍처에 내장된 복제 및 보관 지원을 갖기를 원합니다.다음 중 캐싱 계층의 리엔지니어링에 필요한 기능을 제공하는 AWS 서비스는 무엇입니까?,Memcached용 ElastiCache,Redis용 ElastiCache,문서DB,DynamoDB 액셀러레이터(DAX),,,0,,
udemy,CLF-01,343,"A company is experiencing stability issues with their cluster of self-managed RabbitMQ message brokers and the company now wants to explore an alternate solution on AWS.As a solutions architect, which of the following AWS services would you recommend that can provide support for quick and easy migration from RabbitMQ?",A,A,Amazon MQ,Amazon Simple Notification Service (Amazon SNS),Amazon SQS FIFO (First-In-First-Out),Amazon SQS Standard,,,,회사는 자체 관리 RabbitMQ 메시지 브로커 클러스터에 안정성 문제를 겪고 있으며 이제 AWS에서 대체 솔루션을 탐색하려고 합니다.솔루션 설계자로서 다음 중 RabbitMQ에서 빠르고 쉽게 마이그레이션할 수 있는 지원을 제공할 수 있는 AWS 서비스를 추천하시겠습니까?,아마존 MQ,Amazon Simple Notification Service(Amazon SNS),Amazon SQS FIFO(선입선출),아마존 SQS 표준,,,0,,
udemy,CLF-01,344,"An e-commerce company uses RDS MySQL DB to store the data. The analytics department at the company runs its reports on the same DB. The engineering team has noticed sluggish performance on the DB when the analytics reporting process is in progress.As an AWS Certified Solutions Architect Associate, which of the following would you suggest as the MOST cost-optimal solution to improve the performance?",A,A,Create a read-replica with the same compute capacity and the same storage capacity as the primary. Point the reporting queries to run against the read replica,Create a standby instance in a multi-AZ configuration with half compute capacity and half storage capacity as the primary. Point the reporting queries to run against the standby instance,Create a standby instance in a multi-AZ configuration with the same compute capacity and the same storage capacity as the primary. Point the reporting queries to run against the standby instance,Create a read-replica with half compute capacity and half storage capacity as the primary. Point the reporting queries to run against the read replica,,,,전자 상거래 회사는 RDS MySQL DB를 사용하여 데이터를 저장합니다. 회사의 분석 부서는 동일한 DB에서 보고서를 실행합니다. 엔지니어링 팀은 분석 보고 프로세스가 진행 중일 때 DB에서 느린 성능을 발견했습니다.AWS 공인 솔루션스 아키텍트 어소시에이트로서 다음 중 성능을 개선하기 위한 가장 비용 최적화된 솔루션으로 제안하는 것은 무엇입니까?,컴퓨팅 용량과 스토리지 용량이 기본과 동일한 읽기 전용 복제본을 생성합니다. 읽기 복제본에 대해 실행할 보고 쿼리 지정,절반의 컴퓨팅 용량과 절반의 스토리지 용량을 기본으로 사용하여 다중 AZ 구성에서 대기 인스턴스를 생성합니다. 대기 인스턴스에 대해 실행할 보고 쿼리 지정,기본 인스턴스와 동일한 컴퓨팅 용량 및 스토리지 용량을 사용하여 다중 AZ 구성에서 대기 인스턴스를 생성합니다. 대기 인스턴스에 대해 실행할 보고 쿼리 지정,절반의 컴퓨팅 용량과 절반의 스토리지 용량을 기본으로 하는 읽기 전용 복제본을 생성합니다. 읽기 복제본에 대해 실행할 보고 쿼리 지정,,,0,,
udemy,CLF-01,345,"A digital media streaming company wants to use AWS Cloudfront to distribute its content only to its service subscribers. As a solutions architect, which of the following solutions would you suggest to deliver restricted content to the bona fide end users? (Select two)",AB,AB,Use CloudFront signed cookies,Use CloudFront signed URLs,Require HTTPS for communication between CloudFront and your S3 origin,Require HTTPS for communication between CloudFront and your custom origin,Forward HTTPS requests to the origin server by using the ECDSA or RSA ciphers,,,디지털 미디어 스트리밍 회사는 AWS Cloudfront를 사용하여 서비스 가입자에게만 콘텐츠를 배포하려고 합니다. 솔루션 아키텍트로서 다음 중 선의의 최종 사용자에게 제한된 콘텐츠를 제공하기 위해 제안할 솔루션은 무엇입니까? (2개 선택),CloudFront 서명 쿠키 사용,CloudFront 서명 URL 사용,CloudFront와 S3 오리진 간의 통신에 HTTPS 필요,CloudFront와 사용자 지정 오리진 간의 통신에 HTTPS 필요,ECDSA 또는 RSA 암호를 사용하여 HTTPS 요청을 원본 서버로 전달,,0,,
udemy,CLF-01,346,A company uses a legacy on-premises reporting application that operates on gigabytes of .json files and represents years of data. The legacy application cannot handle the growing size of .json files. New .json files are added daily from various data sources to a central on-premises storage location. The company wants to continue to support the legacy application. The company has hired you as a solutions architect to build a solution that can manage ongoing data updates from your on-premises application to Amazon S3.Which of the following solutions would you suggest to address the given requirement?,A,A,Set up an on-premises file gateway. Configure data sources to write the .json files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .json files to Amazon S3,Set up an on-premises volume gateway. Configure data sources to write the .json files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3,Set up AWS DataSync on-premises. Configure DataSync to continuously replicate the .json files between on-premises and Amazon Elastic File System (Amazon EFS). Enable replication from Amazon EFS to the company's S3 bucket,Set up AWS DataSync on-premises. Configure DataSync to continuously replicate the .json files between the company's on-premises storage and the company's S3 bucket,,,,회사는 기가바이트의 .json 파일에서 작동하고 수년간의 데이터를 나타내는 레거시 온프레미스 보고 애플리케이션을 사용합니다. 레거시 애플리케이션은 증가하는 .json 파일 크기를 처리할 수 없습니다. 새로운 .json 파일은 다양한 데이터 소스에서 중앙 온프레미스 스토리지 위치로 매일 추가됩니다. 회사는 레거시 애플리케이션을 계속 지원하기를 원합니다. 회사는 온프레미스 애플리케이션에서 Amazon S3로의 지속적인 데이터 업데이트를 관리할 수 있는 솔루션을 구축하기 위해 귀하를 솔루션 설계자로 고용했습니다.주어진 요구 사항을 해결하기 위해 다음 중 어떤 솔루션을 제안하시겠습니까?,온프레미스 파일 게이트웨이를 설정합니다. .json 파일을 파일 게이트웨이에 쓰도록 데이터 원본을 구성합니다. 레거시 분석 애플리케이션이 파일 게이트웨이를 가리키도록 합니다. 파일 게이트웨이는 .json 파일을 Amazon S3에 복제해야 합니다.,온프레미스 볼륨 게이트웨이를 설정합니다. .json 파일을 볼륨 게이트웨이에 쓰도록 데이터 원본을 구성합니다. 레거시 분석 애플리케이션이 볼륨 게이트웨이를 가리키도록 합니다. 볼륨 게이트웨이는 Amazon S3에 데이터를 복제해야 합니다.,온프레미스에서 AWS DataSync를 설정합니다. 온프레미스와 Amazon Elastic File System(Amazon EFS) 간에 .json 파일을 지속적으로 복제하도록 DataSync를 구성합니다. Amazon EFS에서 회사의 S3 버킷으로 복제 활성화,온프레미스에서 AWS DataSync를 설정합니다. 회사의 온프레미스 스토리지와 회사의 S3 버킷 간에 .json 파일을 지속적으로 복제하도록 DataSync 구성,,,0,,
udemy,CLF-01,347,A Big Data company wants to optimize its daily Extract-Transform-Load (ETL) process that migrates and transforms data from its S3 based data lake to a Redshift cluster. The team wants to manage this daily job in a serverless environment.Which AWS service is the best fit to manage this process without the need to configure or manage the underlying compute resources?,C,C,Amazon EMR,AWS Data Pipeline,AWS Glue,AWS Database Migration Service (DMS),,,,빅 데이터 회사는 S3 기반 데이터 레이크에서 Redshift 클러스터로 데이터를 마이그레이션하고 변환하는 일일 ETL(Extract-Transform-Load) 프로세스를 최적화하려고 합니다. 팀은 서버리스 환경에서 이 일상적인 작업을 관리하려고 합니다.기본 컴퓨팅 리소스를 구성하거나 관리할 필요 없이 이 프로세스를 관리하는 데 가장 적합한 AWS 서비스는 무엇입니까?,아마존 EMR,AWS 데이터 파이프라인,AWS 글루,AWS 데이터베이스 마이그레이션 서비스(DMS),,,0,,
udemy,CLF-01,348,"To support critical production workloads that require maximum resiliency, a company wants to configure network connections between its Amazon VPC and the on-premises infrastructure. The company needs AWS Direct Connect connections with speeds greater than 1 Gbps.As a solutions architect, which of the following will you suggest as the best architecture for this requirement?",D,D,Use AWS Managed VPN as a backup for AWS Direct Connect connections to ensure maximum resiliency,Opt for at least two Direct Connect connections terminating on different devices at a single Direct Connect location,Opt for one Direct Connect connection at each of the multiple Direct Connect locations,Opt for two separate Direct Connect connections terminating on separate devices in more than one Direct Connect location,,,,최대 복원력이 필요한 중요한 프로덕션 워크로드를 지원하기 위해 회사는 Amazon VPC와 온프레미스 인프라 간의 네트워크 연결을 구성하려고 합니다. 회사는 1Gbps 이상의 속도로 AWS Direct Connect 연결이 필요합니다.솔루션 설계자로서 다음 중 이 요구 사항에 가장 적합한 아키텍처를 제안하시겠습니까?,복원력을 극대화하기 위해 AWS Direct Connect 연결을 위한 백업으로 AWS Managed VPN 사용,단일 Direct Connect 위치에서 서로 다른 장치에서 종료되는 최소 2개의 Direct Connect 연결을 선택하십시오.,여러 Direct Connect 위치 각각에서 하나의 Direct Connect 연결 선택,둘 이상의 Direct Connect 위치에 있는 별도의 장치에서 종료되는 두 개의 별도 Direct Connect 연결 선택,,,0,,
udemy,CLF-01,349,"A company has moved its business critical data to Amazon EFS file system which will be accessed by multiple EC2 instances.As an AWS Certified Solutions Architect Associate, which of the following would you recommend to exercise access control such that only the permitted EC2 instances can read from the EFS file system? (Select two)",CE,CE,Use Network ACLs to control the network traffic to and from your Amazon EC2 instance,Set up the IAM policy root credentials to control and configure the clients accessing the EFS file system,Use an IAM policy to control access for clients who can mount your file system with the required permissions,Use Amazon GuardDuty to curb unwanted access to EFS file system,Use VPC security groups to control the network traffic to and from your file system,,,회사에서 비즈니스 크리티컬 데이터를 여러 EC2 인스턴스에서 액세스할 Amazon EFS 파일 시스템으로 옮겼습니다.다음 중 AWS 공인 솔루션스 아키텍트 어소시에이트로서 허용된 EC2 인스턴스만 EFS 파일 시스템에서 읽을 수 있도록 액세스 제어를 행사하기 위해 권장하는 것은 무엇입니까? (2개 선택),네트워크 ACL을 사용하여 Amazon EC2 인스턴스에서 들어오고 나가는 네트워크 트래픽 제어,EFS 파일 시스템에 액세스하는 클라이언트를 제어하고 구성하기 위한 IAM 정책 루트 자격 증명 설정,IAM 정책을 사용하여 필요한 권한으로 파일 시스템을 마운트할 수 있는 클라이언트에 대한 액세스 제어,Amazon GuardDuty를 사용하여 EFS 파일 시스템에 대한 원치 않는 액세스 억제,VPC 보안 그룹을 사용하여 파일 시스템과 주고받는 네트워크 트래픽 제어,,0,,
udemy,CLF-01,350,A company has noticed several provisioned throughput exceptions on its DynamoDB database due to major spikes in the writes to the database. The development team wants to decouple the application layer from the database layer and dedicate a worker process to writing the data to DynamoDB.Which middleware do you recommend on using that can scale infinitely and meet these requirements in the most cost effective way?,D,D,DynamoDB DAX,Amazon Simple Notification Service (SNS),Kinesis Data Streams,Amazon Simple Queue Service (SQS),,,,한 회사에서 데이터베이스에 대한 쓰기의 대폭적인 급증으로 인해 DynamoDB 데이터베이스에서 몇 가지 프로비저닝된 처리량 예외를 발견했습니다. 개발 팀은 데이터베이스 계층에서 애플리케이션 계층을 분리하고 DynamoDB에 데이터를 쓰는 데 작업자 프로세스를 전담하려고 합니다.무한 확장이 가능하고 가장 비용 효율적인 방식으로 이러한 요구 사항을 충족할 수 있는 미들웨어를 사용하는 것이 좋습니다.,DynamoDB DAX,Amazon 단순 알림 서비스(SNS),Kinesis 데이터 스트림,Amazon 단순 대기열 서비스(SQS),,,0,,
udemy,CLF-01,351,"A big data analytics company is looking to archive the on-premises data into a POSIX compliant file storage system on AWS Cloud. The archived data would be accessed for just about a week in a year.As a solutions architect, which of the following AWS services would you recommend as the MOST cost-optimal solution?",C,C,S3 Standard-IA,S3 Standard,EFS Infrequent Access,EFS Standard,,,,빅 데이터 분석 회사는 온프레미스 데이터를 AWS 클라우드의 POSIX 호환 파일 스토리지 시스템에 보관하려고 합니다. 보관된 데이터는 1년에 약 1주일만 액세스할 수 있습니다.솔루션 아키텍트로서 다음 중 가장 비용 최적화된 솔루션으로 추천할 AWS 서비스는 무엇입니까?,S3 스탠다드-IA,S3 스탠다드,EFS 드문 액세스,EFS 표준,,,0,,
udemy,CLF-01,352,A development team wants to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?Which of the following options represents the correct solution?,C,C,Configure the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private,Configure the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set,Configure the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set,Configure the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true,,,,개발 팀이 Amazon S3 버킷에 업로드된 모든 객체가 암호화되었는지 확인하고 싶습니까?다음 옵션 중 올바른 솔루션을 나타내는 것은 무엇입니까?,PutObject에 프라이빗으로 설정된 s3:x-amz-acl 헤더가 없는 경우 거부하도록 버킷 정책 구성,PutObject에 s3:x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책 구성,PutObject에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 정책 구성,PutObject에 true로 설정된 aws:SecureTransport 헤더가 없는 경우 거부하도록 버킷 정책 구성,,,0,,
udemy,CLF-01,353,"A company helps its customers legally sign highly confidential contracts. To meet the strong industry requirements, the company must ensure that the signed contracts are encrypted using the company's proprietary algorithm. The company is now migrating to AWS Cloud using AWS S3 and would like you, the solution architect, to advise them on the encryption scheme to adopt.What do you recommend?",C,C,SSE-S3,SSE-KMS,Client Side Encryption,SSE-C,,,,회사는 고객이 극비 계약에 합법적으로 서명하도록 돕습니다. 강력한 산업 요구 사항을 충족하기 위해 회사는 서명된 계약이 회사의 독점 알고리즘을 사용하여 암호화되도록 해야 합니다. 회사는 현재 AWS S3를 사용하여 AWS 클라우드로 마이그레이션하고 있으며 솔루션 설계자인 귀하가 채택할 암호화 체계에 대해 조언해 주기를 바랍니다.추천 메뉴가 무엇인가요?,SSE-S3,SSE-KMS,클라이언트 측 암호화,SSE-C,,,0,,
udemy,CLF-01,354,"An engineering team wants to orchestrate multiple Amazon ECS task types running on EC2 instances that are part of the ECS cluster. The output and state data for all tasks need to be stored. The amount of data output by each task is approximately 20 MB and there could be hundreds of tasks running at a time. As old outputs are archived, the storage size is not expected to exceed 1 TB.As a solutions architect, which of the following would you recommend as an optimized solution for high-frequency reading and writing?",B,B,Use a DynamoDB table that is accessible by all ECS cluster instances,Use Amazon EFS with Provisioned Throughput mode,Use Amazon EFS with Bursting Throughput mode,Use an Amazon EBS volume mounted to the ECS cluster instances,,,,엔지니어링 팀은 ECS 클러스터의 일부인 EC2 인스턴스에서 실행되는 여러 Amazon ECS 작업 유형을 오케스트레이션하려고 합니다. 모든 작업에 대한 출력 및 상태 데이터를 저장해야 합니다. 각 작업에서 출력되는 데이터의 양은 약 20MB이며 한 번에 수백 개의 작업이 실행될 수 있습니다. 이전 출력이 보관되므로 스토리지 크기는 1TB를 초과하지 않을 것으로 예상됩니다.솔루션 아키텍트로서 다음 중 고주파 읽기 및 쓰기에 최적화된 솔루션으로 추천하고 싶은 것은 무엇입니까?,모든 ECS 클러스터 인스턴스에서 액세스할 수 있는 DynamoDB 테이블 사용,프로비저닝된 처리량 모드로 Amazon EFS 사용,버스팅 처리량 모드에서 Amazon EFS 사용,ECS 클러스터 인스턴스에 마운트된 Amazon EBS 볼륨 사용,,,0,,
udemy,CLF-01,355,"A data analytics company is running a proprietary database on an EC2 instance using EBS volumes. The database is heavily I/O bound. As a solutions architect, which of the following RAID configurations would you recommend improving the I/O performance?",B,B,Use RAID 1 when I/O performance is more important than fault tolerance,Use RAID 0 when I/O performance is more important than fault tolerance,Both RAID 0 and RAID 1 provide equally good I/O performance,Amazon EBS does not support the standard RAID configurations,,,,데이터 분석 회사는 EBS 볼륨을 사용하여 EC2 인스턴스에서 독점 데이터베이스를 실행하고 있습니다. 데이터베이스는 I/O 바인딩이 많습니다. 솔루션 설계자로서 다음 RAID 구성 중 I/O 성능 개선을 권장하는 것은 무엇입니까?,내결함성보다 I/O 성능이 더 중요한 경우 RAID 1 사용,내결함성보다 I/O 성능이 더 중요한 경우 RAID 0 사용,RAID 0과 RAID 1 모두 우수한 I/O 성능을 제공합니다.,Amazon EBS는 표준 RAID 구성을 지원하지 않습니다.,,,0,,
udemy,CLF-01,356,The engineering team at a company wants to create a daily big data analysis job leveraging Spark for analyzing online/offline sales and customer loyalty data to create customized reports on a client-by-client basis. The big data analysis job needs to read the data from Amazon S3 and output it back to S3.Which technology do you recommend to run the Big Data analysis job? (Select two),BE,BE,Amazon Athena,AWS Glue,Amazon Redshift,AWS Batch,Amazon EMR,,,회사의 엔지니어링 팀은 온라인/오프라인 판매 및 고객 충성도 데이터를 분석하기 위해 Spark를 활용하여 클라이언트별로 맞춤형 보고서를 생성하는 일일 빅 데이터 분석 작업을 생성하려고 합니다. 빅 데이터 분석 작업은 Amazon S3에서 데이터를 읽고 S3로 다시 출력해야 합니다.빅 데이터 분석 작업을 실행하기 위해 어떤 기술을 권장합니까? (2개 선택),아마존 아테나,AWS 글루,아마존 레드시프트,AWS 배치,아마존 EMR,,0,,
udemy,CLF-01,357,"A retail company's procurement application becomes slow when traffic spikes. The application has a three-tier architecture (web, application and database tier) that uses synchronous transactions. The engineering team at the company has identified certain bottlenecks in the application tier but it does not want to change the underlying application architecture.As a solutions architect, which of the following solutions would you suggest to meet the required application response times while accounting for any traffic spikes?",A,A,Leverage horizontal scaling for the web and application tiers by using Auto Scaling groups and Application Load Balancer,Leverage SQS with asynchronous AWS Lambda calls to decouple the application and data tiers,Leverage horizontal scaling for the application's persistence layer by adding Oracle RAC on AWS,Leverage vertical scaling for the application instance by provisioning a larger Amazon EC2 instance size,,,,"트래픽이 급증하면 소매 회사의 조달 애플리케이션이 느려집니다. 애플리케이션에는 동기 트랜잭션을 사용하는 3계층 아키텍처(웹, 애플리케이션 및 데이터베이스 계층)가 있습니다. 회사의 엔지니어링 팀은 애플리케이션 계층에서 특정 병목 현상을 식별했지만 기본 애플리케이션 아키텍처를 변경하고 싶지 않습니다.솔루션 설계자로서 트래픽 급증을 고려하면서 필요한 애플리케이션 응답 시간을 충족하기 위해 다음 중 어떤 솔루션을 제안하시겠습니까?",Auto Scaling 그룹 및 Application Load Balancer를 사용하여 웹 및 애플리케이션 계층에 대한 수평적 확장 활용,비동기식 AWS Lambda 호출과 함께 SQS를 활용하여 애플리케이션과 데이터 계층을 분리합니다.,AWS에 Oracle RAC를 추가하여 애플리케이션의 지속성 계층에 대한 수평 확장 활용,더 큰 Amazon EC2 인스턴스 크기를 프로비저닝하여 애플리케이션 인스턴스에 대한 수직 확장 활용,,,0,,
udemy,CLF-01,358,"A software engineering intern at a company is documenting the features offered by EC2 Spot instances, Spot blocks, and Spot Fleets.Can you help the intern by selecting the correct options that identify the key characteristics of these three types of Spot entities? (Select three)",BDE,BDE,A Spot block is a set of Spot Instances and optionally On-Demand Instances that are launched to meet your target capacity,A Spot Fleet is a set of Spot Instances and optionally On-Demand Instances that are launched to meet your target capacity,Spot Fleet allows you to request Amazon EC2 Spot instances for 1 to 6 hours at a time to avoid being interrupted,Spot blocks allow you to request Amazon EC2 Spot instances for 1 to 6 hours at a time to avoid being interrupted,Spot instances are spare EC2 capacity that can save you up 90% off of On-Demand prices. Spot instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification,Spot blocks are spare EC2 capacity that can save you up 90% off of On-Demand prices. Spot blocks are usually interrupted by Amazon EC2 for capacity requirements with a 2-minute notification,,"회사의 소프트웨어 엔지니어링 인턴이 EC2 스팟 인스턴스, 스팟 블록 및 스팟 플릿에서 제공하는 기능을 문서화하고 있습니다.이러한 세 가지 유형의 스팟 엔터티의 주요 특성을 식별하는 올바른 옵션을 선택하여 인턴을 도울 수 있습니까? (3개 선택)",스팟 블록은 목표 용량을 충족하기 위해 시작되는 스팟 인스턴스 및 선택적으로 온디맨드 인스턴스 세트입니다.,스팟 플릿은 목표 용량을 충족하기 위해 시작되는 스팟 인스턴스 및 선택적으로 온디맨드 인스턴스 세트입니다.,Spot Fleet를 사용하면 중단을 방지하기 위해 한 번에 1~6시간 동안 Amazon EC2 Spot 인스턴스를 요청할 수 있습니다.,스팟 블록을 사용하면 중단되지 않도록 한 번에 1~6시간 동안 Amazon EC2 스팟 인스턴스를 요청할 수 있습니다.,스팟 인스턴스는 온디맨드 가격에서 90%까지 절약할 수 있는 여분의 EC2 용량입니다. 스팟 인스턴스는 2분 알림으로 용량 요구 사항에 대해 Amazon EC2에 의해 중단될 수 있습니다.,,0,,스팟 블록은 온디맨드 가격에서 90%까지 절약할 수 있는 여분의 EC2 용량입니다. 스팟 블록은 일반적으로 2분 알림과 함께 용량 요구 사항에 대해 Amazon EC2에 의해 중단됩니다.
udemy,CLF-01,359,"An e-commerce website is migrating towards a microservices-based approach for their website and plans to expose their website from the same load balancer, linked to different target groups with different URLs: checkout.mycorp.com, www.mycorp.com, mycorp.com/products, and mycorp.com/orders. The website would like to use ECS on the backend to manage these microservices and possibly host the same container of the application multiple times on the same EC2 instance.Which feature can help you achieve this with minimal effort?",D,D,Network Load Balancer + dynamic port mapping,Application Load Balancer + Reverse Proxy running as a Docker daemon on each ECS host,Classic Load Balancer + dynamic port mapping,Application Load Balancer + dynamic port mapping,,,,"전자 상거래 웹 사이트는 웹 사이트에 대한 마이크로 서비스 기반 접근 방식으로 마이그레이션하고 있으며 다른 URL(checkout.mycorp.com, www.mycorp.com, mycorp)을 사용하여 다른 대상 그룹에 연결된 동일한 로드 밸런서에서 웹 사이트를 노출할 계획입니다. .com/products 및 mycorp.com/orders. 웹 사이트는 백엔드에서 ECS를 사용하여 이러한 마이크로 서비스를 관리하고 동일한 EC2 인스턴스에서 애플리케이션의 동일한 컨테이너를 여러 번 호스팅하려고 합니다.최소한의 노력으로 이를 달성하는 데 도움이 되는 기능은 무엇입니까?",Network Load Balancer + 동적 포트 매핑,각 ECS 호스트에서 Docker 데몬으로 실행되는 Application Load Balancer + 역방향 프록시,Classic Load Balancer + 동적 포트 매핑,Application Load Balancer + 동적 포트 매핑,,,0,,
udemy,CLF-01,360,"A development team has noticed that one of the EC2 instances has been incorrectly configured with the 'DeleteOnTermination' attribute set to True for its root EBS volume.As a Solution's Architect, can you suggest a way to disable this flag while the instance is still running?",C,C,Set the DisableApiTermination attribute of the instance using the API,Update the attribute using AWS management console. Select the EC2 instance and then uncheck the Delete On Termination check box for the root EBS volume,Set the DeleteOnTermination attribute to False using the command line,The attribute cannot be updated when the instance is running. Stop the instance from Amazon EC2 console and then update the flag,,,,개발 팀은 루트 EBS 볼륨에 대해 'DeleteOnTermination' 속성이 True로 설정된 EC2 인스턴스 중 하나가 잘못 구성되었음을 발견했습니다.솔루션 설계자로서 인스턴스가 계속 실행되는 동안 이 플래그를 비활성화하는 방법을 제안할 수 있습니까?,DisableApiTerminationAPI를 사용하여 인스턴스의 속성 설정,AWS 관리 콘솔을 사용하여 속성을 업데이트합니다. EC2 인스턴스를 선택한 다음 루트 EBS 볼륨에 대한 종료 시 삭제 확인란을 선택 취소합니다.,DeleteOnTermination명령줄을 사용하여 속성을 False로 설정합니다.,인스턴스가 실행 중일 때는 속성을 업데이트할 수 없습니다. Amazon EC2 콘솔에서 인스턴스를 중지한 다음 플래그를 업데이트합니다.,,,0,,
udemy,CLF-01,361,"A company has multiple EC2 instances operating in a private subnet which is part of a custom VPC. These instances are running an image processing application that needs to access images stored on S3. Once each image is processed, the status of the corresponding record needs to be marked as completed in a DynamoDB table.How would you go about providing private access to these AWS resources which are not part of this custom VPC?",B,B,Create a gateway endpoint for S3 and add it as a target in the route table of the custom VPC. Create an interface endpoint for DynamoDB and then connect to the DynamoDB service using the private IP address,Create a separate gateway endpoint for S3 and DynamoDB each. Add two new target entries for these two gateway endpoints in the route table of the custom VPC,Create a gateway endpoint for DynamoDB and add it as a target in the route table of the custom VPC. Create an Origin Access Identity for S3 and then connect to the S3 service using the private IP address,Create a separate interface endpoint for S3 and DynamoDB each. Then connect to these services using the private IP address,,,,회사에는 사용자 지정 VPC의 일부인 프라이빗 서브넷에서 작동하는 여러 EC2 인스턴스가 있습니다. 이러한 인스턴스는 S3에 저장된 이미지에 액세스해야 하는 이미지 처리 애플리케이션을 실행하고 있습니다. 각 이미지가 처리되면 해당 레코드의 상태가 DynamoDB 테이블에서 완료된 것으로 표시되어야 합니다.이 사용자 지정 VPC의 일부가 아닌 이러한 AWS 리소스에 대한 프라이빗 액세스를 제공하는 방법은 무엇입니까?,S3용 게이트웨이 엔드포인트를 생성하고 사용자 지정 VPC의 라우팅 테이블에 대상으로 추가합니다. DynamoDB에 대한 인터페이스 엔드포인트를 생성한 다음 프라이빗 IP 주소를 사용하여 DynamoDB 서비스에 연결합니다.,S3 및 DynamoDB에 대해 각각 별도의 게이트웨이 엔드포인트를 생성합니다. 사용자 지정 VPC의 라우팅 테이블에서 이 두 게이트웨이 엔드포인트에 대한 두 개의 새 대상 항목을 추가합니다.,DynamoDB용 게이트웨이 엔드포인트를 생성하고 이를 사용자 지정 VPC의 라우팅 테이블에 대상으로 추가합니다. S3에 대한 원본 액세스 ID를 만든 다음 개인 IP 주소를 사용하여 S3 서비스에 연결합니다.,S3 및 DynamoDB에 대해 각각 별도의 인터페이스 엔드포인트를 생성합니다. 그런 다음 개인 IP 주소를 사용하여 이러한 서비스에 연결합니다.,,,0,,
udemy,CLF-01,362,"A security consultant is designing a solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Since the individual developers will have AWS account root user-level access to their own accounts, the consultant wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified.Which of the following actions meets the given requirements?",C,C,Set up an IAM policy that prohibits changes to CloudTrail and attach it to the root user,Set up a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the master account,"Set up a service control policy (SCP) that prohibits changes to CloudTrail, and attach it to the developer accounts",Configure a new trail in CloudTrail from within the developer accounts with the organization trails option enabled,,,,보안 컨설턴트는 표준 보안 제어를 유지하면서 개발자에게 AWS Organizations를 통해 개별 AWS 계정을 제공하려는 회사를 위한 솔루션을 설계하고 있습니다. 개별 개발자는 자신의 계정에 대한 AWS 계정 루트 사용자 수준 액세스 권한을 갖게 되므로 컨설턴트는 새 개발자 계정에 적용되는 필수 AWS CloudTrail 구성이 수정되지 않았는지 확인하려고 합니다.다음 중 주어진 요구 사항을 충족하는 조치는 무엇입니까?,CloudTrail 변경을 금지하는 IAM 정책을 설정하고 이를 루트 사용자에게 연결,마스터 계정의 Amazon 리소스 이름(ARN)에서만 변경을 허용하는 정책 조건으로 CloudTrail에 대한 서비스 연결 역할 설정,CloudTrail에 대한 변경을 금지하는 서비스 제어 정책(SCP)을 설정하고 이를 개발자 계정에 연결합니다.,조직 추적 옵션이 활성화된 개발자 계정 내에서 CloudTrail의 새 추적 구성,,,0,,
udemy,CLF-01,363,"A company's real-time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance.Which combination of steps should the solutions architect take? (Select two)",AD,AD,Set up Amazon Kinesis Data Streams to ingest the data,Set up AWS Lambda with AWS Step Functions to process the data,Set up AWS Database Migration Service (AWS DMS) to ingest the data,Set up AWS Fargate with Amazon ECS to process the data,Provision EC2 instances in an Auto Scaling group to process the data,,,회사의 실시간 스트리밍 애플리케이션이 AWS에서 실행되고 있습니다. 데이터가 수집되면 작업이 데이터에서 실행되고 완료하는 데 30분이 걸립니다. 워크로드는 많은 양의 수신 데이터로 인해 높은 대기 시간을 자주 경험합니다. 솔루션 설계자는 성능을 향상시키기 위해 확장 가능한 서버리스 솔루션을 설계해야 합니다.솔루션 아키텍트는 어떤 단계 조합을 취해야 합니까? (2개 선택),데이터를 수집하도록 Amazon Kinesis Data Streams 설정,AWS Step Functions로 AWS Lambda를 설정하여 데이터 처리,데이터를 수집하도록 AWS DMS(AWS Database Migration Service) 설정,Amazon ECS로 AWS Fargate를 설정하여 데이터 처리,Auto Scaling 그룹에 EC2 인스턴스를 프로비저닝하여 데이터 처리,,0,,
udemy,CLF-01,364,"A company is developing a document management application on AWS. The application runs on EC2 instances in multiple Availability Zones. The company requires the document store to be highly available and the documents need to be returned immediately when requested. The engineering team has configured the application to use EBS to store the documents but the team is willing to consider other options to meet the availability requirement.As a solutions architect, which of the following will you recommend?",B,B,Create snapshots for the EBS volumes regularly and then build new volumes using those snapshots in additional Availability Zones,Set up Amazon EBS as the EC2 instance root volume and then configure the application to use S3 as the document store,Set up Amazon EBS as the EC2 instance root volume and then configure the application to use S3 Glacier as the document store,Provision at least three Provisioned IOPS EBS volumes for the EC2 instances and then mount these volumes to the EC2 instances in a RAID 5 configuration,,,,회사에서 AWS에서 문서 관리 애플리케이션을 개발하고 있습니다. 애플리케이션은 여러 가용 영역의 EC2 인스턴스에서 실행됩니다. 회사는 문서 저장소의 가용성이 높아야 하며 요청 시 문서를 즉시 반환해야 합니다. 엔지니어링 팀은 EBS를 사용하여 문서를 저장하도록 애플리케이션을 구성했지만 팀은 가용성 요구 사항을 충족하기 위해 다른 옵션을 고려할 의향이 있습니다.솔루션 아키텍트로서 다음 중 무엇을 추천하시겠습니까?,EBS 볼륨에 대한 스냅샷을 정기적으로 생성한 다음 추가 가용 영역에서 해당 스냅샷을 사용하여 새 볼륨을 구축합니다.,Amazon EBS를 EC2 인스턴스 루트 볼륨으로 설정한 다음 S3를 문서 저장소로 사용하도록 애플리케이션 구성,Amazon EBS를 EC2 인스턴스 루트 볼륨으로 설정한 다음 S3 Glacier를 문서 저장소로 사용하도록 애플리케이션 구성,EC2 인스턴스에 대해 최소 3개의 프로비저닝된 IOPS EBS 볼륨을 프로비저닝한 다음 이 볼륨을 RAID 5 구성의 EC2 인스턴스에 마운트합니다.,,,0,,
udemy,CLF-01,365,"An e-commerce application uses a relational database that runs several queries that perform joins on multiple tables. The development team has found that these queries are slow and expensive, therefore these are a good candidate for caching. The application needs to use a caching service that supports multi-threading.As a solutions architect, which of the following services would you recommend for the given use case?",C,C,AWS Global Accelerator,Amazon ElastiCache for Redis,Amazon ElastiCache for Memcached,Amazon DynamoDB Accelerator (DAX),,,,전자 상거래 애플리케이션은 여러 테이블에서 조인을 수행하는 여러 쿼리를 실행하는 관계형 데이터베이스를 사용합니다. 개발 팀은 이러한 쿼리가 느리고 비용이 많이 들기 때문에 캐싱에 적합하다는 사실을 발견했습니다. 애플리케이션은 멀티스레딩을 지원하는 캐싱 서비스를 사용해야 합니다.솔루션 설계자로서 주어진 사용 사례에 대해 다음 중 어떤 서비스를 추천하시겠습니까?,AWS 글로벌 액셀러레이터,Redis용 Amazon ElastiCache,Memcached용 Amazon ElastiCache,Amazon DynamoDB 가속기(DAX),,,0,,
udemy,CLF-01,366,A company needs an Active Directory service to run directory-aware workloads in the AWS Cloud and it should also support configuring a trust relationship with any existing on-premises Microsoft Active Directory.Which AWS Directory Service is the best fit for this requirement?,D,D,AD Connector,AWS Transit Gateway,Simple AD,AWS Managed Microsoft AD,,,,회사는 AWS 클라우드에서 디렉터리 인식 워크로드를 실행하기 위해 Active Directory 서비스가 필요하며 기존 온프레미스 Microsoft Active Directory와의 신뢰 관계 구성도 지원해야 합니다.이 요구 사항에 가장 적합한 AWS Directory Service는 무엇입니까?,AD 커넥터,AWS 전송 게이트웨이,단순광고,AWS 관리형 Microsoft AD,,,0,,
udemy,CLF-01,367,"A social media application lets users upload photos and perform image editing operations. The application offers two classes of service: pro and lite. The product team wants the photos submitted by pro users to be processed before those submitted by lite users. Photos are uploaded to S3 and the job information is sent to Amazon SQS.As a solutions architect, which of the following solutions would you recommend?",D,D,Create two SQS FIFO queues: one for pro and one for lite. Set the lite queue to use short polling and the pro queue to use long polling,Create one SQS standard queue. Set the visibility timeout of the pro photos to zero. Set up EC2 instances to prioritize visibility settings so pro photos are processed first,Create two SQS standard queues: one for pro and one for lite. Set the lite queue to use short polling and the pro queue to use long polling,Create two SQS standard queues: one for pro and one for lite. Set up EC2 instances to prioritize polling for the pro queue over the lite queue,,,,소셜 미디어 애플리케이션을 통해 사용자는 사진을 업로드하고 이미지 편집 작업을 수행할 수 있습니다. 이 응용 프로그램은 프로와 라이트의 두 가지 서비스 등급을 제공합니다. 제품 팀은 프로 사용자가 제출한 사진이 라이트 사용자가 제출한 사진보다 먼저 처리되기를 원합니다. 사진은 S3에 업로드되고 작업 정보는 Amazon SQS로 전송됩니다.솔루션 아키텍트로서 다음 중 어떤 솔루션을 추천하시겠습니까?,두 개의 SQS FIFO 대기열을 생성합니다. 하나는 pro용이고 다른 하나는 lite용입니다. 짧은 폴링을 사용하도록 라이트 대기열을 설정하고 긴 폴링을 사용하도록 프로 대기열을 설정합니다.,하나의 SQS 표준 대기열을 만듭니다. 프로 사진의 가시성 제한 시간을 0으로 설정합니다. 전문 사진이 먼저 처리되도록 EC2 인스턴스를 설정하여 가시성 설정의 우선 순위 지정,두 개의 SQS 표준 대기열을 만듭니다. 하나는 Pro용이고 다른 하나는 Lite용입니다. 짧은 폴링을 사용하도록 라이트 대기열을 설정하고 긴 폴링을 사용하도록 프로 대기열을 설정합니다.,두 개의 SQS 표준 대기열을 만듭니다. 하나는 Pro용이고 다른 하나는 Lite용입니다. Lite 대기열보다 Pro 대기열에 대한 폴링에 우선순위를 두도록 EC2 인스턴스 설정,,,0,,
udemy,CLF-01,368,A company has media files that need to be shared internally. Users are first authenticated using Active Directory and then they access files on a Microsoft Windows platform. The engineering manager wants to keep the same user permissions but wants the company to migrate the storage layer to AWS Cloud as the company is reaching its storage capacity limit on the on-premises infrastructure.What should a solutions architect recommend to meet this requirement?,A,A,Set up Amazon FSx for Windows File Server and move all the media files,Set up EFS and move all media files,"Provision EC2 with Windows OS, attach multiple EBS volumes, and move all media files",Create a corporate Amazon S3 bucket and move all media files,,,,회사에 내부적으로 공유해야 하는 미디어 파일이 있습니다. 사용자는 먼저 Active Directory를 사용하여 인증을 받은 다음 Microsoft Windows 플랫폼의 파일에 액세스합니다. 엔지니어링 관리자는 동일한 사용자 권한을 유지하고 싶지만 회사가 온프레미스 인프라에서 스토리지 용량 제한에 도달함에 따라 스토리지 계층을 AWS 클라우드로 마이그레이션하기를 원합니다.이 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?,Windows File Server용 Amazon FSx 설정 및 모든 미디어 파일 이동,EFS 설정 및 모든 미디어 파일 이동,"Windows OS로 EC2 프로비저닝, 여러 EBS 볼륨 연결, 모든 미디어 파일 이동",회사 Amazon S3 버킷 생성 및 모든 미디어 파일 이동,,,0,,
udemy,CLF-01,369,An application running on an EC2 instance needs to access a DynamoDB table in the same AWS account.Which of the following solutions should a solutions architect configure for the necessary permissions?,D,D,Set up an IAM user with the appropriate permissions to allow access to the DynamoDB table. Store the access credentials in an S3 bucket and read them from within the application code directly,Set up an IAM user with the appropriate permissions to allow access to the DynamoDB table. Store the access credentials in the local storage and read them from within the application code directly,Set up an IAM service role with the appropriate permissions to allow access to the DynamoDB table. Add the EC2 instance to the trust relationship policy document so that the instance can assume the role,Set up an IAM service role with the appropriate permissions to allow access to the DynamoDB table. Configure an instance profile to assign this IAM role to the EC2 instance,,,,EC2 인스턴스에서 실행되는 애플리케이션은 동일한 AWS 계정의 DynamoDB 테이블에 액세스해야 합니다.다음 중 솔루션 설계자가 필요한 권한에 대해 구성해야 하는 솔루션은 무엇입니까?,DynamoDB 테이블에 대한 액세스를 허용하는 적절한 권한이 있는 IAM 사용자를 설정합니다. 액세스 자격 증명을 S3 버킷에 저장하고 애플리케이션 코드 내에서 직접 읽습니다.,DynamoDB 테이블에 대한 액세스를 허용하는 적절한 권한이 있는 IAM 사용자를 설정합니다. 액세스 자격 증명을 로컬 저장소에 저장하고 애플리케이션 코드 내에서 직접 읽습니다.,DynamoDB 테이블에 대한 액세스를 허용하는 적절한 권한으로 IAM 서비스 역할을 설정합니다. 인스턴스가 역할을 맡을 수 있도록 신뢰 관계 정책 문서에 EC2 인스턴스를 추가합니다.,DynamoDB 테이블에 대한 액세스를 허용하는 적절한 권한으로 IAM 서비스 역할을 설정합니다. 이 IAM 역할을 EC2 인스턴스에 할당하도록 인스턴스 프로필 구성,,,0,,
udemy,CLF-01,370,An application is hosted on multiple Amazon EC2 instances in the same Availability Zone. The engineering team wants to set up shared data access for these EC2 instances using EBS Multi-Attach volumes.Which EBS volume type is the correct choice for these EC2 instances?,A,A,Provisioned IOPS SSD EBS volumes,General-purpose SSD-based EBS volumes,Cold HDD EBS volumes,Throughput Optimized HDD EBS volumes,,,,애플리케이션은 동일한 가용 영역의 여러 Amazon EC2 인스턴스에서 호스팅됩니다. 엔지니어링 팀은 EBS 다중 연결 볼륨을 사용하여 이러한 EC2 인스턴스에 대한 공유 데이터 액세스를 설정하려고 합니다.이러한 EC2 인스턴스에 적합한 EBS 볼륨 유형은 무엇입니까?,프로비저닝된 IOPS SSD EBS 볼륨,범용 SSD 기반 EBS 볼륨,콜드 HDD EBS 볼륨,처리량에 최적화된 HDD EBS 볼륨,,,0,,
udemy,CLF-01,371,"The systems administrator at a company wants to set up a highly available architecture for a bastion host solution.As a solutions architect, which of the following options would you recommend as the solution?",D,D,Create a VPC Endpoint for a fleet of EC2 instances that are bastion hosts managed by an ASG,Create a public Application Load Balancer that links to EC2 instances that are bastion hosts managed by an ASG,Create an Elastic IP and assign it to all EC2 instances that are bastion hosts managed by an ASG,Create a public Network Load Balancer that links to EC2 instances that are bastion hosts managed by an ASG,,,,회사의 시스템 관리자는 배스천 호스트 솔루션을 위한 고가용성 아키텍처를 설정하려고 합니다.솔루션 아키텍트로서 다음 중 어떤 옵션을 솔루션으로 추천하시겠습니까?,ASG에서 관리하는 배스천 호스트인 EC2 인스턴스 플릿에 대한 VPC 엔드포인트 생성,ASG에서 관리하는 배스천 호스트인 EC2 인스턴스에 연결되는 퍼블릭 Application Load Balancer 생성,탄력적 IP를 생성하고 ASG에서 관리하는 배스천 호스트인 모든 EC2 인스턴스에 할당,ASG에서 관리하는 배스천 호스트인 EC2 인스턴스에 연결되는 퍼블릭 Network Load Balancer 생성,,,0,,
udemy,CLF-01,372,"A healthcare company runs a fleet of EC2 instances in two private subnets (named PR1 and PR2) across two Availability Zones (named A1 and A2). The EC2 instances need access to the internet for OS patch management and third-party software maintenance. To facilitate this, the engineering team at the company wants to set up two NAT gateways in a highly available configuration.Which of the following options would you suggest?",B,B,Set up a total of two NAT gateways. NAT gateway N1 should be set up in private subnet PR1 in Availability Zone A1. NAT gateway N2 should be set up in private subnet PR2 in Availability Zone A2,Set up a total of two NAT gateways. NAT gateway N1 should be set up in public subnet PU1 in Availability Zone A1. NAT gateway N2 should be set up in public subnet PU2 in Availability Zone A2,Set up a total of one NAT gateway. NAT gateway N1 should be set up in public subnet PU1 in any of the Availability Zones A1 or A2,Set up a total of two NAT gateways. Both NAT gateways N1 and N2 should be set up in a single public subnet PU1 in any of the Availability Zones A1 or A2,,,,의료 회사는 2개의 가용 영역(A1 및 A2)에 걸쳐 2개의 프라이빗 서브넷(PR1 및 PR2)에서 EC2 인스턴스 플릿을 실행합니다. EC2 인스턴스는 OS 패치 관리 및 타사 소프트웨어 유지 관리를 위해 인터넷에 액세스해야 합니다. 이를 용이하게 하기 위해 회사의 엔지니어링 팀은 고가용성 구성에서 두 개의 NAT 게이트웨이를 설정하려고 합니다.다음 중 어떤 옵션을 제안하시겠습니까?,총 2개의 NAT 게이트웨이를 설정합니다. NAT 게이트웨이 N1은 가용 영역 A1의 프라이빗 서브넷 PR1에 설정되어야 합니다. NAT 게이트웨이 N2는 가용 영역 A2의 프라이빗 서브넷 PR2에 설정되어야 합니다.,총 2개의 NAT 게이트웨이를 설정합니다. NAT 게이트웨이 N1은 가용 영역 A1의 퍼블릭 서브넷 PU1에 설정되어야 합니다. NAT 게이트웨이 N2는 가용 영역 A2의 퍼블릭 서브넷 PU2에 설정되어야 합니다.,총 하나의 NAT 게이트웨이를 설정합니다. NAT 게이트웨이 N1은 가용 영역 A1 또는 A2의 퍼블릭 서브넷 PU1에 설정되어야 합니다.,총 2개의 NAT 게이트웨이를 설정합니다. NAT 게이트웨이 N1과 N2는 모두 가용 영역 A1 또는 A2의 단일 퍼블릭 서브넷 PU1에 설정되어야 합니다.,,,0,,
udemy,CLF-01,373,You have deployed a database technology that has a synchronous replication mode to survive disasters in data centers. The database is therefore deployed on two EC2 instances in two Availability Zones. The database must be publicly available so you have deployed the EC2 instances in public subnets. The replication protocol currently uses the EC2 public IP addresses.What can you do to decrease the replication cost?,B,B,Use an Elastic Fabric Adapter,Use the EC2 instances private IP for the replication,Assign Elastic IPs to the EC2 instances and use them for the replication,Create a Private Link between the two EC2 instances,,,,데이터 센터의 재해에서 살아남기 위해 동기식 복제 모드가 있는 데이터베이스 기술을 배포했습니다. 따라서 데이터베이스는 2개의 가용 영역에 있는 2개의 EC2 인스턴스에 배포됩니다. 퍼블릭 서브넷에 EC2 인스턴스를 배포하려면 데이터베이스를 공개적으로 사용할 수 있어야 합니다. 복제 프로토콜은 현재 EC2 퍼블릭 IP 주소를 사용합니다.복제 비용을 줄이기 위해 무엇을 할 수 있습니까?,Elastic Fabric 어댑터 사용,복제에 EC2 인스턴스 사설 IP 사용,Elastic IP를 EC2 인스턴스에 할당하고 복제에 사용,두 EC2 인스턴스 간에 Private Link 생성,,,0,,
udemy,CLF-01,374,"A company manages a High Performance Computing (HPC) application that needs to be deployed on EC2 instances. The application requires high levels of inter-node communications and high network traffic between the instances.As a solutions architect, which of the following options would you recommend to the engineering team at the company? (Select two)",AB,AB,Deploy EC2 instances with Elastic Fabric Adapter,Deploy EC2 instances in a cluster placement group,Deploy EC2 instances in a partition placement group,Deploy EC2 instances in a spread placement group,Deploy EC2 instances behind a Network Load Balancer,,,회사는 EC2 인스턴스에 배포해야 하는 고성능 컴퓨팅(HPC) 애플리케이션을 관리합니다. 애플리케이션에는 높은 수준의 노드 간 통신과 인스턴스 간의 높은 네트워크 트래픽이 필요합니다.솔루션 아키텍트로서 다음 중 회사의 엔지니어링 팀에 추천할 옵션은 무엇입니까? (2개 선택),Elastic Fabric Adapter로 EC2 인스턴스 배포,클러스터 배치 그룹에 EC2 인스턴스 배포,파티션 배치 그룹에 EC2 인스턴스 배포,분산 배치 그룹에 EC2 인스턴스 배포,Network Load Balancer 뒤에 EC2 인스턴스 배포,,0,,
udemy,CLF-01,375,The development team at a company manages a flexible nightly process which runs for 1 hour using Python. The process currently runs on the on-premises infrastructure and it needs to be migrated to AWS.Which of the following options do you recommend as the MOST cost-effective solution?,B,B,Run on Lambda,Run on a Spot Instance with Spot Block,Run on EMR,Run on an Application Load Balancer,,,,회사의 개발팀은 Python을 사용하여 1시간 동안 실행되는 유연한 야간 프로세스를 관리합니다. 이 프로세스는 현재 온프레미스 인프라에서 실행되며 AWS로 마이그레이션해야 합니다.다음 중 가장 비용 효율적인 솔루션으로 권장하는 옵션은 무엇입니까?,람다에서 실행,스팟 블록을 사용하여 스팟 인스턴스에서 실행,EMR에서 실행,Application Load Balancer에서 실행,,,0,,
udemy,CLF-01,376,The DevOps team at a major financial services company uses Multi-Availability Zone (Multi-AZ) deployment for its MySQL RDS database in order to automate its database replication and augment data durability. The DevOps team has scheduled a maintenance window for a database engine level upgrade for the coming weekend.Which of the following is the correct outcome during the maintenance window?,D,D,Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers the standby DB instance to be upgraded which is then followed by the upgrade of the primary DB instance. This does not cause any downtime for the duration of the upgrade,Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers the primary DB instance to be upgraded which is then followed by the upgrade of the standby DB instance. This does not cause any downtime for the duration of the upgrade,"Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers both the primary and standby DB instances to be upgraded at the same time. However, this does not cause any downtime until the upgrade is complete",Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers both the primary and standby DB instances to be upgraded at the same time. This causes downtime until the upgrade is complete,,,,주요 금융 서비스 회사의 DevOps 팀은 데이터베이스 복제를 자동화하고 데이터 내구성을 강화하기 위해 MySQL RDS 데이터베이스에 다중 AZ(다중 가용 영역) 배포를 사용합니다. DevOps 팀은 다음 주말에 데이터베이스 엔진 수준 업그레이드를 위한 유지 관리 기간을 예약했습니다.다음 중 유지 관리 기간 동안의 올바른 결과는 무엇입니까?,다중 AZ 배포가 포함된 RDS DB 인스턴스에 대한 모든 데이터베이스 엔진 레벨 업그레이드는 대기 DB 인스턴스가 업그레이드된 다음 기본 DB 인스턴스가 업그레이드되도록 트리거합니다. 업그레이드 기간 동안 다운타임이 발생하지 않습니다.,다중 AZ 배포가 포함된 RDS DB 인스턴스에 대한 모든 데이터베이스 엔진 레벨 업그레이드는 기본 DB 인스턴스가 업그레이드된 다음 대기 DB 인스턴스가 업그레이드되도록 트리거합니다. 업그레이드 기간 동안 다운타임이 발생하지 않습니다.,다중 AZ 배포가 포함된 RDS DB 인스턴스에 대한 모든 데이터베이스 엔진 레벨 업그레이드는 기본 및 대기 DB 인스턴스가 동시에 업그레이드되도록 트리거합니다. 그러나 이로 인해 업그레이드가 완료될 때까지 다운타임이 발생하지 않습니다.,다중 AZ 배포가 포함된 RDS DB 인스턴스에 대한 모든 데이터베이스 엔진 레벨 업그레이드는 기본 및 대기 DB 인스턴스가 동시에 업그레이드되도록 트리거합니다. 이로 인해 업그레이드가 완료될 때까지 다운타임이 발생합니다.,,,0,,
udemy,CLF-01,377,"As a Solutions Architect, you would like to completely secure the communications between your CloudFront distribution and your S3 bucket which contains the static files for your website. Users should only be able to access the S3 bucket through CloudFront and not directly.What do you recommend?",B,B,Make the S3 bucket public,Create an origin access identity (OAI) and update the S3 Bucket Policy,Create a bucket policy to only authorize the IAM role attached to the CloudFront distribution,Update the S3 bucket security groups to only allow traffic from the CloudFront security group,,,,솔루션 아키텍트로서 귀하는 CloudFront 배포와 웹 사이트의 정적 파일이 포함된 S3 버킷 간의 통신을 완벽하게 보호하고자 합니다. 사용자는 CloudFront를 통해서만 S3 버킷에 액세스할 수 있어야 하며 직접 액세스할 수는 없습니다.추천 메뉴가 무엇인가요?,S3 버킷 공개,원본 액세스 ID(OAI) 생성 및 S3 버킷 정책 업데이트,CloudFront 배포에 연결된 IAM 역할에만 권한을 부여하는 버킷 정책 생성,CloudFront 보안 그룹의 트래픽만 허용하도록 S3 버킷 보안 그룹 업데이트,,,0,,
udemy,CLF-01,378,A startup uses a fleet of EC2 servers to manage its CRM application. These EC2 servers are behind an Elastic Load Balancer (ELB). Which of the following configurations are NOT allowed for the Elastic Load Balancer?,D,D,Use the ELB to distribute traffic for four EC2 instances. All the four instances are deployed in Availability Zone A of us-east-1 region,Use the ELB to distribute traffic for four EC2 instances. All the four instances are deployed across two Availability Zones of us-east-1 region,Use the ELB to distribute traffic for four EC2 instances. All the four instances are deployed in Availability Zone B of us-west-1 region,Use the ELB to distribute traffic for four EC2 instances. Two of these instances are deployed in Availability Zone A of us-east-1 region and the other two instances are deployed in Availability Zone B of us-west-1 region,,,,스타트업은 EC2 서버를 사용하여 CRM 애플리케이션을 관리합니다. 이러한 EC2 서버는 Elastic Load Balancer(ELB) 뒤에 있습니다. 다음 중 Elastic Load Balancer에 허용되지 않는 구성은 무엇입니까?,ELB를 사용하여 4개의 EC2 인스턴스에 대한 트래픽을 분산합니다. 인스턴스 4개 모두 us-east-1 지역의 가용 영역 A에 배포됩니다.,ELB를 사용하여 4개의 EC2 인스턴스에 대한 트래픽을 분산합니다. 네 개의 인스턴스는 모두 us-east-1 지역의 두 가용 영역에 배포됩니다.,ELB를 사용하여 4개의 EC2 인스턴스에 대한 트래픽을 분산합니다. 인스턴스 4개 모두 us-west-1 지역의 가용 영역 B에 배포됩니다.,ELB를 사용하여 4개의 EC2 인스턴스에 대한 트래픽을 분산합니다. 이러한 인스턴스 중 2개는 us-east-1 지역의 가용 영역 A에 배포되고 나머지 2개 인스턴스는 us-west-1 지역의 가용 영역 B에 배포됩니다.,,,0,,
udemy,CLF-01,379,"Your e-commerce application is using an RDS PostgreSQL database and an analytics workload also runs on the same database. When the analytics workload is run, your e-commerce application slows down which further affects your sales.Which of the following is the MOST cost-optimal solution to fix this issue?",D,D,Enable Multi-AZ for the RDS database and run the analytics workload on the standby database,Create a Read Replica in another Region as the Master database and point the analytics workload there,Migrate the analytics application to AWS Lambda,Create a Read Replica in the same Region as the Master database and point the analytics workload there,,,,전자 상거래 애플리케이션이 RDS PostgreSQL 데이터베이스를 사용하고 분석 워크로드도 동일한 데이터베이스에서 실행됩니다. 분석 워크로드가 실행되면 전자상거래 애플리케이션의 속도가 느려져 판매에 더 많은 영향을 미칩니다.다음 중 이 문제를 해결하기 위한 가장 비용 효율적인 솔루션은 무엇입니까?,RDS 데이터베이스에 대해 다중 AZ를 활성화하고 대기 데이터베이스에서 분석 워크로드 실행,마스터 데이터베이스로 다른 지역에 읽기 전용 복제본을 생성하고 여기에서 분석 워크로드 지정,분석 애플리케이션을 AWS Lambda로 마이그레이션,마스터 데이터베이스와 동일한 리전에서 읽기 전용 복제본을 생성하고 그곳에서 분석 워크로드를 지정합니다.,,,0,,
udemy,CLF-01,380,The engineering team at an e-commerce company wants to set up a custom domain for internal usage such as internaldomainexample.com. The team wants to use the private hosted zones feature of Route 53 to accomplish this.Which of the following settings of the VPC need to be enabled? (Select two),CD,CD,enableVpcSupport,enableDnsDomain,enableDnsSupport,enableDnsHostnames,enableVpcHostnames,,,전자상거래 회사의 엔지니어링 팀은 internaldomainexample.com과 같은 내부용 사용자 정의 도메인을 설정하려고 합니다. 팀은 이를 달성하기 위해 Route 53의 프라이빗 호스팅 영역 기능을 사용하려고 합니다.다음 VPC 설정 중 활성화해야 하는 것은 무엇입니까? (2개 선택),enableVpcSupport,enableDnsDomain,enableDnsSupport,enableDnsHostnames,enableVpc호스트 이름,,0,,
udemy,CLF-01,381,"You are deploying a critical monolith application that must be deployed on a single web server, as it hasn't been created to work in distributed mode. Still, you want to make sure your setup can automatically recover from the failure of an AZ.Which of the following options should be combined to form the MOST cost-efficient solution? (Select three)",ACE,ACE,Assign an EC2 Instance Role to perform the necessary API calls,Create an Application Load Balancer and a target group with the instance(s) of the Auto Scaling Group,"Create an auto-scaling group that spans across 2 AZ, which min=1, max=1, desired=1","Create an auto-scaling group that spans across 2 AZ, which min=1, max=2, desired=2",Create an Elastic IP and use the EC2 user-data script to attach it,Create a Spot Fleet request,,분산 모드에서 작동하도록 생성되지 않았기 때문에 단일 웹 서버에 배포해야 하는 중요한 모놀리식 애플리케이션을 배포하고 있습니다. 그래도 설정이 AZ 장애로부터 자동으로 복구될 수 있는지 확인하려고 합니다.가장 비용 효율적인 솔루션을 형성하기 위해 다음 옵션 중 무엇을 결합해야 합니까? (3개 선택),필요한 API 호출을 수행할 EC2 인스턴스 역할 할당,Auto Scaling 그룹의 인스턴스로 Application Load Balancer 및 대상 그룹 생성,"최소=1, 최대=1, 원하는=1인 2개의 AZ에 걸쳐 있는 Auto-Scaling 그룹을 생성합니다.","최소=1, 최대=2, 원하는=2인 2개의 AZ에 걸쳐 있는 Auto-Scaling 그룹을 생성합니다.",탄력적 IP를 생성하고 EC2 사용자 데이터 스크립트를 사용하여 연결,,0,,스팟 플릿 요청 생성
udemy,CLF-01,382,"A startup wants to create a highly available architecture for its multi-tier application. Currently, the startup manages a single EC2 instance along with a single RDS MySQL DB instance. The startup has hired you as an AWS Certified Solutions Architect Associate to build a solution that meets these requirements while minimizing the underlying infrastructure maintenance effort.What will you recommend?",D,D,Provision a second EC2 instance in another Availability Zone. Provision a second RDS MySQL DB in another Availabililty Zone. Leverage Route 53 for equal distribution of incoming traffic to the EC2 instances. Use a custom script to sync data across the two MySQL DBs,Create an Auto-Scaling group with a desired capacity of a total of two EC2 instances in a single Availability Zone. Configure an Application Load Balancer having a target group of these EC2 instances. Set up RDS MySQL DB in a multi-AZ configuration,Create an Auto-Scaling group with a desired capacity of a total of two EC2 instances across two Availability Zones. Configure an Application Load Balancer having a target group of these EC2 instances. Set up a read replica of the RDS MySQL DB in another Availability Zone,Create an Auto-Scaling group with a desired capacity of a total of two EC2 instances across two Availability Zones. Configure an Application Load Balancer having a target group of these EC2 instances. Set up RDS MySQL DB in a multi-AZ configuration,,,,신생 기업은 다중 계층 애플리케이션을 위한 고가용성 아키텍처를 생성하려고 합니다. 현재 스타트업은 단일 RDS MySQL DB 인스턴스와 함께 단일 EC2 인스턴스를 관리합니다. 이 스타트업은 기본 인프라 유지 관리 노력을 최소화하면서 이러한 요구 사항을 충족하는 솔루션을 구축하기 위해 귀사를 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용했습니다.무엇을 추천하시겠습니까?,다른 가용 영역에서 두 번째 EC2 인스턴스를 프로비저닝합니다. 다른 가용 영역에서 두 번째 RDS MySQL DB를 프로비저닝합니다. 수신 트래픽을 EC2 인스턴스에 균등하게 분배하기 위해 Route 53을 활용합니다. 사용자 지정 스크립트를 사용하여 두 MySQL DB 간에 데이터 동기화,단일 가용 영역에서 총 2개의 EC2 인스턴스의 원하는 용량으로 Auto-Scaling 그룹을 생성합니다. 이러한 EC2 인스턴스의 대상 그룹이 있는 Application Load Balancer를 구성합니다. 다중 AZ 구성에서 RDS MySQL DB 설정,2개의 가용 영역에 걸쳐 총 2개의 EC2 인스턴스의 원하는 용량으로 Auto-Scaling 그룹을 생성합니다. 이러한 EC2 인스턴스의 대상 그룹이 있는 Application Load Balancer를 구성합니다. 다른 가용 영역에서 RDS MySQL DB의 읽기 복제본 설정,2개의 가용 영역에 걸쳐 총 2개의 EC2 인스턴스의 원하는 용량으로 Auto-Scaling 그룹을 생성합니다. 이러한 EC2 인스턴스의 대상 그룹이 있는 Application Load Balancer를 구성합니다. 다중 AZ 구성에서 RDS MySQL DB 설정,,,0,,
udemy,CLF-01,383,"A Big Data analytics company is using a fleet of Amazon EC2 instances to ingest Internet-of-Things (IoT) data from various data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is restarted, the in-flight data is lost. The analytics team at the company wants to store as well as query the ingested data in near-real-time.Which of the following solutions provides near-real-time data querying that is scalable with minimal data loss?",A,A,Capture data in Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data,Capture data in an EBS volume and then publish this data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data,Capture data in an EC2 instance store and then publish this data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data,Capture data in Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query and analyze this streaming data in real-time,,,,빅 데이터 분석 회사는 Amazon EC2 인스턴스 플릿을 사용하여 다양한 데이터 소스에서 사물 인터넷(IoT) 데이터를 수집하고 있습니다. 데이터는 JSON 형식이며 수집 속도는 최대 1MB/s입니다. EC2 인스턴스를 다시 시작하면 진행 중인 데이터가 손실됩니다. 회사의 분석 팀은 거의 실시간으로 수집된 데이터를 저장하고 쿼리하기를 원합니다.다음 중 데이터 손실을 최소화하면서 확장 가능한 거의 실시간 데이터 쿼리를 제공하는 솔루션은 무엇입니까?,Amazon Redshift를 대상으로 사용하여 Amazon Kinesis Data Firehose에서 데이터를 캡처합니다. Amazon Redshift를 사용하여 데이터 쿼리,EBS 볼륨에서 데이터를 캡처한 다음 이 데이터를 Redis용 Amazon ElastiCache에 게시합니다. Redis 채널을 구독하여 데이터 쿼리,EC2 인스턴스 스토어에서 데이터를 캡처한 다음 이 데이터를 Amazon S3를 대상으로 Amazon Kinesis Data Firehose에 게시합니다. Amazon Athena를 사용하여 데이터 쿼리,Amazon Kinesis Data Streams에서 데이터를 캡처합니다. Kinesis Data Analytics를 사용하여 이 스트리밍 데이터를 실시간으로 쿼리하고 분석합니다.,,,0,,
udemy,CLF-01,384,A Big Data consulting company runs large distributed and replicated workloads on the on-premises data center. The company now wants to move these workloads to Amazon EC2 instances by using the placement groups feature and it wants to minimize correlated hardware failures.Which of the following represents the correct placement group configuration for the given requirement?,A,A,Partition placement groups,Cluster placement groups,Spread placement groups,Multi-AZ placement groups,,,,빅 데이터 컨설팅 회사는 온프레미스 데이터 센터에서 대규모 분산 및 복제 워크로드를 실행합니다. 이제 회사는 배치 그룹 기능을 사용하여 이러한 워크로드를 Amazon EC2 인스턴스로 옮기고 관련 하드웨어 장애를 최소화하려고 합니다.다음 중 주어진 요구 사항에 대한 올바른 배치 그룹 구성을 나타내는 것은 무엇입니까?,파티션 배치 그룹,클러스터 배치 그룹,확산 배치 그룹,다중 AZ 배치 그룹,,,0,,
udemy,CLF-01,385,"The DevOps team at an e-commerce company has deployed a fleet of EC2 instances under an Auto Scaling group (ASG). The instances under the ASG span two Availability Zones (AZ) within the us-east-1 region. All the incoming requests are handled by an Application Load Balancer (ALB) that routes the requests to the EC2 instances under the ASG. As part of a test run, two instances (instance 1 and 2, belonging to AZ A) were manually terminated by the DevOps team causing the Availability Zones to become unbalanced. Later that day, another instance (belonging to AZ B) was detected as unhealthy by the Application Load Balancer's health check.Can you identify the correct outcomes for these events? (Select two)",BE,BE,Amazon EC2 Auto Scaling creates a new scaling activity to terminate the unhealthy instance and launch the new instance simultaneously,"Amazon EC2 Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it. Later, another scaling activity launches a new instance to replace the terminated instance","As the Availability Zones got unbalanced, Amazon EC2 Auto Scaling will compensate by rebalancing the Availability Zones. When rebalancing, Amazon EC2 Auto Scaling terminates old instances before launching new instances, so that rebalancing does not cause extra instances to be launched","Amazon EC2 Auto Scaling creates a new scaling activity for launching a new instance to replace the unhealthy instance. Later, EC2 Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it","As the Availability Zones got unbalanced, Amazon EC2 Auto Scaling will compensate by rebalancing the Availability Zones. When rebalancing, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, so that rebalancing does not compromise the performance or availability of your application",,,전자상거래 회사의 DevOps 팀은 Auto Scaling 그룹(ASG)에 EC2 인스턴스 플릿을 배포했습니다. ASG 아래의 인스턴스는 us-east-1 지역 내의 두 가용 영역(AZ)에 걸쳐 있습니다. 모든 수신 요청은 요청을 ASG 아래의 EC2 인스턴스로 라우팅하는 Application Load Balancer(ALB)에서 처리합니다. 테스트 실행의 일부로 두 개의 인스턴스(AZ A에 속하는 인스턴스 1과 2)가 DevOps 팀에 의해 수동으로 종료되어 가용 영역의 균형이 맞지 않게 되었습니다. 그날 늦게 다른 인스턴스(AZ B에 속함)가 Application Load Balancer의 상태 확인에서 비정상으로 감지되었습니다.이러한 이벤트에 대한 올바른 결과를 식별할 수 있습니까? (2개 선택),Amazon EC2 Auto Scaling은 비정상 인스턴스를 종료하고 동시에 새 인스턴스를 시작하는 새로운 조정 활동을 생성합니다.,Amazon EC2 Auto Scaling은 비정상 인스턴스를 종료하기 위한 새로운 조정 활동을 생성한 다음 종료합니다. 나중에 다른 조정 활동이 새 인스턴스를 시작하여 종료된 인스턴스를 대체합니다.,가용 영역의 균형이 맞지 않으면 Amazon EC2 Auto Scaling이 가용 영역을 재조정하여 보상합니다. 재조정 시 Amazon EC2 Auto Scaling은 새 인스턴스를 시작하기 전에 이전 인스턴스를 종료하므로 재조정으로 인해 추가 인스턴스가 시작되지 않습니다.,Amazon EC2 Auto Scaling은 비정상 인스턴스를 대체할 새 인스턴스를 시작하기 위한 새로운 조정 활동을 생성합니다. 나중에 EC2 Auto Scaling은 비정상 인스턴스를 종료하기 위한 새로운 조정 활동을 생성한 다음 종료합니다.,가용 영역의 균형이 맞지 않으면 Amazon EC2 Auto Scaling이 가용 영역을 재조정하여 보상합니다. 재조정할 때 Amazon EC2 Auto Scaling은 이전 인스턴스를 종료하기 전에 새 인스턴스를 시작하므로 재조정으로 인해 애플리케이션의 성능이나 가용성이 손상되지 않습니다.,,0,,
udemy,CLF-01,386,A systems administration team has a requirement to run certain custom scripts only once during the launch of the Amazon EC2 instances that host their application.Which of the following represents the best way of configuring a solution for this requirement with minimal effort?,A,A,Run the custom scripts as user data scripts on the Amazon EC2 instances,"Update Amazon EC2 instance configuration to ensure that the custom scripts, added as user data scripts, are run only during the boot process",Run the custom scripts as instance metadata scripts on the Amazon EC2 instances,Use AWS CLI to run the user data scripts only once while launching the instance,,,,시스템 관리 팀은 애플리케이션을 호스팅하는 Amazon EC2 인스턴스를 시작하는 동안 특정 사용자 지정 스크립트를 한 번만 실행해야 한다는 요구 사항이 있습니다.다음 중 최소한의 노력으로 이 요구 사항에 맞는 솔루션을 구성하는 가장 좋은 방법은 무엇입니까?,Amazon EC2 인스턴스에서 사용자 데이터 스크립트로 사용자 지정 스크립트 실행,사용자 데이터 스크립트로 추가된 사용자 지정 스크립트가 부팅 프로세스 중에만 실행되도록 Amazon EC2 인스턴스 구성을 업데이트합니다.,Amazon EC2 인스턴스에서 인스턴스 메타데이터 스크립트로 사용자 지정 스크립트 실행,인스턴스를 시작하는 동안 AWS CLI를 사용하여 사용자 데이터 스크립트를 한 번만 실행합니다.,,,0,,
udemy,CLF-01,387,"A team has around 200 users, each of these having an IAM user account in AWS. Currently, they all have read access to an Amazon S3 bucket. The team wants 50 among them to have write and read access to the buckets.How can you provide these users access in the least possible time, with minimal changes?",A,A,"Create a group, attach the policy to the group and place the users in the group",Create an MFA user with read / write access and link 50 IAM with MFA,Update the S3 bucket policy,Create a policy and assign it manually to the 50 users,,,,팀에는 약 200명의 사용자가 있으며 각 사용자는 AWS에서 IAM 사용자 계정을 가지고 있습니다. 현재 이들은 모두 Amazon S3 버킷에 대한 읽기 액세스 권한이 있습니다. 팀은 그들 중 50명이 버킷에 대한 쓰기 및 읽기 액세스 권한을 갖기를 원합니다.최소한의 변경으로 가능한 최소한의 시간에 이러한 사용자 액세스를 제공하려면 어떻게 해야 합니까?,그룹을 생성하고 정책을 그룹에 연결하고 사용자를 그룹에 배치합니다.,읽기/쓰기 권한이 있는 MFA 사용자를 생성하고 MFA와 50 IAM을 연결합니다.,S3 버킷 정책 업데이트,정책을 생성하고 50명의 사용자에게 수동으로 할당,,,0,,
udemy,CLF-01,388,"A Hollywood production studio is looking at transferring their existing digital media assets of around 20PB to AWS Cloud in the shortest possible timeframe.Which of the following is an optimal solution for this requirement, given that the studio's data centers are located at a remote location?",D,D,AWS Storage Gateway,AWS Direct Connect,AWS Snowball,AWS Snowmobile,,,,할리우드 프로덕션 스튜디오는 약 20PB의 기존 디지털 미디어 자산을 가능한 가장 짧은 시간 내에 AWS 클라우드로 이전하는 방법을 모색하고 있습니다.스튜디오의 데이터 센터가 원격 위치에 있는 경우 다음 중 이 요구 사항에 대한 최적의 솔루션은 무엇입니까?,AWS 스토리지 게이트웨이,AWS 다이렉트 커넥트,AWS 스노우볼,AWS 스노우모빌,,,0,,
udemy,CLF-01,389,"You are looking to build an index of your files in S3, using Amazon RDS PostgreSQL. To build this index, it is necessary to read the first 250 bytes of each object in S3, which contains some metadata about the content of the file itself. There are over 100,000 files in your S3 bucket, amounting to 50TB of data.How can you build this index efficiently?",C,C,"Use the RDS Import feature to load the data from S3 to PostgreSQL, and run a SQL query to build the index","Create an application that will traverse the S3 bucket, read all the files one by one, extract the first 250 bytes, and store that information in RDS","Create an application that will traverse the S3 bucket, issue a Byte Range Fetch for the first 250 bytes, and store that information in RDS","Create an application that will traverse the S3 bucket, then use S3 Select Byte Range Fetch parameter to get the first 250 bytes, and store that information in RDS",,,,"Amazon RDS PostgreSQL을 사용하여 S3에서 파일 인덱스를 구축하려고 합니다. 이 인덱스를 구축하려면 S3에 있는 각 객체의 처음 250바이트를 읽어야 합니다. 여기에는 파일 자체의 콘텐츠에 대한 일부 메타데이터가 포함되어 있습니다. S3 버킷에는 50TB의 데이터에 해당하는 100,000개 이상의 파일이 있습니다.이 인덱스를 어떻게 효율적으로 구축할 수 있습니까?",RDS 가져오기 기능을 사용하여 S3에서 PostgreSQL로 데이터를 로드하고 SQL 쿼리를 실행하여 인덱스를 빌드합니다.,S3 버킷을 통과하고 모든 파일을 하나씩 읽고 처음 250바이트를 추출하고 해당 정보를 RDS에 저장하는 애플리케이션을 생성합니다.,S3 버킷을 순회하는 애플리케이션을 생성하고 처음 250바이트에 대해 바이트 범위 가져오기를 실행하고 해당 정보를 RDS에 저장합니다.,S3 버킷을 순회하는 애플리케이션을 만든 다음 S3 Select Byte Range Fetch 매개변수를 사용하여 처음 250바이트를 가져오고 해당 정보를 RDS에 저장합니다.,,,0,,
udemy,CLF-01,390,The engineering team at a multi-national company uses AWS Firewall Manager to centrally configure and manage firewall rules across its accounts and applications using AWS Organizations.Which of the following AWS resources can the AWS Firewall Manager configure rules on? (Select three),ACE,ACE,VPC Security Groups,Amazon Inspector,AWS WAF,Amazon GuardDuty,AWS Shield Advanced,Network Access Control Lists (NACLs),,다국적 기업의 엔지니어링 팀은 AWS Firewall Manager를 사용하여 AWS Organizations를 사용하는 계정 및 애플리케이션 전체에서 방화벽 규칙을 중앙에서 구성하고 관리합니다.다음 중 AWS Firewall Manager가 규칙을 구성할 수 있는 AWS 리소스는 무엇입니까? (3개 선택),VPC 보안 그룹,아마존 인스펙터,AWS WAF,Amazon GuardDuty,AWS 쉴드 어드밴스드,,0,,네트워크 액세스 제어 목록(NACL)
